{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Practical 2b - Predicting House Prices</h2><h3>AY2020/21 Semester</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras:  2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print('keras: ', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "After completing this practical exercise, students should be able to:\n",
    "1. [Build a neural network model to predict house prices](#demo)\n",
    "2. [Exercise- tuning several model parameters](#exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predicting house prices (a regression example) <a id='demo' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Boston Housing Price dataset\n",
    "\n",
    "We will be attempting to predict the median price of homes in a given Boston suburb in the mid-1970s, given a few data points about the \n",
    "suburb at the time, such as the crime rate, the local property tax rate, etc.\n",
    "\n",
    "The dataset has only 506 samples, split between 404 training samples and 102 test samples. Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1290e-02 2.0000e+01 3.3300e+00 1.0000e+00 4.4290e-01 7.6450e+00\n",
      " 4.9700e+01 5.2119e+00 5.0000e+00 2.1600e+02 1.4900e+01 3.7707e+02\n",
      " 3.0100e+00]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can see, we have 404 training samples and 102 test samples. The data comprises 13 features (details are shown below) and each \"feature\" in the input data (e.g. the crime rate is a feature) has a different scale. For instance some values are proportions, which take a values between 0 and 1, others take values between 1 and 12, others between 0 and 100...\n",
    "\n",
    "1. Per capita crime rate.\n",
    "2. Proportion of residential land zoned for lots over 25,000 square feet.\n",
    "3. Proportion of non-retail business acres per town.\n",
    "4. Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "5. Nitric oxides concentration (parts per 10 million).\n",
    "6. Average number of rooms per dwelling.\n",
    "7. Proportion of owner-occupied units built prior to 1940.\n",
    "8. Weighted distances to five Boston employment centres.\n",
    "9. Index of accessibility to radial highways.\n",
    "10. Full-value property-tax rate per $10,000.\n",
    "11. Pupil-teacher ratio by town.\n",
    "12. 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
    "13. % lower status of the population.\n",
    "\n",
    "The targets are the median values of owner-occupied homes, in thousands of dollars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prices are typically between $10,000  -  $50,000. If that sounds cheap, remember this was the mid-1970s, and these prices are not inflation-adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preparing the data\n",
    "\n",
    "It would be problematic to feed into a neural network values that all take wildly different ranges. The network might be able to \n",
    "automatically adapt to such heterogeneous data, but it would definitely make learning more difficult. A widespread best practice to deal with such data is to do feature-wise normalization: for each feature in the input data (a column in the input data matrix), we will subtract the mean of the feature and divide by the standard deviation, so that the feature will be centered around 0 and will have a unit standard deviation. This is easily done in Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the quantities that we use for normalizing the test data have been computed using the training data. We should never use in our workflow any quantity computed on the test data, even for something as simple as data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39914449  0.35890566 -1.14281587  3.89358447 -0.97702129  1.9437178\n",
      " -0.69198737  0.72576261 -0.51114231 -1.1428069  -1.62718308  0.23710757\n",
      " -1.34300395]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Building our network\n",
    "\n",
    "\n",
    "Because so few samples are available, we will be using a very small network with two \n",
    "hidden layers, each with 64 units. In general, the less training data you have, the worse overfitting will be, and using \n",
    "a small network is one way to mitigate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu',\n",
    "                        input_shape=(train_data.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network ends with a single unit, and no activation (i.e. linear layer). This is a typical setup for scalar regression. Because the last layer is purely linear, the network is free to learn to predict values in any range.\n",
    "\n",
    "Note that we are compiling the network with the `mse` loss function -- Mean Squared Error, the square of the difference between the predictions and the targets, a widely used loss function for regression problems.\n",
    "\n",
    "We are also monitoring a new metric during training: `mae`. This stands for Mean Absolute Error. It is simply the absolute value of the difference between the predictions and the targets. For instance, a MAE of 0.5 on this problem would mean that our predictions are off by \n",
    "\\$500 on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/200\n",
      "323/323 [==============================] - 2s 5ms/sample - loss: 185.8138 - mae: 10.0061 - val_loss: 63.0468 - val_mae: 5.2112\n",
      "Epoch 2/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 33.4197 - mae: 3.7243 - val_loss: 35.4351 - val_mae: 3.8716\n",
      "Epoch 3/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 24.2874 - mae: 3.1867 - val_loss: 24.5178 - val_mae: 3.3199\n",
      "Epoch 4/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 19.9873 - mae: 2.8635 - val_loss: 26.5748 - val_mae: 3.4881\n",
      "Epoch 5/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 17.9527 - mae: 2.5980 - val_loss: 19.7638 - val_mae: 2.9730\n",
      "Epoch 6/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 15.6116 - mae: 2.5304 - val_loss: 14.7837 - val_mae: 2.6793\n",
      "Epoch 7/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 14.5627 - mae: 2.4011 - val_loss: 15.2116 - val_mae: 2.7706\n",
      "Epoch 8/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 13.1259 - mae: 2.3414 - val_loss: 13.6428 - val_mae: 2.8358\n",
      "Epoch 9/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 12.7672 - mae: 2.3073 - val_loss: 12.3850 - val_mae: 2.6169\n",
      "Epoch 10/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 11.4516 - mae: 2.2222 - val_loss: 15.0778 - val_mae: 3.0439\n",
      "Epoch 11/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 11.8658 - mae: 2.2227 - val_loss: 11.5851 - val_mae: 2.5477\n",
      "Epoch 12/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.9395 - mae: 2.2163 - val_loss: 12.3814 - val_mae: 2.7472\n",
      "Epoch 13/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.4415 - mae: 2.1591 - val_loss: 10.7821 - val_mae: 2.5409\n",
      "Epoch 14/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.4614 - mae: 2.1279 - val_loss: 10.6278 - val_mae: 2.5597\n",
      "Epoch 15/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.0827 - mae: 2.1356 - val_loss: 10.4365 - val_mae: 2.5551\n",
      "Epoch 16/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.0777 - mae: 2.0506 - val_loss: 10.6648 - val_mae: 2.4451\n",
      "Epoch 17/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.1326 - mae: 2.0919 - val_loss: 11.4321 - val_mae: 2.6239\n",
      "Epoch 18/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 9.4144 - mae: 1.9859 - val_loss: 10.2423 - val_mae: 2.4797\n",
      "Epoch 19/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 9.5939 - mae: 2.0161 - val_loss: 11.1479 - val_mae: 2.4697\n",
      "Epoch 20/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.2275 - mae: 1.9059 - val_loss: 11.3188 - val_mae: 2.5756\n",
      "Epoch 21/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 9.3100 - mae: 1.9435 - val_loss: 12.2373 - val_mae: 2.5277\n",
      "Epoch 22/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.7711 - mae: 1.9396 - val_loss: 12.7052 - val_mae: 2.6333\n",
      "Epoch 23/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.3276 - mae: 1.9331 - val_loss: 13.2434 - val_mae: 2.5484\n",
      "Epoch 24/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.5035 - mae: 1.9078 - val_loss: 12.1446 - val_mae: 2.5412\n",
      "Epoch 25/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.6760 - mae: 1.8814 - val_loss: 12.6609 - val_mae: 2.5382\n",
      "Epoch 26/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.9571 - mae: 1.8786 - val_loss: 11.3526 - val_mae: 2.6003\n",
      "Epoch 27/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.3775 - mae: 1.8507 - val_loss: 11.1398 - val_mae: 2.5072\n",
      "Epoch 28/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.1321 - mae: 1.8837 - val_loss: 11.9869 - val_mae: 2.6251\n",
      "Epoch 29/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.0196 - mae: 1.8195 - val_loss: 12.0588 - val_mae: 2.6343\n",
      "Epoch 30/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.9338 - mae: 1.8224 - val_loss: 12.0876 - val_mae: 2.5568\n",
      "Epoch 31/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.6974 - mae: 1.8667 - val_loss: 11.8326 - val_mae: 2.5462\n",
      "Epoch 32/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.6946 - mae: 1.7998 - val_loss: 12.0449 - val_mae: 2.6495\n",
      "Epoch 33/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.4738 - mae: 1.8275 - val_loss: 12.0792 - val_mae: 2.6623\n",
      "Epoch 34/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.8196 - mae: 1.8010 - val_loss: 11.8758 - val_mae: 2.6543\n",
      "Epoch 35/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.1970 - mae: 1.8164 - val_loss: 12.2101 - val_mae: 2.5544\n",
      "Epoch 36/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.0236 - mae: 1.7319 - val_loss: 12.1320 - val_mae: 2.5024\n",
      "Epoch 37/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.2600 - mae: 1.7802 - val_loss: 13.3777 - val_mae: 2.7361\n",
      "Epoch 38/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.7852 - mae: 1.7594 - val_loss: 11.7511 - val_mae: 2.5306\n",
      "Epoch 39/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.0658 - mae: 1.7237 - val_loss: 11.9789 - val_mae: 2.4911\n",
      "Epoch 40/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.0776 - mae: 1.7545 - val_loss: 12.8136 - val_mae: 2.6935\n",
      "Epoch 41/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.9463 - mae: 1.7384 - val_loss: 12.8751 - val_mae: 2.5667\n",
      "Epoch 42/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.7004 - mae: 1.6770 - val_loss: 11.4616 - val_mae: 2.4371\n",
      "Epoch 43/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.9275 - mae: 1.6988 - val_loss: 10.8743 - val_mae: 2.3821\n",
      "Epoch 44/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.6339 - mae: 1.6836 - val_loss: 11.4565 - val_mae: 2.3819\n",
      "Epoch 45/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.7368 - mae: 1.6987 - val_loss: 10.8080 - val_mae: 2.4292\n",
      "Epoch 46/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.3908 - mae: 1.6818 - val_loss: 12.4395 - val_mae: 2.4495\n",
      "Epoch 47/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.5328 - mae: 1.6498 - val_loss: 11.5190 - val_mae: 2.3680\n",
      "Epoch 48/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.2278 - mae: 1.6522 - val_loss: 13.8054 - val_mae: 2.5826\n",
      "Epoch 49/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.5207 - mae: 1.6385 - val_loss: 11.8088 - val_mae: 2.4767\n",
      "Epoch 50/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.1937 - mae: 1.6359 - val_loss: 11.8394 - val_mae: 2.4285\n",
      "Epoch 51/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.3235 - mae: 1.6504 - val_loss: 12.1020 - val_mae: 2.3251\n",
      "Epoch 52/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.1634 - mae: 1.6418 - val_loss: 13.4616 - val_mae: 2.5287\n",
      "Epoch 53/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.0450 - mae: 1.6492 - val_loss: 12.4751 - val_mae: 2.4520\n",
      "Epoch 54/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.2056 - mae: 1.6068 - val_loss: 12.7584 - val_mae: 2.4285\n",
      "Epoch 55/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.4852 - mae: 1.6280 - val_loss: 15.2539 - val_mae: 2.5838\n",
      "Epoch 56/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.9834 - mae: 1.5868 - val_loss: 12.6780 - val_mae: 2.6459\n",
      "Epoch 57/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.4109 - mae: 1.6078 - val_loss: 12.7632 - val_mae: 2.4460\n",
      "Epoch 58/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.8508 - mae: 1.5411 - val_loss: 11.7489 - val_mae: 2.4409\n",
      "Epoch 59/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.0781 - mae: 1.5450 - val_loss: 14.4799 - val_mae: 2.8355\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.0156 - mae: 1.5211 - val_loss: 13.2219 - val_mae: 2.6174\n",
      "Epoch 61/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.5484 - mae: 1.5588 - val_loss: 12.5934 - val_mae: 2.5566\n",
      "Epoch 62/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.3977 - mae: 1.5429 - val_loss: 14.1217 - val_mae: 2.5953\n",
      "Epoch 63/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.3479 - mae: 1.5288 - val_loss: 15.4798 - val_mae: 2.6115\n",
      "Epoch 64/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.7578 - mae: 1.5397 - val_loss: 13.9930 - val_mae: 2.4162\n",
      "Epoch 65/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.6716 - mae: 1.5482 - val_loss: 13.3326 - val_mae: 2.4459\n",
      "Epoch 66/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.5616 - mae: 1.5354 - val_loss: 11.5060 - val_mae: 2.4101\n",
      "Epoch 67/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.4130 - mae: 1.5534 - val_loss: 11.9137 - val_mae: 2.5472\n",
      "Epoch 68/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.5580 - mae: 1.5324 - val_loss: 17.0059 - val_mae: 2.7718\n",
      "Epoch 69/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.6656 - mae: 1.5273 - val_loss: 14.1866 - val_mae: 2.6342\n",
      "Epoch 70/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.6724 - mae: 1.5162 - val_loss: 14.0212 - val_mae: 2.5112\n",
      "Epoch 71/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.3725 - mae: 1.4958 - val_loss: 12.4993 - val_mae: 2.5297\n",
      "Epoch 72/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.3432 - mae: 1.5062 - val_loss: 13.0091 - val_mae: 2.5328\n",
      "Epoch 73/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.3019 - mae: 1.5325 - val_loss: 13.0068 - val_mae: 2.4209\n",
      "Epoch 74/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.2071 - mae: 1.4960 - val_loss: 13.1275 - val_mae: 2.4458\n",
      "Epoch 75/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.0920 - mae: 1.4517 - val_loss: 14.8624 - val_mae: 2.5102\n",
      "Epoch 76/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.1287 - mae: 1.4863 - val_loss: 13.3242 - val_mae: 2.4849\n",
      "Epoch 77/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.1440 - mae: 1.5208 - val_loss: 17.6025 - val_mae: 2.8065\n",
      "Epoch 78/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.3056 - mae: 1.4981 - val_loss: 13.6653 - val_mae: 2.5411\n",
      "Epoch 79/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.3954 - mae: 1.5090 - val_loss: 16.3054 - val_mae: 3.0044\n",
      "Epoch 80/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.2577 - mae: 1.4722 - val_loss: 14.8998 - val_mae: 2.6839\n",
      "Epoch 81/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.2707 - mae: 1.5340 - val_loss: 16.1560 - val_mae: 2.6366\n",
      "Epoch 82/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.9305 - mae: 1.5285 - val_loss: 15.1953 - val_mae: 2.7852\n",
      "Epoch 83/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.6639 - mae: 1.4379 - val_loss: 13.9233 - val_mae: 2.5356\n",
      "Epoch 84/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.4388 - mae: 1.4017 - val_loss: 12.3980 - val_mae: 2.3887\n",
      "Epoch 85/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.2099 - mae: 1.4726 - val_loss: 19.8510 - val_mae: 2.9415\n",
      "Epoch 86/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.9661 - mae: 1.4766 - val_loss: 12.0169 - val_mae: 2.3943\n",
      "Epoch 87/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.0094 - mae: 1.4326 - val_loss: 13.5572 - val_mae: 2.5078\n",
      "Epoch 88/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.2693 - mae: 1.4441 - val_loss: 12.5782 - val_mae: 2.4523\n",
      "Epoch 89/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.7503 - mae: 1.3897 - val_loss: 15.0058 - val_mae: 2.5548\n",
      "Epoch 90/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.5999 - mae: 1.4296 - val_loss: 13.1195 - val_mae: 2.4819\n",
      "Epoch 91/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.8452 - mae: 1.4069 - val_loss: 15.2915 - val_mae: 2.5647\n",
      "Epoch 92/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.0532 - mae: 1.4432 - val_loss: 14.1291 - val_mae: 2.5060\n",
      "Epoch 93/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.9067 - mae: 1.4118 - val_loss: 14.3116 - val_mae: 2.4798\n",
      "Epoch 94/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.4334 - mae: 1.3971 - val_loss: 13.6722 - val_mae: 2.4272\n",
      "Epoch 95/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.4316 - mae: 1.4323 - val_loss: 16.4067 - val_mae: 2.9590\n",
      "Epoch 96/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.8312 - mae: 1.3809 - val_loss: 13.6530 - val_mae: 2.3792\n",
      "Epoch 97/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.7164 - mae: 1.4077 - val_loss: 15.6395 - val_mae: 2.5777\n",
      "Epoch 98/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.5450 - mae: 1.4083 - val_loss: 13.9661 - val_mae: 2.5672\n",
      "Epoch 99/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.5104 - mae: 1.3783 - val_loss: 12.5080 - val_mae: 2.5746\n",
      "Epoch 100/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.6731 - mae: 1.3992 - val_loss: 15.1062 - val_mae: 2.5648\n",
      "Epoch 101/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.5329 - mae: 1.3765 - val_loss: 13.4998 - val_mae: 2.4452\n",
      "Epoch 102/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.5755 - mae: 1.3613 - val_loss: 13.9654 - val_mae: 2.4721\n",
      "Epoch 103/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.6204 - mae: 1.3768 - val_loss: 15.5611 - val_mae: 2.5022\n",
      "Epoch 104/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.2712 - mae: 1.3897 - val_loss: 13.4179 - val_mae: 2.4075\n",
      "Epoch 105/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.8366 - mae: 1.4141 - val_loss: 15.9261 - val_mae: 2.7617\n",
      "Epoch 106/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.3337 - mae: 1.3742 - val_loss: 12.5520 - val_mae: 2.3828\n",
      "Epoch 107/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.8088 - mae: 1.3954 - val_loss: 12.2002 - val_mae: 2.3671\n",
      "Epoch 108/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.7549 - mae: 1.3684 - val_loss: 14.0571 - val_mae: 2.5089\n",
      "Epoch 109/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.0956 - mae: 1.3561 - val_loss: 11.8554 - val_mae: 2.3044\n",
      "Epoch 110/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.1727 - mae: 1.2984 - val_loss: 13.8513 - val_mae: 2.4633\n",
      "Epoch 111/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.3395 - mae: 1.3616 - val_loss: 12.2727 - val_mae: 2.4121\n",
      "Epoch 112/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.3658 - mae: 1.3318 - val_loss: 14.2197 - val_mae: 2.5940\n",
      "Epoch 113/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.1630 - mae: 1.3566 - val_loss: 11.9931 - val_mae: 2.3310\n",
      "Epoch 114/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.1422 - mae: 1.3496 - val_loss: 14.8331 - val_mae: 2.4762\n",
      "Epoch 115/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.0628 - mae: 1.3249 - val_loss: 14.5817 - val_mae: 2.3632\n",
      "Epoch 116/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.0234 - mae: 1.3503 - val_loss: 13.8785 - val_mae: 2.4842\n",
      "Epoch 117/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.0014 - mae: 1.3579 - val_loss: 13.8297 - val_mae: 2.3412\n",
      "Epoch 118/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.9695 - mae: 1.3685 - val_loss: 12.4430 - val_mae: 2.3601\n",
      "Epoch 119/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.0974 - mae: 1.3154 - val_loss: 12.0549 - val_mae: 2.4370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.0552 - mae: 1.3590 - val_loss: 14.9735 - val_mae: 2.5470\n",
      "Epoch 121/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.0135 - mae: 1.3288 - val_loss: 13.9195 - val_mae: 2.4696\n",
      "Epoch 122/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.9517 - mae: 1.3160 - val_loss: 14.2873 - val_mae: 2.6039\n",
      "Epoch 123/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5832 - mae: 1.2666 - val_loss: 12.8807 - val_mae: 2.4758\n",
      "Epoch 124/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.0971 - mae: 1.3048 - val_loss: 15.4715 - val_mae: 2.7754\n",
      "Epoch 125/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5400 - mae: 1.2589 - val_loss: 18.6562 - val_mae: 2.8158\n",
      "Epoch 126/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5997 - mae: 1.2541 - val_loss: 12.9980 - val_mae: 2.4068\n",
      "Epoch 127/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.6321 - mae: 1.2519 - val_loss: 15.3988 - val_mae: 2.5210\n",
      "Epoch 128/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.8152 - mae: 1.2840 - val_loss: 16.0881 - val_mae: 2.7490\n",
      "Epoch 129/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.6487 - mae: 1.2312 - val_loss: 12.1912 - val_mae: 2.4482\n",
      "Epoch 130/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.8854 - mae: 1.2959 - val_loss: 13.3208 - val_mae: 2.3991\n",
      "Epoch 131/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.8742 - mae: 1.3123 - val_loss: 12.8804 - val_mae: 2.4084\n",
      "Epoch 132/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.7613 - mae: 1.2670 - val_loss: 15.5433 - val_mae: 2.7710\n",
      "Epoch 133/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.9104 - mae: 1.2414 - val_loss: 11.9317 - val_mae: 2.3255\n",
      "Epoch 134/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.6368 - mae: 1.2255 - val_loss: 12.2637 - val_mae: 2.4654\n",
      "Epoch 135/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.6531 - mae: 1.2652 - val_loss: 12.8892 - val_mae: 2.3676\n",
      "Epoch 136/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.9466 - mae: 1.2758 - val_loss: 13.7315 - val_mae: 2.3961\n",
      "Epoch 137/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.7255 - mae: 1.2865 - val_loss: 13.2581 - val_mae: 2.4094\n",
      "Epoch 138/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.7021 - mae: 1.2411 - val_loss: 10.8798 - val_mae: 2.2645\n",
      "Epoch 139/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.3833 - mae: 1.2896 - val_loss: 12.3687 - val_mae: 2.5382\n",
      "Epoch 140/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.4964 - mae: 1.2397 - val_loss: 12.9782 - val_mae: 2.4772\n",
      "Epoch 141/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.6547 - mae: 1.2428 - val_loss: 12.9539 - val_mae: 2.5042\n",
      "Epoch 142/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5869 - mae: 1.2325 - val_loss: 14.5695 - val_mae: 2.4485\n",
      "Epoch 143/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5674 - mae: 1.2639 - val_loss: 16.9135 - val_mae: 2.6335\n",
      "Epoch 144/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.7931 - mae: 1.2551 - val_loss: 14.0293 - val_mae: 2.5452\n",
      "Epoch 145/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.6658 - mae: 1.2645 - val_loss: 16.2474 - val_mae: 2.6935\n",
      "Epoch 146/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5302 - mae: 1.2233 - val_loss: 14.8929 - val_mae: 2.4052\n",
      "Epoch 147/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.7437 - mae: 1.2260 - val_loss: 15.9332 - val_mae: 2.7263\n",
      "Epoch 148/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.2194 - mae: 1.2169 - val_loss: 16.3811 - val_mae: 2.7471\n",
      "Epoch 149/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5463 - mae: 1.1965 - val_loss: 14.4485 - val_mae: 2.4714\n",
      "Epoch 150/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.4386 - mae: 1.2358 - val_loss: 14.5217 - val_mae: 2.5108\n",
      "Epoch 151/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.0487 - mae: 1.1981 - val_loss: 14.8806 - val_mae: 2.5063\n",
      "Epoch 152/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.3397 - mae: 1.1956 - val_loss: 16.5853 - val_mae: 2.7327\n",
      "Epoch 153/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.4268 - mae: 1.2085 - val_loss: 16.4336 - val_mae: 2.5631\n",
      "Epoch 154/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.2142 - mae: 1.2126 - val_loss: 13.0353 - val_mae: 2.5308\n",
      "Epoch 155/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.4104 - mae: 1.1907 - val_loss: 14.4947 - val_mae: 2.3629\n",
      "Epoch 156/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.1877 - mae: 1.2098 - val_loss: 17.9926 - val_mae: 2.6359\n",
      "Epoch 157/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.3456 - mae: 1.2244 - val_loss: 14.5448 - val_mae: 2.5300\n",
      "Epoch 158/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.6025 - mae: 1.2174 - val_loss: 13.5733 - val_mae: 2.4382\n",
      "Epoch 159/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.3534 - mae: 1.1830 - val_loss: 15.1667 - val_mae: 2.5732\n",
      "Epoch 160/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5083 - mae: 1.2055 - val_loss: 15.7161 - val_mae: 2.6260\n",
      "Epoch 161/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.2446 - mae: 1.2316 - val_loss: 15.6409 - val_mae: 2.7335\n",
      "Epoch 162/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5169 - mae: 1.2015 - val_loss: 17.1510 - val_mae: 2.6267\n",
      "Epoch 163/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.3437 - mae: 1.2235 - val_loss: 16.4880 - val_mae: 2.5907\n",
      "Epoch 164/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.1297 - mae: 1.1732 - val_loss: 16.2695 - val_mae: 2.9070\n",
      "Epoch 165/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.3148 - mae: 1.2108 - val_loss: 14.7225 - val_mae: 2.4847\n",
      "Epoch 166/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8654 - mae: 1.1111 - val_loss: 20.6203 - val_mae: 3.1964\n",
      "Epoch 167/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.3184 - mae: 1.2137 - val_loss: 16.3168 - val_mae: 2.8056\n",
      "Epoch 168/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.1331 - mae: 1.1638 - val_loss: 16.4525 - val_mae: 2.6246\n",
      "Epoch 169/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.1972 - mae: 1.2070 - val_loss: 14.8811 - val_mae: 2.5596\n",
      "Epoch 170/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.0779 - mae: 1.1506 - val_loss: 14.9359 - val_mae: 2.8124\n",
      "Epoch 171/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.0368 - mae: 1.1654 - val_loss: 15.6490 - val_mae: 2.5072\n",
      "Epoch 172/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6951 - mae: 1.1706 - val_loss: 13.9754 - val_mae: 2.4747\n",
      "Epoch 173/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9601 - mae: 1.1701 - val_loss: 13.9872 - val_mae: 2.6114\n",
      "Epoch 174/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.0852 - mae: 1.1795 - val_loss: 15.1489 - val_mae: 2.4609\n",
      "Epoch 175/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.3466 - mae: 1.1778 - val_loss: 15.6097 - val_mae: 2.5003\n",
      "Epoch 176/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.1544 - mae: 1.1484 - val_loss: 13.4147 - val_mae: 2.4748\n",
      "Epoch 177/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.1568 - mae: 1.1627 - val_loss: 19.7470 - val_mae: 2.7908\n",
      "Epoch 178/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.0110 - mae: 1.1590 - val_loss: 15.0078 - val_mae: 2.5341\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.2038 - mae: 1.1256 - val_loss: 14.5724 - val_mae: 2.5150\n",
      "Epoch 180/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9875 - mae: 1.1277 - val_loss: 16.7556 - val_mae: 2.8360\n",
      "Epoch 181/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8519 - mae: 1.1459 - val_loss: 15.6606 - val_mae: 2.7058\n",
      "Epoch 182/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7947 - mae: 1.1633 - val_loss: 15.8943 - val_mae: 2.5924\n",
      "Epoch 183/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9047 - mae: 1.1084 - val_loss: 16.2076 - val_mae: 2.6843\n",
      "Epoch 184/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9293 - mae: 1.1697 - val_loss: 13.8833 - val_mae: 2.5975\n",
      "Epoch 185/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8420 - mae: 1.1733 - val_loss: 14.5332 - val_mae: 2.5259\n",
      "Epoch 186/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8137 - mae: 1.1100 - val_loss: 15.5697 - val_mae: 2.6392\n",
      "Epoch 187/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.1354 - mae: 1.2001 - val_loss: 15.3336 - val_mae: 2.4642\n",
      "Epoch 188/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8749 - mae: 1.1590 - val_loss: 12.3125 - val_mae: 2.4508\n",
      "Epoch 189/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8383 - mae: 1.1309 - val_loss: 15.6940 - val_mae: 2.5636\n",
      "Epoch 190/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8264 - mae: 1.1548 - val_loss: 12.6562 - val_mae: 2.4844\n",
      "Epoch 191/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7101 - mae: 1.1232 - val_loss: 15.2690 - val_mae: 2.5422\n",
      "Epoch 192/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7116 - mae: 1.1113 - val_loss: 15.8770 - val_mae: 2.6727\n",
      "Epoch 193/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7162 - mae: 1.1277 - val_loss: 14.4931 - val_mae: 2.5910\n",
      "Epoch 194/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.5754 - mae: 1.0931 - val_loss: 12.5165 - val_mae: 2.4035\n",
      "Epoch 195/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7850 - mae: 1.1759 - val_loss: 15.6312 - val_mae: 2.6460\n",
      "Epoch 196/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9901 - mae: 1.1636 - val_loss: 13.7863 - val_mae: 2.4831\n",
      "Epoch 197/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6217 - mae: 1.1118 - val_loss: 13.7984 - val_mae: 2.4652\n",
      "Epoch 198/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9437 - mae: 1.1429 - val_loss: 13.8811 - val_mae: 2.4567\n",
      "Epoch 199/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7275 - mae: 1.1439 - val_loss: 12.7851 - val_mae: 2.3744\n",
      "Epoch 200/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.4805 - mae: 1.0652 - val_loss: 16.9272 - val_mae: 2.6082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23b9bf321c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_targets, validation_split =0.2, epochs = 200, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model very quickly overfits to the training data, so we should stop it before it overfits. Now the question is when to stop? We will use K-fold validation to figure out in the next secsion.  \n",
    "\n",
    "Because you'll need to instantiate the same model multiple times, you use a function to construct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Validating our approach using K-fold validation\n",
    "\n",
    "To evaluate our network while we keep adjusting its parameters (e.g. the number of epochs), we use K-fold cross-validation because we have so few data points. It splits the data into K partitions, then instantiating K identical models, and training each one on K-1 partitions while evaluating on the remaining partition. The validation score for the model used would then be the average of the K validation scores obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "# Some memory clean-up\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 215.4052 - mae: 10.9107 - val_loss: 32.8363 - val_mae: 3.3708\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 26.0013 - mae: 3.5231 - val_loss: 23.2790 - val_mae: 2.6427\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 19.1027 - mae: 2.9794 - val_loss: 18.6542 - val_mae: 2.6171\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 16.2505 - mae: 2.7407 - val_loss: 15.8958 - val_mae: 2.2113\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.6994 - mae: 2.5341 - val_loss: 15.1762 - val_mae: 2.6344\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.7301 - mae: 2.4285 - val_loss: 14.9981 - val_mae: 2.2630\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.2631 - mae: 2.4173 - val_loss: 12.8174 - val_mae: 2.1023\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.2844 - mae: 2.3374 - val_loss: 12.4249 - val_mae: 2.0309\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.2302 - mae: 2.3048 - val_loss: 12.4626 - val_mae: 2.3251\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.6063 - mae: 2.2537 - val_loss: 11.8061 - val_mae: 2.4730\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.3629 - mae: 2.3016 - val_loss: 11.1446 - val_mae: 2.0551\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.8587 - mae: 2.2205 - val_loss: 12.4716 - val_mae: 2.0368\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.2826 - mae: 2.1530 - val_loss: 11.0596 - val_mae: 1.9464\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.5437 - mae: 2.1755 - val_loss: 10.1191 - val_mae: 1.9994\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.4786 - mae: 2.0998 - val_loss: 10.2953 - val_mae: 2.2598\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.9302 - mae: 2.0879 - val_loss: 9.9921 - val_mae: 2.0398\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.7268 - mae: 2.1336 - val_loss: 9.9591 - val_mae: 2.1932\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.6276 - mae: 2.1047 - val_loss: 10.7903 - val_mae: 1.8892\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.6361 - mae: 2.0598 - val_loss: 9.5494 - val_mae: 1.7989\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4461 - mae: 2.0624 - val_loss: 9.1770 - val_mae: 1.9863\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.1833 - mae: 2.0142 - val_loss: 9.7107 - val_mae: 2.3444\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.2531 - mae: 1.9624 - val_loss: 8.3112 - val_mae: 1.8841\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.0809 - mae: 1.9798 - val_loss: 9.3944 - val_mae: 1.9010\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.9487 - mae: 1.9717 - val_loss: 9.3924 - val_mae: 1.8660\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.7209 - mae: 1.9476 - val_loss: 10.2502 - val_mae: 1.8906\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.8633 - mae: 1.9308 - val_loss: 9.5068 - val_mae: 2.0442\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.7852 - mae: 1.9497 - val_loss: 9.6339 - val_mae: 1.7942\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2003 - mae: 1.9326 - val_loss: 8.3603 - val_mae: 1.7849\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.3921 - mae: 1.8748 - val_loss: 8.1483 - val_mae: 1.7272\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7697 - mae: 1.8640 - val_loss: 7.9935 - val_mae: 1.8425\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.3846 - mae: 1.8793 - val_loss: 8.5444 - val_mae: 1.9311\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8029 - mae: 1.8784 - val_loss: 8.6997 - val_mae: 1.9893\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.0194 - mae: 1.8950 - val_loss: 8.1273 - val_mae: 1.8941\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8174 - mae: 1.8947 - val_loss: 7.7448 - val_mae: 1.7969\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8192 - mae: 1.7716 - val_loss: 7.7090 - val_mae: 1.6761\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8822 - mae: 1.8538 - val_loss: 8.0540 - val_mae: 1.8417\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1966 - mae: 1.7284 - val_loss: 7.3931 - val_mae: 1.7206\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.4283 - mae: 1.8133 - val_loss: 7.5568 - val_mae: 1.7853\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0498 - mae: 1.7936 - val_loss: 8.4742 - val_mae: 2.2430\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5146 - mae: 1.7985 - val_loss: 7.4016 - val_mae: 1.7335\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7547 - mae: 1.7320 - val_loss: 7.4175 - val_mae: 1.7100\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5049 - mae: 1.6914 - val_loss: 8.2892 - val_mae: 2.1462\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2472 - mae: 1.8072 - val_loss: 7.2417 - val_mae: 1.6410\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9620 - mae: 1.6985 - val_loss: 7.6836 - val_mae: 1.9839\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5248 - mae: 1.6969 - val_loss: 7.6246 - val_mae: 1.6961\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8090 - mae: 1.7080 - val_loss: 7.6778 - val_mae: 1.8241\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7416 - mae: 1.7436 - val_loss: 7.2175 - val_mae: 1.6105\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5854 - mae: 1.6509 - val_loss: 7.6435 - val_mae: 1.6546\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4045 - mae: 1.6422 - val_loss: 6.9197 - val_mae: 1.7597\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1902 - mae: 1.6424 - val_loss: 7.3822 - val_mae: 1.9217\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2971 - mae: 1.6955 - val_loss: 7.4455 - val_mae: 1.6126\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9652 - mae: 1.6898 - val_loss: 7.9485 - val_mae: 1.7475\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4426 - mae: 1.6635 - val_loss: 6.7822 - val_mae: 1.5807\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0199 - mae: 1.6380 - val_loss: 7.6578 - val_mae: 1.6422\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6594 - mae: 1.5481 - val_loss: 8.5832 - val_mae: 2.0543\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2498 - mae: 1.6771 - val_loss: 7.4569 - val_mae: 1.9139\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7939 - mae: 1.6100 - val_loss: 7.2905 - val_mae: 1.8884\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0770 - mae: 1.5915 - val_loss: 7.3532 - val_mae: 1.8231\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7552 - mae: 1.5943 - val_loss: 6.7938 - val_mae: 1.6339\n",
      "Epoch 60/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4792 - mae: 1.5072 - val_loss: 7.1090 - val_mae: 1.6855\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8639 - mae: 1.5813 - val_loss: 8.2065 - val_mae: 1.9142\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7615 - mae: 1.6091 - val_loss: 6.5130 - val_mae: 1.6831\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6739 - mae: 1.5811 - val_loss: 6.2355 - val_mae: 1.6321\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2711 - mae: 1.5104 - val_loss: 6.9857 - val_mae: 1.7012\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4774 - mae: 1.5995 - val_loss: 7.6351 - val_mae: 1.7045\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0937 - mae: 1.5527 - val_loss: 7.0611 - val_mae: 1.9415\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5929 - mae: 1.5126 - val_loss: 6.3805 - val_mae: 1.7644\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4260 - mae: 1.5544 - val_loss: 6.2875 - val_mae: 1.7243\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2515 - mae: 1.5597 - val_loss: 7.1395 - val_mae: 1.6729\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3826 - mae: 1.5323 - val_loss: 6.0188 - val_mae: 1.5921\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3730 - mae: 1.5653 - val_loss: 6.8060 - val_mae: 1.7876\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4377 - mae: 1.5318 - val_loss: 8.3026 - val_mae: 1.9490\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1824 - mae: 1.4544 - val_loss: 6.9290 - val_mae: 1.8741\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0661 - mae: 1.5080 - val_loss: 8.5078 - val_mae: 1.8454\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.0291 - mae: 1.4864 - val_loss: 6.6290 - val_mae: 1.6951\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3797 - mae: 1.5403 - val_loss: 6.2906 - val_mae: 1.6708\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8626 - mae: 1.4080 - val_loss: 5.9326 - val_mae: 1.5572\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0241 - mae: 1.4602 - val_loss: 7.3630 - val_mae: 1.7487\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7534 - mae: 1.3989 - val_loss: 11.7324 - val_mae: 2.3051\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7646 - mae: 1.4864 - val_loss: 7.9708 - val_mae: 2.1327\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8946 - mae: 1.3888 - val_loss: 7.5397 - val_mae: 1.8503\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6144 - mae: 1.4117 - val_loss: 9.4212 - val_mae: 2.0342\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7349 - mae: 1.4230 - val_loss: 6.4149 - val_mae: 1.7444\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7203 - mae: 1.4261 - val_loss: 6.8062 - val_mae: 1.6657\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2890 - mae: 1.4241 - val_loss: 14.5232 - val_mae: 2.9106\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1519 - mae: 1.4491 - val_loss: 7.2511 - val_mae: 1.7323\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3493 - mae: 1.3609 - val_loss: 8.8695 - val_mae: 2.0166\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7607 - mae: 1.3792 - val_loss: 6.5156 - val_mae: 1.7444\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7589 - mae: 1.4268 - val_loss: 9.0761 - val_mae: 2.1020\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7274 - mae: 1.3624 - val_loss: 7.7534 - val_mae: 1.8725\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9097 - mae: 1.3978 - val_loss: 6.8903 - val_mae: 1.6380\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6836 - mae: 1.3546 - val_loss: 7.6955 - val_mae: 2.0472\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6845 - mae: 1.3228 - val_loss: 6.8553 - val_mae: 1.7620\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8707 - mae: 1.3350 - val_loss: 6.3489 - val_mae: 1.7473\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 4.6793 - mae: 1.402 - 1s 2ms/sample - loss: 4.7580 - mae: 1.4273 - val_loss: 8.2489 - val_mae: 2.0388\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6253 - mae: 1.3785 - val_loss: 6.7504 - val_mae: 1.7950\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.2291 - mae: 1.3564 - val_loss: 7.3514 - val_mae: 1.9012\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0844 - mae: 1.3563 - val_loss: 6.0717 - val_mae: 1.7242\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1135 - mae: 1.3421 - val_loss: 6.6210 - val_mae: 1.6966\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9631 - mae: 1.3484 - val_loss: 6.9369 - val_mae: 1.7420\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1390 - mae: 1.3908 - val_loss: 7.0412 - val_mae: 1.7450\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9249 - mae: 1.3684 - val_loss: 6.7256 - val_mae: 1.8980\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1250 - mae: 1.3755 - val_loss: 7.7633 - val_mae: 1.8702\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0621 - mae: 1.3588 - val_loss: 8.7118 - val_mae: 2.2280\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4300 - mae: 1.3559 - val_loss: 7.7627 - val_mae: 1.9239\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7556 - mae: 1.3020 - val_loss: 7.5676 - val_mae: 2.0528\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0279 - mae: 1.3046 - val_loss: 7.5581 - val_mae: 1.8949\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8429 - mae: 1.3292 - val_loss: 7.7209 - val_mae: 1.9880\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9045 - mae: 1.3165 - val_loss: 6.5247 - val_mae: 1.8560\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0983 - mae: 1.3262 - val_loss: 6.5383 - val_mae: 1.7204\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9142 - mae: 1.3197 - val_loss: 6.4455 - val_mae: 1.7670\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0588 - mae: 1.3510 - val_loss: 7.1719 - val_mae: 1.9529\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4739 - mae: 1.2766 - val_loss: 6.5022 - val_mae: 1.7795\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8563 - mae: 1.3763 - val_loss: 6.6786 - val_mae: 1.8439\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9047 - mae: 1.3011 - val_loss: 6.2743 - val_mae: 1.8509\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8556 - mae: 1.3169 - val_loss: 7.1155 - val_mae: 1.9900\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7518 - mae: 1.3119 - val_loss: 5.7580 - val_mae: 1.6937\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4979 - mae: 1.2429 - val_loss: 6.8812 - val_mae: 1.9403\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5355 - mae: 1.2683 - val_loss: 7.3461 - val_mae: 2.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6918 - mae: 1.3111 - val_loss: 6.5463 - val_mae: 1.7423\n",
      "processing fold # 1\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 186.1788 - mae: 10.2123 - val_loss: 30.4846 - val_mae: 4.2462\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 26.1353 - mae: 3.3119 - val_loss: 21.4634 - val_mae: 3.4924\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 18.3438 - mae: 2.8058 - val_loss: 17.8568 - val_mae: 3.2887\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.1245 - mae: 2.5272 - val_loss: 19.3187 - val_mae: 3.3973\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.6579 - mae: 2.4285 - val_loss: 13.1145 - val_mae: 2.8388\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.5064 - mae: 2.3620 - val_loss: 14.8781 - val_mae: 2.9726\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.5948 - mae: 2.2720 - val_loss: 14.4158 - val_mae: 2.9561\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.6345 - mae: 2.1998 - val_loss: 12.4117 - val_mae: 2.7776\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.5375 - mae: 2.1755 - val_loss: 11.0939 - val_mae: 2.6082\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.8280 - mae: 2.1775 - val_loss: 13.3812 - val_mae: 2.7959\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.9264 - mae: 2.0905 - val_loss: 12.0171 - val_mae: 2.6752\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.7352 - mae: 2.0863 - val_loss: 12.9169 - val_mae: 2.7996\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.6611 - mae: 2.1193 - val_loss: 10.8860 - val_mae: 2.5162\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.0191 - mae: 2.0529 - val_loss: 12.0046 - val_mae: 2.6944\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.9901 - mae: 2.0207 - val_loss: 10.2094 - val_mae: 2.4501\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.9126 - mae: 2.0174 - val_loss: 14.4339 - val_mae: 2.8578\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.5004 - mae: 2.0370 - val_loss: 12.1056 - val_mae: 2.6525\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.3516 - mae: 1.9121 - val_loss: 13.5127 - val_mae: 2.7760\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6770 - mae: 1.9936 - val_loss: 11.8106 - val_mae: 2.6360\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.5226 - mae: 1.9667 - val_loss: 10.6339 - val_mae: 2.4842\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.4805 - mae: 1.9388 - val_loss: 12.5696 - val_mae: 2.6923\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1089 - mae: 1.8983 - val_loss: 10.4298 - val_mae: 2.5101\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1689 - mae: 1.8768 - val_loss: 10.3510 - val_mae: 2.4327\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2989 - mae: 1.8685 - val_loss: 14.8516 - val_mae: 2.9432\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8032 - mae: 1.8925 - val_loss: 10.2594 - val_mae: 2.4391\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1311 - mae: 1.9003 - val_loss: 11.8490 - val_mae: 2.5743\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.0220 - mae: 1.8635 - val_loss: 12.8443 - val_mae: 2.7088\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8683 - mae: 1.8624 - val_loss: 11.3740 - val_mae: 2.5478\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8907 - mae: 1.8526 - val_loss: 12.5247 - val_mae: 2.6781\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.4556 - mae: 1.8732 - val_loss: 10.5398 - val_mae: 2.4462\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1941 - mae: 1.8229 - val_loss: 15.4007 - val_mae: 2.9808\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.4217 - mae: 1.8365 - val_loss: 11.0947 - val_mae: 2.4985\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.6266 - mae: 1.7547 - val_loss: 11.2040 - val_mae: 2.5765\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2724 - mae: 1.8168 - val_loss: 10.5630 - val_mae: 2.5154\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7162 - mae: 1.7672 - val_loss: 9.5961 - val_mae: 2.4095\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.3353 - mae: 1.7853 - val_loss: 10.4839 - val_mae: 2.4184\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8851 - mae: 1.7182 - val_loss: 11.9115 - val_mae: 2.5393\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5067 - mae: 1.7236 - val_loss: 9.3850 - val_mae: 2.3008\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6778 - mae: 1.7594 - val_loss: 10.5546 - val_mae: 2.5038\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6641 - mae: 1.7618 - val_loss: 10.6788 - val_mae: 2.4591\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2591 - mae: 1.7156 - val_loss: 12.0761 - val_mae: 2.6000\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9570 - mae: 1.7192 - val_loss: 10.4913 - val_mae: 2.4280\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4859 - mae: 1.6972 - val_loss: 10.1242 - val_mae: 2.4053\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0241 - mae: 1.6746 - val_loss: 11.9900 - val_mae: 2.6445\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4491 - mae: 1.6483 - val_loss: 8.9675 - val_mae: 2.2316\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9125 - mae: 1.6163 - val_loss: 14.3362 - val_mae: 2.7813\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2664 - mae: 1.7386 - val_loss: 11.8093 - val_mae: 2.5222\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9513 - mae: 1.6637 - val_loss: 11.3832 - val_mae: 2.6934\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0909 - mae: 1.6646 - val_loss: 10.2494 - val_mae: 2.3238\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0042 - mae: 1.6416 - val_loss: 8.9897 - val_mae: 2.2822\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3206 - mae: 1.6406 - val_loss: 11.9707 - val_mae: 2.6562\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4616 - mae: 1.5462 - val_loss: 10.4528 - val_mae: 2.4253\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5941 - mae: 1.6197 - val_loss: 11.2708 - val_mae: 2.5707\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5450 - mae: 1.5839 - val_loss: 13.0153 - val_mae: 2.7338\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8418 - mae: 1.5657 - val_loss: 13.6690 - val_mae: 2.7626\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3754 - mae: 1.5943 - val_loss: 10.4994 - val_mae: 2.5040\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4380 - mae: 1.5345 - val_loss: 11.9482 - val_mae: 2.5320\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4729 - mae: 1.5195 - val_loss: 10.6470 - val_mae: 2.4437\n",
      "Epoch 59/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2658 - mae: 1.5542 - val_loss: 9.1720 - val_mae: 2.3547\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1390 - mae: 1.5567 - val_loss: 9.9083 - val_mae: 2.4615\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0680 - mae: 1.5045 - val_loss: 9.4918 - val_mae: 2.2987\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9745 - mae: 1.4961 - val_loss: 11.9725 - val_mae: 2.6389\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1601 - mae: 1.5453 - val_loss: 8.7973 - val_mae: 2.3385\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2620 - mae: 1.5575 - val_loss: 10.9980 - val_mae: 2.5381\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0758 - mae: 1.4687 - val_loss: 9.4865 - val_mae: 2.4415\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9355 - mae: 1.5352 - val_loss: 8.5036 - val_mae: 2.2045\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2261 - mae: 1.4646 - val_loss: 9.0442 - val_mae: 2.2924\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5475 - mae: 1.4681 - val_loss: 15.8909 - val_mae: 3.3285\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8323 - mae: 1.4717 - val_loss: 14.5388 - val_mae: 2.7533\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8523 - mae: 1.4307 - val_loss: 9.6678 - val_mae: 2.4532\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6561 - mae: 1.4437 - val_loss: 12.0877 - val_mae: 2.6263\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9808 - mae: 1.4141 - val_loss: 9.5098 - val_mae: 2.3232\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5287 - mae: 1.3925 - val_loss: 11.7765 - val_mae: 2.6508\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6289 - mae: 1.4481 - val_loss: 8.5974 - val_mae: 2.2524\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5226 - mae: 1.3934 - val_loss: 9.2036 - val_mae: 2.3621\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3772 - mae: 1.3794 - val_loss: 13.3508 - val_mae: 2.8056\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4084 - mae: 1.4446 - val_loss: 12.8949 - val_mae: 2.6772\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2813 - mae: 1.3636 - val_loss: 12.2823 - val_mae: 2.7198\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5396 - mae: 1.3918 - val_loss: 13.0123 - val_mae: 2.6539\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4500 - mae: 1.4009 - val_loss: 10.8488 - val_mae: 2.3958\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2162 - mae: 1.3552 - val_loss: 10.6424 - val_mae: 2.5356\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2902 - mae: 1.3320 - val_loss: 13.4708 - val_mae: 2.6042\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2466 - mae: 1.3391 - val_loss: 8.6319 - val_mae: 2.1847\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1206 - mae: 1.3820 - val_loss: 9.4632 - val_mae: 2.4162\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0616 - mae: 1.3831 - val_loss: 11.9611 - val_mae: 2.4867\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1695 - mae: 1.3727 - val_loss: 11.1520 - val_mae: 2.4744\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1037 - mae: 1.3826 - val_loss: 9.6598 - val_mae: 2.4266\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1712 - mae: 1.3404 - val_loss: 13.4886 - val_mae: 2.6621\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1473 - mae: 1.3332 - val_loss: 11.9875 - val_mae: 2.5908\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2056 - mae: 1.3479 - val_loss: 14.4136 - val_mae: 2.7456\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7213 - mae: 1.2406 - val_loss: 14.6159 - val_mae: 2.7881\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1815 - mae: 1.3500 - val_loss: 14.5969 - val_mae: 2.6907\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8075 - mae: 1.3084 - val_loss: 12.6497 - val_mae: 2.6223\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9822 - mae: 1.3079 - val_loss: 13.0991 - val_mae: 2.7084\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6965 - mae: 1.2878 - val_loss: 9.9040 - val_mae: 2.3492\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4518 - mae: 1.2896 - val_loss: 12.9006 - val_mae: 2.7335\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0371 - mae: 1.3025 - val_loss: 13.5596 - val_mae: 2.6233\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8098 - mae: 1.2689 - val_loss: 13.6557 - val_mae: 2.8166\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0254 - mae: 1.2928 - val_loss: 12.2414 - val_mae: 2.6437\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6175 - mae: 1.2554 - val_loss: 12.0646 - val_mae: 2.5908\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2937 - mae: 1.2507 - val_loss: 13.1677 - val_mae: 2.7077\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5467 - mae: 1.2931 - val_loss: 10.9883 - val_mae: 2.4602\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6249 - mae: 1.2656 - val_loss: 11.2180 - val_mae: 2.5769\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7800 - mae: 1.2706 - val_loss: 11.8889 - val_mae: 2.5327\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4741 - mae: 1.2896 - val_loss: 13.8094 - val_mae: 2.8676\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4505 - mae: 1.2812 - val_loss: 9.2997 - val_mae: 2.3861\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6904 - mae: 1.2692 - val_loss: 12.1251 - val_mae: 2.5854\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6109 - mae: 1.2788 - val_loss: 14.7010 - val_mae: 2.8718\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2666 - mae: 1.2019 - val_loss: 11.8478 - val_mae: 2.5910\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3456 - mae: 1.2532 - val_loss: 10.9030 - val_mae: 2.4633\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2581 - mae: 1.2409 - val_loss: 15.7024 - val_mae: 2.7492\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2909 - mae: 1.2867 - val_loss: 11.1872 - val_mae: 2.5130\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4714 - mae: 1.2153 - val_loss: 12.4268 - val_mae: 2.6430\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0072 - mae: 1.1407 - val_loss: 14.4476 - val_mae: 2.8841\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2866 - mae: 1.2384 - val_loss: 17.4908 - val_mae: 2.9730\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2220 - mae: 1.2269 - val_loss: 16.2312 - val_mae: 2.8265\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3423 - mae: 1.2186 - val_loss: 11.9601 - val_mae: 2.5806\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4038 - mae: 1.2178 - val_loss: 12.6056 - val_mae: 2.6114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3878 - mae: 1.2247 - val_loss: 13.2020 - val_mae: 2.6489\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0183 - mae: 1.1616 - val_loss: 12.2066 - val_mae: 2.6038\n",
      "processing fold # 2\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 2s 7ms/sample - loss: 229.9152 - mae: 11.3001 - val_loss: 32.7154 - val_mae: 4.3297\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 36.9875 - mae: 3.9598 - val_loss: 14.5440 - val_mae: 2.8542\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 25.1377 - mae: 3.1874 - val_loss: 11.9998 - val_mae: 2.5731\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 20.2309 - mae: 2.8824 - val_loss: 12.0564 - val_mae: 2.4995\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 18.4752 - mae: 2.7300 - val_loss: 11.0645 - val_mae: 2.5379\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 16.1634 - mae: 2.6170 - val_loss: 11.3696 - val_mae: 2.6234\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 15.0320 - mae: 2.4457 - val_loss: 10.6484 - val_mae: 2.5649\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.2608 - mae: 2.4587 - val_loss: 9.6414 - val_mae: 2.3985\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.2678 - mae: 2.3703 - val_loss: 10.5562 - val_mae: 2.5023\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.1905 - mae: 2.2895 - val_loss: 9.8928 - val_mae: 2.3651\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.0055 - mae: 2.2669 - val_loss: 10.6085 - val_mae: 2.6271\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.3011 - mae: 2.2414 - val_loss: 8.6161 - val_mae: 2.2587\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.8002 - mae: 2.1525 - val_loss: 9.9803 - val_mae: 2.4170\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.3351 - mae: 2.1375 - val_loss: 10.5542 - val_mae: 2.5207\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 10.7856 - mae: 2.1841 - val_loss: 8.8806 - val_mae: 2.3489\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.1357 - mae: 2.1154 - val_loss: 10.7398 - val_mae: 2.5736\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.3951 - mae: 2.0800 - val_loss: 9.2882 - val_mae: 2.3620\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.4434 - mae: 2.0684 - val_loss: 10.6789 - val_mae: 2.5458\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.2889 - mae: 2.0790 - val_loss: 9.8648 - val_mae: 2.4115\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.8779 - mae: 2.0217 - val_loss: 9.2021 - val_mae: 2.3954\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.3301 - mae: 2.0739 - val_loss: 9.4257 - val_mae: 2.4196\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.5067 - mae: 1.9831 - val_loss: 8.8109 - val_mae: 2.2868\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.9795 - mae: 1.9604 - val_loss: 11.2692 - val_mae: 2.6036\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.7515 - mae: 1.9490 - val_loss: 10.5174 - val_mae: 2.5217\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.6103 - mae: 1.9278 - val_loss: 8.6039 - val_mae: 2.2735\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.2711 - mae: 1.9211 - val_loss: 8.6068 - val_mae: 2.3113\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.3731 - mae: 1.9561 - val_loss: 8.6246 - val_mae: 2.3669\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.9626 - mae: 1.8695 - val_loss: 11.8097 - val_mae: 2.7236\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6321 - mae: 1.8374 - val_loss: 7.8413 - val_mae: 2.2100\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.4836 - mae: 1.8130 - val_loss: 10.2034 - val_mae: 2.5014\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6484 - mae: 1.8994 - val_loss: 9.1444 - val_mae: 2.4371\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.4579 - mae: 1.8731 - val_loss: 8.8330 - val_mae: 2.3142\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.0852 - mae: 1.8498 - val_loss: 8.0013 - val_mae: 2.2404\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2033 - mae: 1.8159 - val_loss: 8.1367 - val_mae: 2.2427\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.0403 - mae: 1.8069 - val_loss: 7.9781 - val_mae: 2.2656\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1262 - mae: 1.8292 - val_loss: 8.4109 - val_mae: 2.2500\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.8355 - mae: 1.7606 - val_loss: 10.8063 - val_mae: 2.6148\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.6600 - mae: 1.7759 - val_loss: 8.2115 - val_mae: 2.2875\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5042 - mae: 1.7182 - val_loss: 7.3957 - val_mae: 2.1429\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8202 - mae: 1.7443 - val_loss: 7.6732 - val_mae: 2.1513\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7614 - mae: 1.7869 - val_loss: 8.0792 - val_mae: 2.2458\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5168 - mae: 1.7509 - val_loss: 7.7306 - val_mae: 2.2073\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.3026 - mae: 1.6963 - val_loss: 8.7391 - val_mae: 2.3044\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7125 - mae: 1.6924 - val_loss: 9.6158 - val_mae: 2.4219\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2978 - mae: 1.6996 - val_loss: 8.9701 - val_mae: 2.3409\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9402 - mae: 1.7678 - val_loss: 8.4095 - val_mae: 2.3111\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0022 - mae: 1.7226 - val_loss: 7.4621 - val_mae: 2.1312\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9707 - mae: 1.6754 - val_loss: 7.5647 - val_mae: 2.1908\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1022 - mae: 1.7040 - val_loss: 8.1518 - val_mae: 2.2911\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7630 - mae: 1.6329 - val_loss: 8.0660 - val_mae: 2.1944\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3163 - mae: 1.6399 - val_loss: 7.0871 - val_mae: 2.0946\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9122 - mae: 1.6638 - val_loss: 7.7318 - val_mae: 2.1905\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4080 - mae: 1.5709 - val_loss: 7.9960 - val_mae: 2.2355\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4869 - mae: 1.6226 - val_loss: 8.1801 - val_mae: 2.1856\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3545 - mae: 1.6030 - val_loss: 8.6056 - val_mae: 2.3065\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6558 - mae: 1.5759 - val_loss: 7.4028 - val_mae: 2.1687\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1986 - mae: 1.5980 - val_loss: 8.2704 - val_mae: 2.2876\n",
      "Epoch 58/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3118 - mae: 1.6267 - val_loss: 7.8091 - val_mae: 2.1863\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8024 - mae: 1.5812 - val_loss: 7.9531 - val_mae: 2.2784\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.4331 - mae: 1.5868 - val_loss: 8.0781 - val_mae: 2.1962\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8059 - mae: 1.5994 - val_loss: 9.7545 - val_mae: 2.4478\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1665 - mae: 1.5643 - val_loss: 7.9459 - val_mae: 2.2271\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8219 - mae: 1.5588 - val_loss: 8.6926 - val_mae: 2.3407\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7563 - mae: 1.5360 - val_loss: 7.8479 - val_mae: 2.1688\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0549 - mae: 1.5393 - val_loss: 7.7553 - val_mae: 2.2007\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5579 - mae: 1.4878 - val_loss: 7.5439 - val_mae: 2.0781\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6954 - mae: 1.5622 - val_loss: 8.4457 - val_mae: 2.3136\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5180 - mae: 1.5244 - val_loss: 7.3827 - val_mae: 2.1755\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5171 - mae: 1.4603 - val_loss: 8.3579 - val_mae: 2.2336\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6981 - mae: 1.4737 - val_loss: 7.7658 - val_mae: 2.1929\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4908 - mae: 1.4824 - val_loss: 7.5871 - val_mae: 2.2129\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5614 - mae: 1.4917 - val_loss: 7.6072 - val_mae: 2.2150\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4062 - mae: 1.5134 - val_loss: 7.7781 - val_mae: 2.2352\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1259 - mae: 1.4866 - val_loss: 7.4685 - val_mae: 2.1797\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3847 - mae: 1.4876 - val_loss: 8.4663 - val_mae: 2.2654\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3345 - mae: 1.4955 - val_loss: 8.4352 - val_mae: 2.2935\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1113 - mae: 1.4578 - val_loss: 8.2549 - val_mae: 2.2529\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 5.1708 - mae: 1.472 - 1s 2ms/sample - loss: 5.0200 - mae: 1.4663 - val_loss: 7.3771 - val_mae: 2.1657\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3492 - mae: 1.4616 - val_loss: 7.3198 - val_mae: 2.1654\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2070 - mae: 1.4719 - val_loss: 7.4845 - val_mae: 2.1553\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9552 - mae: 1.4389 - val_loss: 7.8293 - val_mae: 2.1667\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9858 - mae: 1.4685 - val_loss: 9.4484 - val_mae: 2.3556\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0362 - mae: 1.4041 - val_loss: 7.5391 - val_mae: 2.2130\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7656 - mae: 1.4458 - val_loss: 7.0564 - val_mae: 2.0760\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7675 - mae: 1.4573 - val_loss: 8.4817 - val_mae: 2.3051\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0538 - mae: 1.4377 - val_loss: 8.4079 - val_mae: 2.2973\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7599 - mae: 1.4149 - val_loss: 6.9157 - val_mae: 2.0941\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2427 - mae: 1.4540 - val_loss: 6.6309 - val_mae: 2.0622\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9213 - mae: 1.3889 - val_loss: 8.4605 - val_mae: 2.2414\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4513 - mae: 1.4205 - val_loss: 7.6712 - val_mae: 2.1514\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5457 - mae: 1.3264 - val_loss: 9.6501 - val_mae: 2.4577\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0110 - mae: 1.4282 - val_loss: 8.3085 - val_mae: 2.2654\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3140 - mae: 1.4028 - val_loss: 7.5900 - val_mae: 2.1347\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5161 - mae: 1.3535 - val_loss: 7.7373 - val_mae: 2.1971\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4448 - mae: 1.3488 - val_loss: 7.9955 - val_mae: 2.2726\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4445 - mae: 1.4237 - val_loss: 7.8143 - val_mae: 2.2086\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1373 - mae: 1.3261 - val_loss: 8.1947 - val_mae: 2.2462\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1733 - mae: 1.3013 - val_loss: 7.4415 - val_mae: 2.1590\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2233 - mae: 1.3706 - val_loss: 9.7897 - val_mae: 2.4381\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3314 - mae: 1.3220 - val_loss: 8.8077 - val_mae: 2.3425\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0369 - mae: 1.3692 - val_loss: 8.7422 - val_mae: 2.2516\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2786 - mae: 1.3503 - val_loss: 8.7468 - val_mae: 2.3541\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2163 - mae: 1.3648 - val_loss: 8.1136 - val_mae: 2.2440\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1570 - mae: 1.3792 - val_loss: 7.8428 - val_mae: 2.2451\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9246 - mae: 1.3087 - val_loss: 10.1307 - val_mae: 2.3820\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2381 - mae: 1.3079 - val_loss: 8.8703 - val_mae: 2.3728\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0575 - mae: 1.3564 - val_loss: 8.0884 - val_mae: 2.2874\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1034 - mae: 1.3769 - val_loss: 7.9073 - val_mae: 2.2943\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2501 - mae: 1.2926 - val_loss: 8.5070 - val_mae: 2.3682\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2221 - mae: 1.3362 - val_loss: 7.5093 - val_mae: 2.1396\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9003 - mae: 1.3099 - val_loss: 9.7643 - val_mae: 2.3906\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7369 - mae: 1.3003 - val_loss: 7.1497 - val_mae: 2.1268\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9046 - mae: 1.2731 - val_loss: 9.0583 - val_mae: 2.3052\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9953 - mae: 1.3403 - val_loss: 7.6191 - val_mae: 2.1812\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1874 - mae: 1.2426 - val_loss: 8.8170 - val_mae: 2.2984\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2367 - mae: 1.3697 - val_loss: 8.3318 - val_mae: 2.1900\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7031 - mae: 1.2965 - val_loss: 7.3357 - val_mae: 2.1116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7679 - mae: 1.2920 - val_loss: 8.2196 - val_mae: 2.2699\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7474 - mae: 1.2472 - val_loss: 7.8450 - val_mae: 2.2071\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6115 - mae: 1.2551 - val_loss: 7.5270 - val_mae: 2.1373\n",
      "processing fold # 3\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 204.0924 - mae: 10.6538 - val_loss: 42.2639 - val_mae: 4.6768\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 25.5421 - mae: 3.5409 - val_loss: 29.6254 - val_mae: 3.7941\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 20.1603 - mae: 3.1001 - val_loss: 23.5029 - val_mae: 3.0192\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 16.5349 - mae: 2.7362 - val_loss: 20.7746 - val_mae: 2.8617\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.8047 - mae: 2.5348 - val_loss: 23.4953 - val_mae: 2.8566\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.2724 - mae: 2.3893 - val_loss: 19.9855 - val_mae: 2.9274\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.2772 - mae: 2.3656 - val_loss: 18.3991 - val_mae: 2.7810\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.1708 - mae: 2.3009 - val_loss: 20.6212 - val_mae: 2.7268\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.0995 - mae: 2.2701 - val_loss: 19.1215 - val_mae: 2.6737\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.5657 - mae: 2.1781 - val_loss: 21.9044 - val_mae: 2.8334\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.6128 - mae: 2.1552 - val_loss: 19.1977 - val_mae: 2.6739\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.9491 - mae: 2.0489 - val_loss: 17.8819 - val_mae: 2.7051\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6262 - mae: 2.1110 - val_loss: 19.4167 - val_mae: 2.6714\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.4483 - mae: 2.0314 - val_loss: 18.5537 - val_mae: 2.6400\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2657 - mae: 1.9856 - val_loss: 17.7347 - val_mae: 2.6132\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1870 - mae: 1.9763 - val_loss: 17.2522 - val_mae: 2.6063\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.6615 - mae: 1.9898 - val_loss: 18.4974 - val_mae: 2.6047\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8616 - mae: 1.9695 - val_loss: 16.6147 - val_mae: 2.4929\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.6355 - mae: 1.8839 - val_loss: 18.8138 - val_mae: 2.6554\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.6147 - mae: 1.8744 - val_loss: 16.8757 - val_mae: 2.5396\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2527 - mae: 1.8820 - val_loss: 17.3542 - val_mae: 2.5533\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1226 - mae: 1.8494 - val_loss: 16.0444 - val_mae: 2.4768\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1344 - mae: 1.8380 - val_loss: 16.3903 - val_mae: 2.5144\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5483 - mae: 1.8307 - val_loss: 21.1279 - val_mae: 2.7018\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1461 - mae: 1.8130 - val_loss: 17.4948 - val_mae: 2.5500\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5021 - mae: 1.8309 - val_loss: 16.3996 - val_mae: 2.5815\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5131 - mae: 1.8014 - val_loss: 17.3939 - val_mae: 2.5838\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5080 - mae: 1.7483 - val_loss: 16.4960 - val_mae: 2.4484\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0835 - mae: 1.7494 - val_loss: 17.2133 - val_mae: 2.6016\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0739 - mae: 1.7506 - val_loss: 16.8287 - val_mae: 2.5295\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1318 - mae: 1.7056 - val_loss: 15.6412 - val_mae: 2.4387\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9131 - mae: 1.7246 - val_loss: 18.7667 - val_mae: 2.6086\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2195 - mae: 1.7477 - val_loss: 16.9829 - val_mae: 2.6930\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8025 - mae: 1.7149 - val_loss: 19.3657 - val_mae: 2.8103\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6804 - mae: 1.6883 - val_loss: 17.5589 - val_mae: 2.7594\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9631 - mae: 1.6977 - val_loss: 16.6310 - val_mae: 2.4907\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7454 - mae: 1.6100 - val_loss: 18.6801 - val_mae: 2.7310\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7807 - mae: 1.6643 - val_loss: 16.0864 - val_mae: 2.5031\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5126 - mae: 1.6380 - val_loss: 19.1621 - val_mae: 2.8908\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2717 - mae: 1.6490 - val_loss: 20.4554 - val_mae: 2.8867\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1724 - mae: 1.6445 - val_loss: 16.7565 - val_mae: 2.4255\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4000 - mae: 1.5949 - val_loss: 16.2135 - val_mae: 2.5577\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2432 - mae: 1.5691 - val_loss: 21.7695 - val_mae: 3.0130\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2138 - mae: 1.5526 - val_loss: 17.0057 - val_mae: 2.6164\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3238 - mae: 1.5964 - val_loss: 18.3187 - val_mae: 2.6120\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2623 - mae: 1.5543 - val_loss: 16.2081 - val_mae: 2.5041\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8895 - mae: 1.5873 - val_loss: 16.8565 - val_mae: 2.4762\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0308 - mae: 1.5982 - val_loss: 16.1677 - val_mae: 2.6828\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9816 - mae: 1.5683 - val_loss: 15.3184 - val_mae: 2.3842\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9225 - mae: 1.5002 - val_loss: 17.4188 - val_mae: 2.4763\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9386 - mae: 1.5462 - val_loss: 17.6538 - val_mae: 2.5542\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5475 - mae: 1.5211 - val_loss: 18.9706 - val_mae: 2.6841\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7006 - mae: 1.5553 - val_loss: 17.1738 - val_mae: 2.5601\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6806 - mae: 1.5028 - val_loss: 18.9778 - val_mae: 2.7115\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4813 - mae: 1.4731 - val_loss: 17.4795 - val_mae: 2.5647\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6623 - mae: 1.5060 - val_loss: 16.1762 - val_mae: 2.5099\n",
      "Epoch 57/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6600 - mae: 1.4822 - val_loss: 16.6315 - val_mae: 2.5337\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4101 - mae: 1.4761 - val_loss: 17.0416 - val_mae: 2.5874\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1265 - mae: 1.4614 - val_loss: 16.2114 - val_mae: 2.6221\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1549 - mae: 1.4075 - val_loss: 16.5028 - val_mae: 2.5530\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5110 - mae: 1.4866 - val_loss: 15.6592 - val_mae: 2.4534\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5126 - mae: 1.4450 - val_loss: 18.9560 - val_mae: 2.5947\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3212 - mae: 1.4681 - val_loss: 17.1665 - val_mae: 2.5757\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8754 - mae: 1.4312 - val_loss: 17.1419 - val_mae: 2.4842\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3144 - mae: 1.4544 - val_loss: 19.3012 - val_mae: 2.8207\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2159 - mae: 1.4504 - val_loss: 16.4397 - val_mae: 2.5221\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0992 - mae: 1.4159 - val_loss: 17.9696 - val_mae: 2.7708\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1158 - mae: 1.4197 - val_loss: 18.4062 - val_mae: 2.7225\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6544 - mae: 1.3630 - val_loss: 16.8339 - val_mae: 2.5445\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7295 - mae: 1.4014 - val_loss: 15.8147 - val_mae: 2.3918\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8994 - mae: 1.4187 - val_loss: 16.8121 - val_mae: 2.5741\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6744 - mae: 1.3859 - val_loss: 16.3824 - val_mae: 2.5046\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8725 - mae: 1.4085 - val_loss: 17.2154 - val_mae: 2.6611\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9079 - mae: 1.4041 - val_loss: 15.4684 - val_mae: 2.4878\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7524 - mae: 1.3897 - val_loss: 16.1911 - val_mae: 2.4680\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4387 - mae: 1.3383 - val_loss: 17.9365 - val_mae: 2.5435\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3878 - mae: 1.2843 - val_loss: 17.6694 - val_mae: 2.7708\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.4856 - mae: 1.3486 - val_loss: 17.5414 - val_mae: 2.6577\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5929 - mae: 1.3381 - val_loss: 16.0828 - val_mae: 2.5358\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3161 - mae: 1.3036 - val_loss: 17.6280 - val_mae: 2.6550\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3731 - mae: 1.2914 - val_loss: 17.2203 - val_mae: 2.6777\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2717 - mae: 1.2739 - val_loss: 17.3575 - val_mae: 2.7212\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3512 - mae: 1.2553 - val_loss: 16.2201 - val_mae: 2.5478\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4108 - mae: 1.2908 - val_loss: 17.0252 - val_mae: 2.7180\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2241 - mae: 1.3048 - val_loss: 19.8866 - val_mae: 2.7185\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0881 - mae: 1.2948 - val_loss: 17.1798 - val_mae: 2.7091\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0813 - mae: 1.2647 - val_loss: 16.3128 - val_mae: 2.6644\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0974 - mae: 1.2667 - val_loss: 18.1527 - val_mae: 2.6332\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1725 - mae: 1.2490 - val_loss: 20.1391 - val_mae: 2.8611\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1401 - mae: 1.2877 - val_loss: 16.1043 - val_mae: 2.5955\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.9972 - mae: 1.3009 - val_loss: 19.3537 - val_mae: 2.8684\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.9364 - mae: 1.2789 - val_loss: 15.5038 - val_mae: 2.6036\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.9316 - mae: 1.2348 - val_loss: 16.5912 - val_mae: 2.5170\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7174 - mae: 1.1912 - val_loss: 17.2208 - val_mae: 2.6845\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8982 - mae: 1.2480 - val_loss: 18.9913 - val_mae: 2.7719\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0168 - mae: 1.2369 - val_loss: 20.2656 - val_mae: 2.8157\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8765 - mae: 1.1989 - val_loss: 17.7638 - val_mae: 2.6637\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7440 - mae: 1.1949 - val_loss: 17.6527 - val_mae: 2.6429\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7865 - mae: 1.1831 - val_loss: 17.1403 - val_mae: 2.7973\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.7831 - mae: 1.2372 - val_loss: 17.4338 - val_mae: 2.7635\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7448 - mae: 1.2231 - val_loss: 17.2633 - val_mae: 2.7796\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7414 - mae: 1.2234 - val_loss: 17.8502 - val_mae: 2.7999\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.6809 - mae: 1.1729 - val_loss: 16.9521 - val_mae: 2.6094\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5285 - mae: 1.1645 - val_loss: 17.5890 - val_mae: 2.9510\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5826 - mae: 1.1666 - val_loss: 18.2610 - val_mae: 2.8178\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5420 - mae: 1.1866 - val_loss: 17.6892 - val_mae: 2.7602\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.6758 - mae: 1.2098 - val_loss: 18.2510 - val_mae: 2.7445\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.4515 - mae: 1.1503 - val_loss: 17.1384 - val_mae: 2.7841\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.4628 - mae: 1.1627 - val_loss: 17.2085 - val_mae: 2.6548\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5315 - mae: 1.1550 - val_loss: 18.6065 - val_mae: 2.8147\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5278 - mae: 1.1822 - val_loss: 18.6927 - val_mae: 2.8095\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.2281 - mae: 1.0732 - val_loss: 19.7818 - val_mae: 3.0972\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5507 - mae: 1.1748 - val_loss: 18.4294 - val_mae: 2.8466\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.2602 - mae: 1.1247 - val_loss: 19.2831 - val_mae: 2.9026\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.4419 - mae: 1.1522 - val_loss: 20.0359 - val_mae: 2.9627\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.0922 - mae: 1.0934 - val_loss: 19.5209 - val_mae: 2.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.1934 - mae: 1.0945 - val_loss: 16.2545 - val_mae: 2.5554\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.3352 - mae: 1.1004 - val_loss: 17.8472 - val_mae: 2.8104\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.0832 - mae: 1.0717 - val_loss: 17.6050 - val_mae: 2.8709\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.2468 - mae: 1.1244 - val_loss: 19.5540 - val_mae: 2.8712\n",
      "processing fold # 4\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 182.8700 - mae: 10.1550 - val_loss: 49.8308 - val_mae: 4.5369\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 23.8903 - mae: 3.3682 - val_loss: 32.8548 - val_mae: 3.5551\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 15.9087 - mae: 2.7339 - val_loss: 27.7293 - val_mae: 3.2436\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.7448 - mae: 2.5493 - val_loss: 28.1787 - val_mae: 3.4013\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.2857 - mae: 2.4846 - val_loss: 22.5108 - val_mae: 2.9638\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.7984 - mae: 2.3513 - val_loss: 20.7610 - val_mae: 2.8879\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.5553 - mae: 2.2753 - val_loss: 26.8819 - val_mae: 3.2628\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.9557 - mae: 2.2241 - val_loss: 18.8829 - val_mae: 2.8175\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.2907 - mae: 2.2320 - val_loss: 21.1334 - val_mae: 2.9144\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.5560 - mae: 2.1719 - val_loss: 17.7728 - val_mae: 2.8087\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.1480 - mae: 2.0995 - val_loss: 19.5852 - val_mae: 3.0419\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.2463 - mae: 2.1401 - val_loss: 18.8393 - val_mae: 3.0265\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.9288 - mae: 2.1253 - val_loss: 20.8339 - val_mae: 2.9654\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.9487 - mae: 2.0418 - val_loss: 17.7626 - val_mae: 2.8026\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.6393 - mae: 1.9932 - val_loss: 15.6290 - val_mae: 2.7122\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4676 - mae: 2.0121 - val_loss: 17.1545 - val_mae: 2.8487\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.7745 - mae: 2.0005 - val_loss: 17.6477 - val_mae: 2.9301\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.9534 - mae: 1.9714 - val_loss: 14.9640 - val_mae: 2.6577\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.8370 - mae: 1.9547 - val_loss: 16.0875 - val_mae: 2.7428\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.9249 - mae: 1.9798 - val_loss: 16.4912 - val_mae: 2.7759\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.3837 - mae: 1.9504 - val_loss: 14.8956 - val_mae: 2.6515\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.8902 - mae: 1.9604 - val_loss: 13.5729 - val_mae: 2.5487\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2228 - mae: 1.8366 - val_loss: 19.0894 - val_mae: 3.0721\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2434 - mae: 1.9291 - val_loss: 14.2600 - val_mae: 2.6485\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8471 - mae: 1.8672 - val_loss: 14.7437 - val_mae: 2.7224\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.0327 - mae: 1.8746 - val_loss: 12.8637 - val_mae: 2.5123\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.9631 - mae: 1.8525 - val_loss: 16.0174 - val_mae: 2.7291\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7725 - mae: 1.7782 - val_loss: 14.4453 - val_mae: 2.6544\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5723 - mae: 1.8058 - val_loss: 15.5927 - val_mae: 2.7526\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7486 - mae: 1.7989 - val_loss: 13.9411 - val_mae: 2.5787\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7462 - mae: 1.7980 - val_loss: 13.7064 - val_mae: 2.5239\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1736 - mae: 1.7409 - val_loss: 14.3237 - val_mae: 2.8370\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.3786 - mae: 1.7314 - val_loss: 12.6020 - val_mae: 2.4397\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0871 - mae: 1.7695 - val_loss: 13.6851 - val_mae: 2.6072\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.3375 - mae: 1.7649 - val_loss: 12.1737 - val_mae: 2.4613\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2268 - mae: 1.7491 - val_loss: 13.0582 - val_mae: 2.6287\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0741 - mae: 1.6962 - val_loss: 12.6054 - val_mae: 2.5738\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9763 - mae: 1.7219 - val_loss: 12.2522 - val_mae: 2.4934\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2653 - mae: 1.7428 - val_loss: 12.9572 - val_mae: 2.6419\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6887 - mae: 1.7200 - val_loss: 12.4496 - val_mae: 2.4931\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9488 - mae: 1.7003 - val_loss: 11.6964 - val_mae: 2.4828\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9835 - mae: 1.7282 - val_loss: 11.5262 - val_mae: 2.4081\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7717 - mae: 1.6314 - val_loss: 12.0126 - val_mae: 2.5400\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6683 - mae: 1.6590 - val_loss: 12.5503 - val_mae: 2.5946\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3689 - mae: 1.6306 - val_loss: 13.1768 - val_mae: 2.5802\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3142 - mae: 1.6445 - val_loss: 12.8650 - val_mae: 2.5625\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3829 - mae: 1.6096 - val_loss: 12.2604 - val_mae: 2.4988\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1397 - mae: 1.6353 - val_loss: 13.9310 - val_mae: 2.7907\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1463 - mae: 1.6163 - val_loss: 12.1445 - val_mae: 2.5338\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1804 - mae: 1.5635 - val_loss: 16.0687 - val_mae: 2.9341\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0760 - mae: 1.6262 - val_loss: 11.5229 - val_mae: 2.4796\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9587 - mae: 1.6093 - val_loss: 13.3905 - val_mae: 2.7690\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8486 - mae: 1.6351 - val_loss: 11.1825 - val_mae: 2.3992\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0341 - mae: 1.5848 - val_loss: 11.6905 - val_mae: 2.4617\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1023 - mae: 1.5997 - val_loss: 11.7112 - val_mae: 2.5066\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8720 - mae: 1.5363 - val_loss: 13.3477 - val_mae: 2.7193\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8821 - mae: 1.5797 - val_loss: 12.2956 - val_mae: 2.7036\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4364 - mae: 1.5361 - val_loss: 12.8171 - val_mae: 2.5636\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7995 - mae: 1.5601 - val_loss: 11.1967 - val_mae: 2.4367\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7374 - mae: 1.5326 - val_loss: 12.4884 - val_mae: 2.5910\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4515 - mae: 1.5348 - val_loss: 11.2292 - val_mae: 2.4462\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4515 - mae: 1.5366 - val_loss: 10.6940 - val_mae: 2.4085\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3914 - mae: 1.4866 - val_loss: 11.1357 - val_mae: 2.4991\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2524 - mae: 1.5239 - val_loss: 11.5323 - val_mae: 2.4416\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3215 - mae: 1.5178 - val_loss: 12.0135 - val_mae: 2.5287\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0752 - mae: 1.4969 - val_loss: 12.0167 - val_mae: 2.5303\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2772 - mae: 1.5098 - val_loss: 12.1302 - val_mae: 2.5698\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1313 - mae: 1.5421 - val_loss: 11.4566 - val_mae: 2.4363\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2325 - mae: 1.4670 - val_loss: 10.8853 - val_mae: 2.3980\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1487 - mae: 1.4659 - val_loss: 10.8043 - val_mae: 2.4243\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1006 - mae: 1.4828 - val_loss: 10.9507 - val_mae: 2.3864\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 5.3294 - mae: 1.525 - 1s 2ms/sample - loss: 5.1574 - mae: 1.4980 - val_loss: 10.9672 - val_mae: 2.4024\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1119 - mae: 1.4587 - val_loss: 11.4017 - val_mae: 2.5977\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1655 - mae: 1.4230 - val_loss: 10.3470 - val_mae: 2.3410\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8731 - mae: 1.4964 - val_loss: 10.3070 - val_mae: 2.3594\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7641 - mae: 1.4375 - val_loss: 10.8308 - val_mae: 2.4672\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0094 - mae: 1.4757 - val_loss: 10.4587 - val_mae: 2.3961\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9555 - mae: 1.4370 - val_loss: 11.0836 - val_mae: 2.4459\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7967 - mae: 1.4462 - val_loss: 10.4965 - val_mae: 2.3282\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9446 - mae: 1.4496 - val_loss: 10.3068 - val_mae: 2.3640\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3747 - mae: 1.3872 - val_loss: 10.6734 - val_mae: 2.3832\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7704 - mae: 1.3866 - val_loss: 10.4774 - val_mae: 2.3567\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5159 - mae: 1.4171 - val_loss: 10.1772 - val_mae: 2.3771\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9342 - mae: 1.4277 - val_loss: 10.4718 - val_mae: 2.3823\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6624 - mae: 1.3786 - val_loss: 10.0675 - val_mae: 2.3367\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8402 - mae: 1.4323 - val_loss: 10.9615 - val_mae: 2.4636\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1991 - mae: 1.3758 - val_loss: 11.4172 - val_mae: 2.4189\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6341 - mae: 1.4599 - val_loss: 10.8448 - val_mae: 2.4168\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3081 - mae: 1.3956 - val_loss: 10.2739 - val_mae: 2.4240\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4443 - mae: 1.3878 - val_loss: 11.6549 - val_mae: 2.5493\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7688 - mae: 1.3858 - val_loss: 10.1445 - val_mae: 2.3941\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2915 - mae: 1.3606 - val_loss: 10.3505 - val_mae: 2.3330\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0286 - mae: 1.3172 - val_loss: 10.7221 - val_mae: 2.3911\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1828 - mae: 1.4092 - val_loss: 10.0595 - val_mae: 2.3814\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2459 - mae: 1.3308 - val_loss: 11.3151 - val_mae: 2.5238\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1258 - mae: 1.3281 - val_loss: 9.6974 - val_mae: 2.3472\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2140 - mae: 1.3483 - val_loss: 10.6354 - val_mae: 2.3864\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2346 - mae: 1.3261 - val_loss: 9.8781 - val_mae: 2.3985\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1201 - mae: 1.3488 - val_loss: 9.9891 - val_mae: 2.3695\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0214 - mae: 1.2915 - val_loss: 10.0573 - val_mae: 2.3665\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9631 - mae: 1.3092 - val_loss: 10.3606 - val_mae: 2.4166\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2615 - mae: 1.2902 - val_loss: 10.1001 - val_mae: 2.3984\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1315 - mae: 1.3476 - val_loss: 10.2710 - val_mae: 2.3492\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0354 - mae: 1.3736 - val_loss: 10.6698 - val_mae: 2.4190\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0426 - mae: 1.3459 - val_loss: 10.6384 - val_mae: 2.4502\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5517 - mae: 1.3060 - val_loss: 12.4009 - val_mae: 2.4709\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0456 - mae: 1.3469 - val_loss: 10.3887 - val_mae: 2.3537\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0173 - mae: 1.2925 - val_loss: 9.7435 - val_mae: 2.3017\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6657 - mae: 1.2440 - val_loss: 10.2479 - val_mae: 2.3480\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8739 - mae: 1.2868 - val_loss: 10.9244 - val_mae: 2.4697\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6927 - mae: 1.3220 - val_loss: 10.0001 - val_mae: 2.3794\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0226 - mae: 1.3514 - val_loss: 10.3395 - val_mae: 2.3893\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8584 - mae: 1.3063 - val_loss: 10.1346 - val_mae: 2.3486\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6616 - mae: 1.2948 - val_loss: 10.1116 - val_mae: 2.3874\n",
      "Epoch 115/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8561 - mae: 1.2550 - val_loss: 10.3991 - val_mae: 2.4150\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8234 - mae: 1.3017 - val_loss: 11.0402 - val_mae: 2.5365\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5833 - mae: 1.2558 - val_loss: 10.5725 - val_mae: 2.4656\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6061 - mae: 1.2913 - val_loss: 9.5385 - val_mae: 2.3306\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6303 - mae: 1.2826 - val_loss: 10.1213 - val_mae: 2.3527\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4416 - mae: 1.2478 - val_loss: 10.6924 - val_mae: 2.4412\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 5\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 120\n",
    "all_scores = []\n",
    "\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the average of the per-epoch MAE scores for all folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(1, len(average_mae_history) + 1)[5:], average_mae_history[5:])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that validation MAE stops improving significantly after 50 epochs. We can now train a final \"production\" model on all of the training data, with the best parameters, then look at its performance on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 185.9212 - mae: 9.9329 - val_loss: 37.1717 - val_mae: 4.1610\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 26.4943 - mae: 3.3925 - val_loss: 25.8267 - val_mae: 3.6285\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 20.4528 - mae: 2.8936 - val_loss: 19.0481 - val_mae: 2.9213\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 17.8224 - mae: 2.6726 - val_loss: 16.5634 - val_mae: 2.9708\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 15.5050 - mae: 2.4766 - val_loss: 20.2127 - val_mae: 3.4270\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 14.2971 - mae: 2.4743 - val_loss: 14.3772 - val_mae: 2.8255\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 13.9271 - mae: 2.3835 - val_loss: 15.3184 - val_mae: 2.8043\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 13.0080 - mae: 2.2276 - val_loss: 13.8172 - val_mae: 2.9116\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 12.4639 - mae: 2.2946 - val_loss: 13.7369 - val_mae: 2.8288\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 11.3111 - mae: 2.2312 - val_loss: 13.1914 - val_mae: 2.8060\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 11.3546 - mae: 2.2041 - val_loss: 12.0067 - val_mae: 2.5914\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.0103 - mae: 2.1835 - val_loss: 12.9973 - val_mae: 2.7207\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.0733 - mae: 2.1436 - val_loss: 11.3934 - val_mae: 2.5384\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.5517 - mae: 2.0979 - val_loss: 11.6405 - val_mae: 2.5472\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.1102 - mae: 2.0669 - val_loss: 12.3593 - val_mae: 2.6974\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 9.5811 - mae: 2.0193 - val_loss: 11.2499 - val_mae: 2.4676\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 9.7427 - mae: 2.0378 - val_loss: 10.8757 - val_mae: 2.4362\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 9.2824 - mae: 2.0054 - val_loss: 11.6078 - val_mae: 2.5289\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 9.3366 - mae: 2.0124 - val_loss: 12.8765 - val_mae: 2.7023\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.5192 - mae: 1.9454 - val_loss: 14.0982 - val_mae: 2.8925\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.5350 - mae: 1.8958 - val_loss: 12.3882 - val_mae: 2.6145\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.5821 - mae: 1.9695 - val_loss: 12.9465 - val_mae: 2.7012\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.3560 - mae: 1.8122 - val_loss: 14.2126 - val_mae: 2.8059\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.9208 - mae: 1.8620 - val_loss: 12.7201 - val_mae: 2.4360\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.8663 - mae: 1.8805 - val_loss: 11.8188 - val_mae: 2.5135\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - ETA: 0s - loss: 7.7837 - mae: 1.795 - 1s 2ms/sample - loss: 7.5842 - mae: 1.7876 - val_loss: 12.8509 - val_mae: 2.6288\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.6236 - mae: 1.8085 - val_loss: 12.6455 - val_mae: 2.5201\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.5751 - mae: 1.8676 - val_loss: 13.1493 - val_mae: 2.5939\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.5161 - mae: 1.7958 - val_loss: 12.0057 - val_mae: 2.4687\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.5539 - mae: 1.8042 - val_loss: 12.4092 - val_mae: 2.5136\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.2319 - mae: 1.7521 - val_loss: 13.5036 - val_mae: 2.6826\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.2809 - mae: 1.7647 - val_loss: 14.0352 - val_mae: 2.5408\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.0751 - mae: 1.7709 - val_loss: 12.9160 - val_mae: 2.5525\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.7194 - mae: 1.7357 - val_loss: 14.6529 - val_mae: 2.8717\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.0046 - mae: 1.6986 - val_loss: 14.5751 - val_mae: 2.6275\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.4941 - mae: 1.6804 - val_loss: 12.6770 - val_mae: 2.4989\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.5063 - mae: 1.6934 - val_loss: 14.4381 - val_mae: 2.5770\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.7413 - mae: 1.7108 - val_loss: 15.5738 - val_mae: 2.6077\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.1948 - mae: 1.6925 - val_loss: 12.8711 - val_mae: 2.4289\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.5284 - mae: 1.6727 - val_loss: 12.4383 - val_mae: 2.5847\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.4315 - mae: 1.6680 - val_loss: 12.4103 - val_mae: 2.6426\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.2871 - mae: 1.6443 - val_loss: 13.4980 - val_mae: 2.8977\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3115 - mae: 1.6097 - val_loss: 16.8665 - val_mae: 3.0410\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.0058 - mae: 1.6555 - val_loss: 13.6514 - val_mae: 2.4671\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.6413 - mae: 1.6198 - val_loss: 14.3651 - val_mae: 2.4783\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.0438 - mae: 1.5915 - val_loss: 13.6624 - val_mae: 2.6516\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.8706 - mae: 1.5670 - val_loss: 12.7524 - val_mae: 2.5340\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.7376 - mae: 1.5750 - val_loss: 13.2560 - val_mae: 2.4832\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.8361 - mae: 1.6031 - val_loss: 13.7953 - val_mae: 2.4749\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.7621 - mae: 1.5622 - val_loss: 13.2683 - val_mae: 2.4057\n"
     ]
    }
   ],
   "source": [
    "# Get a fresh, compiled model.\n",
    "model = build_model()\n",
    "# Train it on the entirety of the data.\n",
    "history = model.fit(train_data, train_targets, validation_split =0.2,\n",
    "          epochs=50, batch_size=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd5hTVdPAf4cFROlSlL4gKm1p0pGiKBZQpCovIqCIIPqJFfC1Yu9dkVcERaQIKlhQUEGKSJWigCJVOtI77O58f0yyfbNJNtlsmd/z5EnuveeeO7m7OXPPzJwZJyIYhmEYeZd8kRbAMAzDiCymCAzDMPI4pggMwzDyOKYIDMMw8jimCAzDMPI4pggMwzDyOKYIjJDhnItyzh11zlUOZdtI4pyr7pwLeYy1c+4K59zmJNt/Ouda+dM2iGt94Jx7ONjzjdyPKYI8jGcg9r7inXMnkmz3CrQ/EYkTkSIisjWUbfMCInKxiMzLbD/Ouf7OuTkp+u4vIs9mtu80rvW0c06cc3em2P+AZ/8jKfZX9+x/M8X+/J79x1L8T94XapmNtDFFkIfxDMRFRKQIsBW4Lsm+8SnbO+fyZ72URjbnL6BPin29PftT0gfYD/R0zhVI43jtpP+TIvJqiGU10sEUgZEunie+Sc65Cc65I8DNzrnmzrlfnXMHnXM7nXNven/USZ7soj3bn3iOz3DOHXHOLXTOVQ20ref4Nc65v5xzh5xzbznnFjjn+qYjtz8y3uGc+9s5dyDpE6rHZPWac26fc24DcLWP+/OIc25iin3vOOde9Xzu75xb6/k+G5xz/X30tc0519bz+Rzn3DiPbH8Al6Rx3Y2efv9wzl3v2R8DvA208jxR/5vk3j6R5PyBnu++zzn3pXOunD/3Jh0WAuc65y729FEfHVd+SyGzQxXEcMABHTLo18hCTBEYGdEZ+BQoDkwCYoF7gNJAS3SgvMPH+f8BHgXORWcdTwXa1jlXFpgMPOi57iagiY9+/JHxWnSAbYAquCs8+wcB7YF6nmv08HGdT4GOzrnCHjnzA909+wF2owNeMeB24C3nXF0f/XkZAVQCqnnkTPnE/ZfnexUHngE+dc6dJyKrgbuAeZ4n6tIpO3bOtff03w2oAOwAUs7+0rs36TEOuMXz+Rbg4zTatAXOQ/+HPkvS3sgGmCIwMmK+iHwlIvEickJElojIIhGJFZGNwCigjY/zp4jIUhE5gw449YNo2xFYISLTPMdeA/5NrxM/ZXxORA6JyGZgTpJr9QBeE5FtIrIPeN7HdTYCvwOdPLuuBA6KyFLP8a9EZKMoPwE/Amk6hFPQA3haRA6IyBb0KT/pdSeLyE7P3+RTYDPQyI9+AXoBH4jIChE5CQwD2jjnKiZpk969SY9xQC/PrKsHqRULqDL7RkQOoYqyg3OuVIo2qzyzOO+rnZ/fycgkpgiMjPgn6YZzroZz7hvn3C7n3GH06TLVk2cSdiX5fBwoEkTb8knlEM2UuC29TvyU0a9rAVt8yAs6qPX0fP4PSQZB51xH59wi59x+59xBdKbh6155KedLBudcX+fcSu+ACdTws1/Q75fQn4gcBg6gswMvgfzNEJFN6AzuWeAPEdmRQt7CQFcS7818YCeJ981LXREpkeT1o5/fycgkpgiMjEgZOvk++hRcXUSKAY+hNt9wshNIeGL12JsrpN88UzLuRM0yXjIKb50EXOF5ou6ExyzknDsbmAI8B5wnIiWAmX7KsSs9GZxz1YD3UBNWKU+/65L0m1Go6w6gSpL+igIlge1+yOWLj4H7Sdss1BVVJqOcc7vQe3w+Zh7KNpgiMAKlKHAIOOacq4lv/0Co+Bpo6Jy7zmOHvwcoEyYZJwNDnHMVPKaLob4ai8hu9Al3DPCniKz3HDoLKAjsBeKccx0Bf00dk4GHnXMlnK6zuCvJsSLoYL8X1Yn90RmBl91ARZd2VA7ABOA251xd59xZqKKaJyLpzrD85FN0xjM1jWN9gP8BMaiZqT7QGmjk+fsYEcYUgREo96M/7CPok/ekcF/QM9jeCLwK7AMuQKNSToVBxvdQW/5qYAn6VJ8RnwJXkOgkRkQOAvcCX6Ahk91QheYPj6NPzZuBGSR5yhaRVcCbwGJPmxrAoiTnzgLWA7s9T9/JEJHvUFPZF57zK6N+g0whIsdF5AeP3yEBjyJrC7wuIruSvBYDP5DcEf6HS76O4JXMymX4h7PCNEZOwzkXhZo4uoViEZZh5HVsRmDkCJxzVzvninvMGY+iIaKLIyyWYeQKTBEYOYVLgY1o2OjVwA0ikp5pyDCMADDTkGEYRh7HZgSGYRh5nByXRKx06dISHR0daTEMwzByFMuWLftXRNIMu85xiiA6OpqlS5dGWgzDMIwchXMu3VXyZhoyDMPI45giMAzDyOOYIjAMw8jjmCIwDMPI45giMAzDyOOYIjAMw8jjmCIwDMPI45giMAwj17BuHcyYEWkpch45bkGZYRhGevTvD2vXwr59kZYkZ2GKwDCMXMHq1bBggX4+cQLOPjuy8uQkzDRkGEau4P33Ez/v3Bk5OXIiYVMEzrlCzrnFzrmVzrk/nHNPptHmLOfcJOfc3865Rc656HDJYxhG7uXoUfj4Y6hUSbd37IisPDmNcM4ITgGXi0g9tFj11c65Zina3AYcEJHqwGvAC2GUxzCMXMqECXDkCDzyiG6bIgiMsCkCUY56Ngt4Ximr4HQCPvJ8ngK0c865cMlkGEbuQwTeew9iYqBrV91niiAwwuojcM5FOedWAHuAWSKyKEWTCsA/ACISCxwCSqXRzwDn3FLn3NK9e/eGU2TDMHIYS5fCb7/BwIFw7rlw1lmmCAIlrIpAROJEpD5QEWjinKuToklaT/+pameKyCgRaSQijcqUSbOugmEYeZT33oPCheHmm8E5KF/eFEGgZEnUkIgcBOagRceTsg2oBOCcyw8UB/ZnhUyGYeR8DhyAiROhVy8oVkz3lS8P27dHVq6cRjijhso450p4Pp8NXAGsS9FsOtDH87kb8JOIpJoRGIZhpMW4cbpmYODAxH0VKtiMIFDCOSMoB8x2zq0ClqA+gq+dcyOcc9d72owGSjnn/gbuA4aFUR7DMHIRIjByJDRpAg0aJO4301DghG1lsYisAhqksf+xJJ9PAt3DJYNhGLmXuXM1ncSYMcn3ly+v6wqOHIGiRSMjW07DVhYbhpEjGTkSSpSAHj2S7y9fXt9tVuA/pggMw8hx7NkDU6dCnz5wzjnJj5kiCBxTBIZh5DjGjIEzZ+COO1IfM0UQOKYIDMPIUcTHa4K5tm2hZs3Ux00RBI4pAsMwchQzZ8KmTclDRpNStCgUKWKKIBBMERiGkaMYORLKlIHOndNvYyGkgWGKwDCMHMO2bfDVV3DbbVCwYPrtTBEEhimCPE5sLPz3v7B5c6QlMYyM+ewz9RHcfrvvdqYIAsMUQR5n7lx49ln48MNIS2IYGbNgAVStCtWq+W7nVQSWsMY/TBHkcaZN0/fFiyMrh2FkhIgqgpYtM25bvjycPAkHD4ZfrtyAKYI8jAhMn66flyyxp6ecxL33wltvRVqKrGXTJti1C1q0yLithZAGhimCPMzq1eobaNwY9u+HjRsjLZHhD3FxMGqU5uHPS/zyi777OyMAUwT+YoogD+OdDYwYoe9mHsoZbNgAx49rwrV//420NFnHggVac6B27YzbmiIIDFMEeZhp06BpU2jXDs4+2xRBTmHlysTP8+dHTo6s5pdfoFkziIrKuG25cvpuisA/TBHkUbZv11qvnTpBgQLQsKH6CYzsz8qVOhiedRbMmxdpabKGQ4fUlOmPWQg0EV2JEqYI/MUUQR7lq6/0/XpPiaDGjWH5ck3kZWRvVq6Eiy/W2VxeUQS//qrBDP44ir3YWgL/MUWQR5k2DS64AGrV0u0mTbTk3x9/RFYuI2NWrYJ69aBVK1XeR49GWqLw88svkC+fKj9/MUXgP+GsWVzJOTfbObfWOfeHc+6eNNoUd8595Zxb6WnTL1zyGIkcOQI//aRmIed0X5Mm+m5+guzNgQOwdWuiIoiLg4ULIy1V+FmwQL9zIBXHrIi9/4RzRhAL3C8iNYFmwGDnXK0UbQYDa0SkHtAWeMU55yODiBEKvv8eTp9ONAuBrtQ899zQ+wni4/VlhIZVq/S9Xj1o3lyfknO7eSg2FhYtCswsBKoIdu60/z9/CJsiEJGdIrLc8/kIsBaokLIZUNQ554AiwH5UgRhhZPp0HfSTOt6cUz9BqGcEN90E11wT2j7zMt6IoXr1NJSyfv3crwhWr1bzl7+OYi/ly6sSyUshtsGSJT4C51w0Wsh+UYpDbwM1gR3AauAeEUmlv51zA5xzS51zS/fu3RtmaXM3sbHwzTfQoQPkz5/8WJMm8PvvcOxYaK7100+aJGzBAnsqCxUrV2oK5vPP1+3WrdWRevp0ZOUKJ96FZIHOCCp4HjvNT5AxYVcEzrkiwFRgiIgcTnH4KmAFUB6oD7ztnCuWsg8RGSUijUSkUZkyZcItcq5mwQJdRdypU+pjTZrogL18eeavEx8P99+vn48dM1ttqFi5EurWTfTttGqlOXWWLYusXOFkwQId1CtXDuw8W1TmP2FVBM65AqgSGC8in6fRpB/wuSh/A5uAGuGUKa8zbZrmcW/fPvWxxo31PRR+gnHjYMWKxJqya9dmvs+8TmysRnXVq5e479JL9X3u3MjIlBV4E815lZ+/mCLwn3BGDTlgNLBWRF5Np9lWoJ2n/XnAxYBlvAkT3iRz7dqlHX1x3nn61JVZP8Hx41rjoHFjeOIJ3bduXeb6NGD9en36T6oIypbVNQW51U+wbZtGSQVqFoJE85kpgozJn3GToGkJ9AZWO+dWePY9DFQGEJGRwFPAWOfcasABQ0XEXDthYs0azVPzwAPpt2nSJPOK4NVX1RQ0caIql5IlTRGEgqSO4qS0agVTpqg5Ll8uWxkUSKK5lBQsqP4UUwQZEzZFICLz0cHdV5sdQBpGCiMceGsPJA0bTUmTJjqo7N2rP6JA2bULnn8eunRJNFvUqGGmoVCwcqU6+GvWTL6/dWv44AN19NetGxnZwsUvv2i6iJTKz19sUZl/5LLnB8MX06erucZrO00L78KypUuDu8Zjj8GpU6oMvNSsaTOCULBypd7LlLV6W7XS99xoHlqwQP8nCxQI7nxTBP5hiiCPsHOnLsrxNRsATT7nXHDmod9/h9GjYfBguPDCxP01auhMwapFZQ5vaomUVKkCFSvmPofxsWPw22/BmYW8mCLwD1MEeYSvv9b3tMJGk1K0qOYfCkYRPPigLnJ67LHk+72mDJsVBM++fep3SUsROKezgnnzcleVuSVLNIVGMI5iL+XLw+7dGnFlpI8pgjzCtGkQHQ116mTc1uswDmRQmTkTvvsOHn1UVy0npYYnINgUQfCk5yj20qqVzvpyU5W5BQv0vXnz4PsoX16d6Hv2hEam3IopAg8LFqR+ks0tHDsGP/yQPMmcL5o00WX5W7b4139cnEYiVaumZqGUREerXdscxsGTkSJo3Vrfc5Of4JdfdHZasmTwfdhaAv8wRYA++f7f/8FTT+XOp9aZM9WBm5F/wEugmUjHjNF8MC+8oMVSUpI/P1x0Ue68t1nFypUaF1+2bNrHa9bUmVhuUQTx8aoIMuMfAFME/mKKAJgzJzGtwhdfRFSUsDB9ulZr8kaXZERMjA7o/iiCo0fVHNSiBXTtmn47CyHNHN7UEumRL5+G6+YWh/HatRpcYIogazBFALz8sj5p1a8fHkUQF6eLrCJhp4yN1WpkHTr4H4JXoAA0aOCfInjqKY0IeuUV32anmjXVfn3qlH8yGImcOaOLATOKpW/VCv7+W/8eOZ1gE82lpGxZVZKmCHyT5xXBmjXw7bdw112aMnnJEl3SHkpmzNAEbCNHhrZff/jpJ4046dYtsPOaNNFEZr6iLX79VZVo//5aVNwXNWqoQtywITA5DPjzT80u6o8igNxhHlqwQBc0Vq+euX7y59fV7aYIfJPnFcGrr8LZZ8OgQdC5s+778svQXmP0aH2fPTu0/frD5MlQpAhcfXVg5zVpojmD0jPnnDgBfftq/Porr2TcnzdyKK+Yh44ehSef1GpwmSUjR7GXhg11FW5uUAS//KKzgUATzaWFrSXImDytCHbt0iyZfftC6dLq0KxTBz5PK09qJq7x1Vf6A124UJOGZRVnzuh36dQJChUK7FxvJtL0zEOPPKJPqh9+qGsHMuLii/U9rziMP/5YE+6FYha4cqVGXXnvYXoUKKChljldEezZown2Musf8GKKIGPytCJ45x0dLO+9N3Ffly76QwqVPf+jj9QkMmKE2sezsr7sjz9qjdsbbwz83OrV1cGcVkrqefPgtdfgzjs1k6k/FC6smU3zyoxgwgR9f//9zBflWbkSatf2z8fTqpW2P3Qoc9eMJN7fiCmCrCPPKoLjx+Hdd/VpOWk6hM6d9Yc7fXrmryGiZqFWrdSOni9f1pqHJk/Wp/W0ag9kRL58aZeuPHYM+vXTtQEvvBBYnzVq5I0ZwT//wPz5aqrZsAFmzcpcf6tW+Z9MrlUr/b/zLsbKiSxYoDOghg1D01/58ppE0QIV0ifPKoKxY7VSl7eKlpd69aBq1dCYh+bN0ylu//5QvDhccknWKYLTpzUC6oYb0o7t94cmTXQQOnEicd/w4Tq4jRmjvodA8Cafy01pENJi8mR9HzdOo1befTf4vvbsUfOiv9k3mzVTB2lONg8tWACNGgVuzkwPbwhpZqOp4uPh00+T/x5yC3lSEcTFqWmjadPU00/n1Dz0ww+Zn16PHq1P5N6Incsu08Rvx49nrl9/mDVL47B79Ai+j8aN9V799ptuz54Nb70F99wDbdoE3l+NGjqj2LYteJlyAhMm6EBWqxbcdpvmeQo2Es1fR7GXc87Ra+dURXDqlGa+DZVZCEK3luDbb6FXr+SZdXMLeVIRTJ+u8dYPPJB2VEKXLuo7+Oab4K9x6JAWbv/Pf/THCaoIzpzJmmn75Mlq47/yyuD78K4wXrJEo19uvVXNaM8+G1x/eSH53Pr1Gnbbs6du33GHzoBGjQquv0AVAah5aMmSrA1MCAUiGml1+nRiyoxQECpF4J3pvf66+t5yE3lSEbz8spp/vOGiKWnWTJfzZ8Y8NGGCTiFvuy1x36WX6rQ93OahU6c0BLZz59S56wOhXDkND128WDOLbtmiJjWvYguUUIeQxsZqMr24uND0FwomTtSHC+9MrEoVXcz3wQc6wAXKypVauL1UKf/PadVKr5XZSnNZiQg8/DA895wqz2uvDV3foVAEJ0/q/1rz5nD4MLzxRmhkyzaISI56XXLJJZIZfvlFBETefNN3u0GDRM45R+TYseCuc8klIvXqicTHJ9/fvLlIs2bB9ekv06frd5wxI/N9dekiUqSI9vfAA5nrKz5epEQJvbeh4LXXVK533glNf5klPl6kZk2R1q2T7//2W5Vz0qTA+4yJEbn22sDO2bdPJF8+kQcfDPx6kSA+XuShh/QeDRokEhcX2v7j4kQKFBAZNiz4Pr78UuX77juRG24QKV5c5MCB0MmYFQBLJZ1xNWwDNlAJmA2sBf4A7kmnXVtghafNzxn1m1lF0LWrDkZHjvhuN2uW3p0vvgj8Gr/9lr6yefhhkagokcOHA+/XX26+WaRkSZHTpzPf13PP6XepUUPk+PHM99e8uchll2W+n6NHRcqWVdnOOy/jv2dWsHKlyvPuu8n3x8WJVK0q0qZNYP2dOiWSP39wA1j37jpYhfP/LBTEx4vcf7/et8GDUz84hYrKlUVuuSX48//zH5FSpfQ3tXy5yvvkk6GTLyuIlCIoBzT0fC4K/AXUStGmBLAGqOzZLptRv5lRBH//rU9Kw4dn3Pb0aR1Me/cO/Dp33SVy1ln6ZJYSr4L59tvA+/WHEydEihYVue220PT3228i558vsmhRaPrr10/7yywvvaT38eWX9X3EiMz3mVmGD1clv2dP6mPPP69y/vGH//2tWKHnTJgQuCyLFum5r70W+Lm+iIsTmTgxOJlSEh8vcu+9Kufdd4dPCYjoLPyKK4I79/hxnRXffnvivuuv1wfKgwdDI19WEBFFkOpCMA24MsW+O4GnA+knM4rgrrt0irh9u3/t+/TRP/apU/5f4/hxPadnz7SPHzumMmTWzJIe3ins99+Hp//M8uKLKl9mptVHjoiUKSPSvr1ud+6syi+tATiriI/Xp/6rrkr7+J49IgUL6v+gv3z0kd6rNWuCk6l1a30SPnMmuPOTEh+vJseYGJWpYMHMDYLx8SL33KN93XNPeJWAiJo4a9UK7tzPP1c5Z81K3Ld0qe576qnQyJcVRFwRANHAVqBYiv2vA+8Ac4BlwC3pnD8AWAosrVy5clA3Yd8+tfn37ev/OdOmBT6ojh+v5/z4Y/ptWrVSH0I46NlTp7Ch+PGHA6//4tdfg+/D+3S9cKFur1mjM7177gmsn48+EnnhheDlSMqvv6pMY8ak36ZXL5Fixfw3Y913n0ihQsH/Lb33+tNPgzvfy5w5Ii1aaF8XXCDyyCP6+ZNPgusvPl5nAKAzgnArARFVwCVKBHfuTTeJlC6d+u/QsaNaDQ4dyrx8WUFEFQFQxDPId0nj2NvAr0BhoDSwHrjIV3/BzgjGjNFvu2qV/+ccPy5SuLDIHXf4f85ll+mToS+H12OP6cAVameTV94BA0Lbbyj566+MB0xfHD6siu6aa5Lv799fZ1obN/rXz/ffizinr7Vrg5MlKUOGZPyUvGCBfvf33/evz3btRBo1Cl6muDiRiy8WadgwuMF22TKd4YBI+fIiI0eqyTQuTrc7dw5Orv/7P+3z/vuzRgmIiDz7rF4z0OCPY8fSHwOWLNE+n3kmNDKGm4gpAqAA8D1wXzrHhwFPJNkeDXT31WdmTEPB/OC7d1dnZGxsxm3//lvv6NNP+243e7a2mzYtcHl8MXWq9vvDD6HtN5ScOaMD5tChwZ3/zDP6HVP6LLZt06fnm2/OuI+NG0XOPVdNBYUKidx6a3CyeImNFSlXTqNJfBEfL1K3rkj9+hkPgPHx+hSaWV/PqFF6v376yf9zdu4U6dZNzzv3XPXHpAwUuPtuvXeBOun/+EPC7hhOi7Fj9bp//x3YeZ995nuG36GD3qPs7pQXiZAiABzwMfC6jzY1gR+B/MA5wO9AHV/9ZjZqKFAmTNC7NG9exm0fflif9Ldt893uxAl1Jg8ZEhoZvdx4o9rOs6tZyEvt2upsC5RDh3Qq3rFj2seHDtUn/BUr0u/j2DEdiEuU0EHhzjt1JpHR38wXXsXuT3joyJGSzKyVHjt2aLs33gheLhH9XytbNvUMKj3OnBFp2VIH+UcfTX+GM2eOyjd5cmDyPPSQRkLt3h3YeZll5kyVd+7cwM7r3l3vX3oPgosXa7/PPZd5GcNNpBTBpYAAqzzhoSuAa4GBwMAk7R70RA79DgzJqN+sVgSHDukT7L33+m535ow+FXbo4F+/l12m6wxCxbFj6gMZODB0fYaLbt1ELroo8PNGjND/2KVL0z6+f78qivQGvfh4jQJzTuSbb3Tfxo0a6XP//YHL4+WOO9R8cPRoxm2PHFHHdkbRaDNm6HedMyd4ubw89ZT2tXp1xm2HDdO248f7bhcbqwNkjx7+y+H9jQTzEJBZfv9dv9fEif6fc/SoyNln68OCL665Rs2V2SGE2RcRdxaH8pXVikBEB/cqVXxPZb/6Su/m55/716d3UPv335CImDCFnT07NP2Fk0ce0cE3kGisAwc0Lr5TJ9/tvFFJad2Ht96SNOO/e/bU8MD9+/2Xx8vp0zoIpBcllhZ33qkzwr170z4eH584eAcjU0r+/VcHtH79fLfzKp+kYZK+GDhQFaC/60u8C+v8/Y2Ekv379dqvvur/ORMn+qeMvYECoQo8CBemCDLJ6NF6p5YtS77/1CmNWPniC42qKFvW/0Vc8+Zpn1OnhkbGbt3892VEmk8+kYBj6h9/XM/57Tff7Y4fF6lYUaRJk+SKe+5cNUlcd11qR743Xj8j305aeAe36dP9P2f1aj3nxRd1e/t2Pf+xx/Sh4/zz9Xi1aoHLkx6DB6sJbMeOtI9v26Y+iZgY/wf2QBdd9uihSjOQB4BQER+v5q5Awra7dNG/hT+/qauuUrOsP7PCSGGKIJPs3au2/+uv15C+Dh1EqlfXp1rNkhL408apU2rKCSSuPD2OHNEnvsGDM99XVrBsWWBKcP9+Dbvs0sW/9l7FPWWKbm/frkrywgvTt3lffbX+kANdPd27t/obTp4M7LxWrXSG4x30Qf/HatfW9StvvqkRVqHCu5gyrVXKZ86oPIULBxZQ4Z0N9eqVcdv9+9XE+n//53//oaZaNV0h7A+HD6viuPtu/9p7U9e89FLw8oUbUwQhwBtGV6iQRn50764mjnHj1GEUzOKaK6/UH35m8U5hf/45831lBUePBvYE7o1b9zf098wZjQi66CL1nTRvroPc77+nf47X4ZsyPYQvjh8PfhX3rFm6lqR3b3UIz58f/qfJbt1UaaWMcHn4Yf3u48YF3uett6qSzkgRvvuuXmP58sCvESouvVSkbVv/2n76qfgdJOLlyivVKvDPP8HJF25MEYSAo0dFtmwJbUIsb2xzZiIo4uM13rxcuZxhFvJSubJ/oZ7//qv2++7dA+vfu8K6Th3xK7olPl6kaVNdA+Jv1NWUKZJqxWl2xmvLfv31xH3ffafO82DDVL2msa+/9t2uaVN9gMrKkNGU9Ojhf5DCDTfoWolAfu/Ll+uDQYUKmncqu2GKIJuycKH4HXaYHt7w1qQ/7pxA+/b+LZYaPlwHKl9P82kRH5+4GtbfLJzeVAL+5tHp1k2fALN7uG5SLr1UAx/OnFGTWZkyqiyDzbJ76pSauHyt2F+zRgI2nYaDIUP0oSIjDh1SZ36gK9VF1N9UoYIqhO++C/z8cGKKIJty+rT+YwYb8rl/vw5EjRrlrNmAiNqKixTx/YS4caOadG66Kbhr/Pmnzrr8Hai9K3H9WfD1zTc6WOQUv4wX70xp3DjNhnrOOcHnMvLSu7fvbLdDh0Zm7UBKvBFlGS3+GjdO2y1YENx1tm3T0N9QRA0AACAASURBVPCoKJEPPgiuj3BgiiAbc801OvgEw+236z9bRpE02ZH33tP/vvTsqSdPqg29RAmRTZuyTi6vozm9p7nYWJH//lfb1KuXuYVokSAuTs0jhQrpd/joo8z36SsnV2ysmlgisXYgJd5otXXrfLe77jqRSpUyZwY+dCjRr/jf/0bWJObFFEE2xvuU4m9GVC9z5+p54cpiGm68ztmZM9M+7k1KFkw9iMxw8qQOXGnVTNi9W/0xoDH5oajPEAnefz/xO4SCEydSp2n24l2bEIm1Ayn56SfxmS5CRNerFCyo0YGZ5fRpzYEFGq0UaGRZqDFFkI3xprPNaCVnUk6e1EIxVapk77hlX+zapd87reI93sVxGa3mDhfeGgdJ8xktWKC230KFdNaQkzlzRkN3Q6nIbrop7fQmN94YubUDKVm3TjKMjvKm/s5MdtykxMcn5sdq3TrtGiVZhSmCbExsrJo/+vf3/5wnn9S/XLiK22QF3rKVKZfv//23hiM2bRq5wePwYZWtSxeV87XX1MZ9wQU50wyXFXiVd9Lkdvv3qx8lkmsHknL4sPhcAXzggBavySiLQDCMH68zjRIlNJdT374aPj1pkkYbZUXSOl+KIH+qIsZGlhIVBa1b+1/Qft06eOYZuOkmuOaa8MoWTpzTYvZJC9mfPAndu+s9mTQJChaMjGxFi8LgwfDss1p4fsYMuOEGGDMGSpSIjEzZnWuugbPPhqlT4bLLdN+kSXDqFPTpE1nZvBQtCkWKwPbtWsj+t9+SvzZt0naPPqr/n6HkP/+BqlVh9Gj4+2+YORPGjk3e5rzzoF8//b8L9fUzJD0NkV1fuW1GIJJYhP2993xHuMTHa6RHiRJqWsnp9Oun6x+8DBokAadrCBe7d6sZKCpK/TjZwdmX3enaVVdKe52sTZtqyorsdO8uukhXWCfNCFC9uq5TefZZDRII5VohXxw9quGmU6Zo9tLrrlN5XnklPNfDTEPZm717dfUrqO3/iy/S/vF4I1pGjcp6GcPBCy/o9zl4MHF1dHZyfs+aFbpazXmBpKtxvWsHwjWoBcuoUWqWeeMNDbjITtXF4uJUmToXnochUwQ5gPh4VQA1auhfpXnz5LnTd+/WWO1WrbLuiSXceEspfvyxRp20aOF/0j4j++FdiDVkiK4diIrKHTPXrOTYMQ2bLlzYd12NYPClCPJlsSXKSAfn1A69ejX873+wZYv6Dq6/Hn7/He69F44ehfffh3y55K9Wo4a+9+8PZ50FEydCgQKRlckInmLFoH17mDIFxo2Da69Vu7fhP+ecA9Onqy/quutg586suW4uGVJyD/nz68C4fj089xzMnQt168Knn8Lw4VCzZqQlDB1Vq6pD+PRpHTgqVYq0REZm6dYNtm1TZ2zfvpGWJmdSvjx89RXs2wedOsGJE+G/ptMZQ86hUaNGsnTp0kiLkWXs2wfPP6+KYeJEKFQo0hKFlttvh+rVYejQSEtihIIDB3QWUKyYKoNIRX7lBr78Erp0UeU6cWLmLQHOuWUi0iitYxY+ms0pVQpeeinSUoSP//0v0hIYoaRkSRg2DM4/35RAZrnhBnjhBXjoITWjjhgRvmuFTRE45yqhxevPB+KBUSLyRjptGwO/AjeKyJRwyWQYRvgJ54CV13jgAV079NRTcPHF0KtXeK4TzhlBLHC/iCx3zhUFljnnZonImqSNnHNRwAvA92GUxTAMI8fhHLz3HmzYALfeCtHR0LJl6K8TNmexiOwUkeWez0eAtUCFNJreDUwF9oRLFsMwjJxKwYK6YrtyZfjpp/BcI0t8BM65aKABsCjF/gpAZ+ByoLGP8wcAAwAqV64cLjENwzCyJaVKwbJl6oQPB2EPH3XOFUGf+IeIyOEUh18HhopInK8+RGSUiDQSkUZlypQJl6iGYRjZlnApAQjzjMA5VwBVAuNF5PM0mjQCJjrNsFQauNY5FysiX4ZTLsMwDCORcEYNOWA0sFZEXk2rjYhUTdJ+LPC1KQHDMIysJZwzgpZAb2C1c26FZ9/DQGUAERkZxmsbhmEYfuKXInDOXQBsE5FTzrm2QF3gYxE5mN45IjIf8Durtoj09betYRiGETr8dRZPBeKcc9VRc09V4NOwSWUYhmFkGf4qgngRiUVDPV8XkXuBcuETyzAMw8gq/FUEZ5xzPYE+wNeefZYw2DAMIxfgryLoBzQHnhGRTc65qsAn4RPLMAzDyCr8chZ78gP9H4BzriRQVESeD6dghmEYRtbg14zAOTfHOVfMOXcusBIY45xLc22AYRiGkbPw1zRU3JMeogswRkQuAa4In1iGYRhGVuGvIsjvnCsH9CDRWWwYhmHkAvxVBCPQegEbRGSJc64asD58YhmGYRhZhb/O4s+Az5JsbwS6hksowzAMI+vw11lc0Tn3hXNuj3Nut3NuqnOuYriFMwzDMMKPv6ahMcB0oDxaZewrzz7DMAwjh+OvIigjImNEJNbzGgtYhRjDMIxcgL+K4F/n3M3OuSjP62ZgXzgFMwzDMLIGfxXBrWjo6C5gJ9ANTTthGIZh5HD8UgQislVErheRMiJSVkRuQBeXGYZhGDmczBSvvy9kUhiGYRgRIzOKwO/qY4ZhGEb2JTOKQHwddM5Vcs7Nds6tdc794Zy7J402vZxzqzyvX5xz9TIhj2EYhhEEPhWBc+6Ic+5wGq8j6JoCX8QC94tITaAZMNg5VytFm01AGxGpCzwFjArye2TM2rXQsyd89RWcPh22yxiGYeQ0fCoCESkqIsXSeBUVEZ/pKURkp4gs93w+AqxFF6MlbfOLiBzwbP4KhG+18vr1MGsWXH89lCsHAwfC3LkQHx+2SxqGYeQEMmMa8hvnXDTQAFjko9ltwIx0zh/gnFvqnFu6d+/e4IS4/nrYuRO+/hquvhrGjYM2baBKFXjoIVixAsSntcswDCNX4iTMg59zrgjwM1rm8vN02lwGvAtcKiI+F6o1atRIli5dmnnBjh2D6dPh00/hu+8gNhYaNoQPPoAGDTLfv2EYRjbCObdMRBqldSysMwLnXAFgKjDehxKoC3wAdMpICYSUwoUTfQa7dsG77+qMoUkTeOopVQyGYRh5gLApAuecA0YDa0UkzbKWzrnKwOdAbxH5K1yyZEipUjBoEPz+O3TvDo89Bi1awLp1ERPJMAwjqwjnjKAl0Bu43Dm3wvO61jk30Dk30NPmMaAU8K7neAhsPpng3HPVVDR5MmzcqCai1183h7JhGLmasPsIQk3IfAQZsWsX3H67OpfbtoUxYyA6OvzXNQzDCAMR8xHkaM4/X53Jo0fDsmVQty589FGkpTIMwwg5pgh84RzceiusWqURRX37wh13wKlTkZbMMAwjZJgi8IfoaPjxRxg+HEaNglatYOvWSEtlGIYREkwR+EtUFDz7LHz+uUYTXXKJKgfDMIwcjimCQOncGZYuhfPOg/bt4fnnbUWyYRg5GlMEwXDRRfDrr7rmYPhw6NoVDh+OtFSGYRhBYYogWIoUgQkT4LXXNLqocWONLjIMw8hhmCLIDM7BkCEwe7bOCBo10rQVf/8dackMwzD8xhRBKGjVSh3Ijzyis4OaNTVlxY4dkZbMMAwjQ0wRhIrixTVZ3YYNWutg9GioXl19CAcOZHy+YRhGhDBFEGrOPx/eektnCF27wgsvQLVqGl1kC9EMw8iGmCIIF9WqafGbFSvg0kt1ZtCmjaa6NgzDyEaYIgg3detqzYOpUzXNdaNGsGRJpKUyDMNIwBRBVtGlCyxcCAULqnP5k08iLZFhGAZgiiBriYnR2UDz5tC7Nzz4IMTF+T5HRM+ZMcPqIhiGERZMEWQ1pUvDzJlw113w8svQoUPqqKLYWPjpJ7j7bqhcWctnXnut5jf66afIyG0YRq7FFEEkKFBAI4tGjdKBvWlTdSpPnw79+mkeo3bt4IMPdPAfOxY+/lgVRrt20LEjrFkT6W9hGEYuIWwVypxzlYCPgfOBeGCUiLyRoo0D3gCuBY4DfUVkua9+s6xCWVYxf76Gme7Zo9vFi8N112lyu6uugsKFE9uePAlvvgnPPANHj2oFtSefVMXhCxFdBW0YRp7FV4WycCqCckA5EVnunCsKLANuEJE1SdpcC9yNKoKmwBsi0tRXv7lOEYDWNhg3TvMVtW2rDmVf/PsvjBgB770HhQrBsGFw442wbRts2ZL6tX073HKLtjeFYBh5kogogjSEmAa8LSKzkux7H5gjIhM8238CbUUk3WD7XKkIguWvv2DoUPjyy9THypWDKlX0FRcHU6ZoCoynnsp6OQ3DiDi+FEH+LBIgGmgALEpxqALwT5LtbZ59yRSBc24AMACgcuXK4RIz53HRRfDFFxqWum6dOparVIFKleCssxLbiagZ6emnoWpVLb9pGIbhIeyKwDlXBJgKDBGRlEn707JTpJqiiMgoYBTojCDkQuZ0mjfXV3o4p2ahf/6BAQOgYkUtqmMYhkGYo4accwVQJTBeRD5Po8k2oFKS7YqApewMBwUKwGefQe3a0K0brFwZaYkMw8gmhE0ReCKCRgNrReTVdJpNB25xSjPgkC//gJFJihWDb77R9w4d1LmcWc6cUWe3YRg5lnDOCFoCvYHLnXMrPK9rnXMDnXMDPW2+BTYCfwP/A+4MozwGqFnom2+0kE6HDpkrsRkfDzfcABdfDLt2hU5GwzCylLD5CERkPmn7AJK2EWBwuGQw0qFePY0iuvZarbv89ddqOgqUJ5+Eb7/Vz59+CvfdF1o5DcPIEmxlcV6lfXtd2TxzplZTCzSMePp0XcvQr5+uf/joo/DIaRhG2DFFkJe59VZdWzB6NPzf/2mOI3/4809NmteoEbz7LvTpA6tWaZoMwzByHKYI8jojRsD998Pbb0OnTnDkiO/2R45o+ouCBbXGQqFCcNNNalqyWYFh5EhMEeR1nNMsqO+/D99/Dy1bph8FJKKmoD//hEmTdAEbQKlSmh9p/HiNIjIMI0dhisBQBgzQmgdbt2ra68WLU7d58UWdBbz4Ilx+efJjffrA3r3w3XdZI69hGCHDFIGRyJVXwi+/wDnnaH3lKVMSj82aBQ8/rMnt0ooOuuYaKFPGzEOGkQMxRWAkp1Yt+PVXaNBAQ0ufew42bVI/QK1a6lhOK4NpgQLwn/9ofeb9+7NebsMwgsYUgZGasmW1YE7PnjoLaNBAF4998UXy+ggp6dMHTp+GiROzTlbDMDKNKQIjbQoVUufv44/r4D5+PFSv7vuc+vW1LrOZhwwjR2GKwEgf5+CJJzQNxbXX+te+Tx91NK9bl/nrHzyoC9cyCmk1DCNTmCIwMiZ/AJlIevWCqKjgZwU7dmjK7Pbt1fncqZOufDYMI2yYIjBCy/nnw9VXa+nNuDj/zlm/XkNSmzeHChXgzjth82aNTrrjDjVLzZqVYTcBM3UqvPNO6Ps1jBxGllQoM/IYffpohtOfftKQ1PTYtUvDUefO1e1LLtEqap07Q82aamo6eRJmz4aBA2H1ag1tDQVjx2qKDRH1h9x2W2j6NYwciM0IjNBz3XVQooRv89Dq1bpwbdkyeOUV2LIFli6F//5Xw1S9IaqFCumq540bQ1dv+eOPVQlccYUqqkGDdP2EYeRRTBEYocebf+jzz9OudzBjhqayiIuDefPUBOSrFnXbtpra4uWXVYFkhvHjoW9fXRk9bZqGulauDF26hKZQj2HkQEwRGOGhTx84cSL56mRQm3zHjhqKunixrlHwh5de0lnGgAG6piEYJkyAW25RxTJ9Opx9Npx7riqEY8fUJHXiRHB9G0YOxhSBER6aNoWLLko0D8XFwZAhcNddWhlt7lx1DPtLqVLw2mu66nnkyMDlmTwZbr4ZWrXS1c9JfQ21a+tMYelSVTSB1mYwjByOKQIjPHjXFMydq+acG26AN95QZfDFF1CkSOB99uqldv3hwzXM1F+mTNH0Fy1aaDW2tFZHX3+9+iA++QReTa/EtmHkTsJZvP5D59we59zv6Rwv7pz7yjm30jn3h3OuX7hkMSJE796qEJo21ZKW77yjT/VRUcH155yuMTh9Wgvp+MMXX2iqDK8MvhTQf/8L3brBQw9pSm7DyCOEc0YwFrjax/HBwBoRqQe0BV5xzhUMozxGVlOpkq4pyJ9fw0nvvDPzfVavDo8+qmsAvvoq/XZr1ujMoUcPraQ2YwYULeq7b+c0rLROHQ1r/euv9NuePKlrHYL1VxhGNsJJGO2hzrlo4GsRqZPGseFAJVQhRAOzgItExOcvq1GjRrJ06dKQy2qEicOH4dQpXSUcKk6fhoYNte81axKf8nfsUIfwJ59o2cyoKDX5jBkDxYv73//mzao8ypTR/v75Rxe9rV8Pf/+t71u3qi+hQwct0uMrGZ9hZAOcc8tEpFGaxyKoCIoC04EaQFHgRhH5Jp1+BgADACpXrnzJli1bwiWykVP45RcNQR00SNcjfPKJLmAT0e2bb9an+rJlg+t/zhz1RyRdHV2yJFx4ob6qV9djzz6rSuPrr0Or7AwjxGRXRdANaAncB1yAzgjqiUgageeJ2IzASGDQoMQIogsu0MG/Vy8dqEPBr7/qDMA7+J97buo206bpmolKlbQ6W7Vqobm2YYSY7KoIvgGeF5F5nu2fgGEikkaNxETSUgRnzpxh27ZtnDx5MlSiGzmB+HjNTFqoEJx1VuTkOHWKQgsXUvG11ygwYYKmyjCMbIYvRRDJXENbgXbAPOfcecDFwMZgOtq2bRtFixYlOjoal1b1LMMIIyLCvrJl2ZY/P1XbtFFH9lVX+Xfy8eOwfXvar3Ll1DEerHnLMPwkbIrAOTcBjQYq7ZzbBjwOFAAQkZHAU8BY59xqwAFDReTfYK518uRJUwJGxHDOUapcOfY2b66+g44dtaTnLbckb7hjh5qbFi3S16pVcOBA6g6LFtXFdtOnq+/jmWc0C2uwYbeGkQFhUwQi0jOD4zuA9qG6nikBI5I453SgnjtX8xb16QN//qkOZu/g781lVKCAVnPr0UPzHFWoABUr6nuFColhrmvX6krswYNVsbz7rq6HMIwQY2moDSOUFCumC9duvVUjigCqVoVLL9VBvFkzVQKFCmXcV82a8MMP8NlncO+9em7//vDcc1C6dHi/h5GnsBQThhFqChbUVNdLl8Lu3ZpCe8IETa/RrJl/SsCLczpzWLcOHnhAF7xdfDGMGmWL2YyQYYogD9C2bVsyG3K7efNm6tRJFfyVime9T8F5nXz5NHooVI7eokU1A+uKFRAToz6DFi0yn5bbMMiNpqEhQ/THEkrq14fXXw9tn7mUZ599locffjhs/cfFxRGVxGkaGxtLfj9qKvvbLttTu7ZWbPv0UzUXNWyouZEefTSwmYZhJMFmBCFi8+bN1KhRg/79+1OnTh169erFDz/8QMuWLbnwwgtZvHgxx44d49Zbb6Vx48Y0aNCAadOmJZzbqlUrGjZsSMOGDfnFUy1rzpw5tG3blm7dulGjRg169eqFr3UfI0aMoHHjxtSpU4cBAwYka/vJJ5/QokUL6tSpw+LFulTj559/pn79+tSvX58GDRpw5MgRRIQHH3yQOnXqEBMTw6RJk1JdZ+zYsdx1110J2x07dmTOnDkMGzaMEydOUL9+fXr16pVw3SZNmlC/fn3uuOMO4nzUMZ45cybNmzenYcOGdO/enaNHjwIQHR3NiBEjuPTSS/nss89o27YtDz/8MG3atOGNN95gy5YttGvXjrp169KuXTu2bt0KQN++fbnvvvu47LLLGDp0qF9/xxyBc7pwbu1afX/2WahbV1dDG0YwiEiOel1yySWSkjVr1qTal9Vs2rRJoqKiZNWqVRIXFycNGzaUfv36SXx8vHz55ZfSqVMnGT58uIwbN05ERA4cOCAXXnihHD16VI4dOyYnTpwQEZG//vpLvN9x9uzZUqxYMfnnn38kLi5OmjVrJvPmzUtXhn379iV8vvnmm2X69OkiItKmTRvp37+/iIj8/PPPUrt2bRER6dixo8yfP19ERI4cOSJnzpyRKVOmyBVXXCGxsbGya9cuqVSpkuzYsUM2bdqUcN6YMWNk8ODBCdfq0KGDzJ49W0REChcunLB/zZo10rFjRzl9+rSIiAwaNEg++uijNGXfu3evtGrVSo4ePSoiIs8//7w8+eSTIiJSpUoVeeGFFxLatmnTRgYNGpSw3bFjRxk7dqyIiIwePVo6deokIiJ9+vSRDh06SGxsbLr3LJRE7P9w1iyRatVEQOS220T27w/Pdc6cEZk7V+Shh0QGDhT56iuR48fDcy0j5ABLJZ1xNRfMlbMPVatWJSYmBoDatWvTrl07nHPExMSwefNmtm3bxvTp03n55ZcBXf+wdetWypcvz1133cWKFSuIioriryRZL5s0aULFihUBqF+/Pps3b+bSSy9N8/qzZ8/mxRdf5Pjx4+zfv5/atWtz3XXXAdCzp0bztm7dmsOHD3Pw4EFatmzJfffdR69evejSpQsVK1Zk/vz59OzZk6ioKM477zzatGnDkiVLqFu3bsD348cff2TZsmU0btwYgBMnTlA2HZv5r7/+ypo1a2jZsiUAp0+fpnnz5gnHb7zxxmTtk24vXLiQzz//HIDevXvz0EMPJRzr3r17MlNSruSKK9RXMGKElvP8+mut/dCjR2Lt52A5cEBTcn/9tWZw3b9fs8kWKqTpPQoX1gyzN9ygCfhKlgzNdzKyFFMEIeSsJGkO8uXLl7CdL18+YmNjiYqKYurUqVx88cXJznviiSc477zzWLlyJfHx8RRKYutN2mdUVBSxsbFpXvvkyZPceeedLF26lEqVKvHEE08kS7mRcp2Fc45hw4bRoUMHvv32W5o1a8YPP/zg0/TkJX/+/MQniVhJL7WHiNCnTx+ee+65DPsUEa688komTJiQ5vHCKbJ7ptxOStLv6qtdruKcc+D55zXv0e236/sjj+gAfcMNGq3kj0I8cwZWroSff9bBf948Ta5XurQulLvuOrjySi3zOWcOfPmlvqZO1f7btNHrde6sayOMHIH5CLKQq666irfeeithsP3tt98AOHToEOXKlSNfvnyMGzfOpx09PbyDcenSpTl69ChTUtQK9tr658+fT/HixSlevDgbNmwgJiaGoUOH0qhRI9atW0fr1q2ZNGkScXFx7N27l7lz59KkSZNkfUVHR7NixQri4+P5559/EnwOAAUKFODMmTMAtGvXjilTprBnzx4A9u/fT3qZY5s1a8aCBQv4+++/ATh+/HiymZEvWrRowcSJEwEYP358ujOmPEH9+rBwoS5Au+ACnRlceqmmq+jfX2s4JK3LvGuXFu956CFo3VrTdTdurKGq+/fD0KGa6XXXLi072q2btilYENq310Vu27bpgrmHHoKdO7VoUKVKet233tJ9RrbGZgRZyKOPPsqQIUOoW7cuIkJ0dDRff/01d955J127duWzzz7jsssuC+optkSJEtx+++3ExMQQHR2dYI7xUrJkSVq0aMHhw4f58MMPAXj99deZPXs2UVFR1KpVi2uuuYaCBQuycOFC6tWrh3OOF198kfPPP5/Nmzcn9NWyZcsEM1idOnVo2LBhwrEBAwZQt25dGjZsyPjx43n66adp37498fHxFChQgHfeeYcqVaqkkr9MmTKMHTuWnj17curUKQCefvppLrroogy/+5tvvsmtt97KSy+9RJkyZRgzZkzA9y9XkT+/Lmi79Vat2TBjhmZJ/ewzVRDnnKOhp+vXg1cxFyigEUh33AHNm+txf5/o8+XT1N9Nmqjj+s8/tTzopEmqFO65R2cKN94IXbtauu5sSFizj4aDtLKPrl27lpo1a0ZIIsNQsv3/4enTas6ZNg3mz4eLLtJBv3lzaNAgPOGna9bA5MmqFNatU/PR5ZdDvXpqbipTJvV78eKZ920YqYhYGupwYIrAyK7Y/6EPRNShPWkSfP65VoFLL218oUKar2ngQDUvmVIICdk1DbURJJ07d2bTpk3J9r3wwgtc5W/q4wjTtGnTBPOPl3HjxiVEXBm5EOd0rUPduppNVURTcO/dC//+m/z9r79g4kRdNFerliqE3r2hRInMy7Fxo5rBKlXKfF+5CJsRGEaIsP/DEHL8uM4eRo6ExYs1Summm1QpNG4c3Czh44/VBwLw8MPq3I5kQaMsxteMwKKGDMPIfpxzDvTrp9FIy5bpjGDyZM3g2rhxYKuoT5/WVN59+mgY7fXXw2OPac6mWbPC9hVyEqYIDMPI3jRsCO+/r4V93ntPTUiXXQY9eybWeEiP7duhbVsNc33gAR34J03SRXIiGgJ7003adx7GFIFhGDmDYsXUNLR2LTz+uC5kq1EDXngBUvicAF0U17ChVoKbPFmzt3oTD7Zvr87rJ59M7Of11yGdBZu5HVMEhmHkLM4+G554QkNTr7wShg1TJ/T33+txEXjtNWjXTh3MixdD9+6p+ylUSE1Ef/wBLVtqNtdGjbQYUA7znWaWsCkC59yHzrk9zrnffbRp65xb4Zz7wzn3c7hkyW4UKVIk0iIETXR0NP/+G1Rp6QTmzJlDx44dfbY5ePAg7777bqauY+RyqlbVVdEzZujA7c15dNNNcN996gtYskQjj3xxwQVaVW7KFNi3T5VLixbwzTd5RiGEM3x0LPA28HFaB51zJYB3gatFZKtzLiQVPKwcQe7AqwjuvPPOsF0jZW2DlNvpkWtqG+QWrr5azTyvvQZPPaXrE557TtNj+Btd5Jyueu7QQavAPf+85lZq0CAxZ1O+MBtQNm3S2c7554f3OmkQtm8mInOB/T6a/Af4XES2etrvCZcs4Wbo0KHJnl6feOIJnnzySdq1a0fDhg2JiYlJqD2QEXPmzKFNmzb06NGDiy66iGHDhjF+/HiaNGlCTEwMGzZsAGDv3r107dqVxo0b07hxYxYsWADA4sWLadGiBQ0aNKBFixb8+eefgNYQ6NKlC1dffTUXXnhhsgyduh+bswAADh5JREFUaTFo0CAaNWpE7dq1efzxx5Mde+mll2jSpAlNmjRJyA302WefUadOHerVq0fr1q0BzX/Ur18/YmJiaNCgAbNnz051nSeeeCIhGytAnTp12Lx5M8OGDWPDhg3Ur1+fBx98MOG6jRs3pm7duqlkSkl6dRCKFCnCY489RtOmTVm4cGGqWgcrVqygWbNm1K1bl86dO3PgwAGAVDUQjGzGWWepiWj9evjtN/0cTIhpoULqh1i/Hj78EI4cUQURE6PrGsLhQ1i+XK9RrZrOTkaNyvqZSHr5qUPxAqKB39M59jrwDjAHWAbc4qOfAcBSYGnlypVT5dmOdD2C5cuXS+vWrRO2a9asKVu2bJFDhw6JiObav+CCCyQ+Pl5EkufsT8ns2bOlePHismPHDjl58qSUL19eHnvsMRERef311+Wee+4REZGePXsm1CbYsmWL1KhRQ0REDh06JGfOnBERkVmzZkmXLl1ERGsIVK1aVQ4ePCgnTpyQypUry9atW9OVw1vbIDY2Vtq0aSMrV64UEa0N8PTTT4uIyEcffSQdOnQQEZE6derItm3bRERrLYiIvPzyy9K3b18REVm7dq1UqlRJTpw4IbNnz0447/HHH5eXXnop4bq1a9eWTZs2Jat/ICLy/fffy+233y7x8fESFxcnHTp0kJ9//jlN2X3VQQBk0qRJCW1T1jqIiYmROXPmiIjIo48+mnC/U9ZASO+6Ri4jNlbk009FatfWeg/Vq4u89ZaI57edKebPF7n6au23eHGRhx8WueIK3e7YUWTXrsxfIwlk03oE+YFLgHbA2cBC59yvIpIq5aSIjAJGgS4oy1Ip/aBBgwbs2bOHHTt2sHfvXkqWLEm5cuW49957mTt3Lvny5WP79u3s3r2b8/2Y9jVu3Jhy5coBcMEFF9C+fXsAYmJiEp6qf/jhB9asWZNwzuHDhzly5AiHDh2iT58+rF+/HudcQiZQ0GygxYsXB6BWrVps2bKFSumssJw8eTKjRo0iNjaWnTt3smbNmoSaBN7aBj179uTee+8FNBFd37596dGjB126dAE00+ndd98NQI0aNahSpYrfGUVTMnPmTGbOnEmDBg0AOHr0KOvXr0+YfSTFVx2EqKgounbtmqy9t7bBoUOHOHjwIG3atAGgT58+dE/iZExZE8HIA0RFaZjqjTdqjqbnn4e774bhw+GWW3R9QkY+iKSIqDP6mWc0qql0aU3Ud+edmmMpPl4ztg4dqrOQ0aM19XeYiaQi2Ab8KyLHgGPOublAPSC4kSLCdOvWjSlTprBr1y5uuukmxo8fz969e1m2bBkFChQgOjo63bz9KcmorgFAfHw8Cxcu5Oyzz0527t13381ll13GF198webNm2nbtm2a/fqqbbBp0yZefvlllixZQsmSJenbt2+6tQ28n0eOHMmiRYv45ptvqF+/PitWrAh5bYPhw4dzh3dlqA/ERx2EQoUKpfID+JvtNc/UNjBSky+f1ljo3Fkd0O+8o4P0u+/qmobBg6FTp8TwVC9HjsCGDYmvqVM1iql8efVp3H67FvdJep177tFiQ716qcN7wAB45RUIY5BJJMNHpwGtnHP5nXPnAE2BtRGUJ1PcdNNNTJw4kSlTptCtWzcOHTpE2bJlKVCgALNnz043D3+wtG/fnrfffjthe4XHQ37o0CEqVKgAqF8gGA4fPkzhwoUpXrw4u3fvZsaMGcmOe2sbTJo0KaGK2IYNG2jatCkjRoygdOnS/PPPP7Ru3Zrx48cD8Ndff7F169ZURXmio6NZvnw5AMuXL0/IoVS0aFGOHDmS0O6qq67iww8/TKhjvH379oQ6BykJpA5CUooXL07JkiWZN28eoPmPvLMDw0igcWN1KG/bpjOEjRu1TkN0tEar3HyzZnQtW1bXPjRooMeHDtUaD++/r+cMGZJcCSSldu3EGg//+5/2sWhR2L5S2GYEzrkJQFugtHNuG/A4UABAREaKyFrn3HfAKiAe+EBE0g01ze7Url2bI0eOUKFCBcqVK0evXr247rrraNSoEfXr16dGjRohvd6bb77J4MGDqVu3LrGxsbRu3ZqRI0fy0EMP0adPH1599VUuv/zyoPquV68eDRo0oHbt2lSrVi2hfKSXU6dO0bRpU+Lj4xMqij344IOsX78eEaFdu3bUq1ePGjVqMHDgQGJiYsifPz9jx45NNisB6Nq1Kx9//DH169encePGCfUHSpUqRcuWLalTpw7XXHMNL730EmvXrk1QPEWKFOGTTz5Js/RlrVq1/K6DkJKPPvqIgQMHcvz4capVq2a1DYz0KV1aB/cHHtDw07ff1leFCur07dQJqlfXz95XsWL+93/WWbpY7tpr1QzVsqWWIh0yJORfxZLOGUaIsP9DA5HwpM0+dAjuukvXSHToEFQXlobaMAwjKwhX7YTixWHcuPD0jSmCiLF69Wp69+6dbN9ZZ53FojDaAdMiJ9cG2LdvH+3atUu1/8cff6RUqVIRkMgwcia5RhGISLJoluxOTExMgoM3kmS14gklpUqVyhb3EPArQsowsiu5IulcoUKF2Ldvn/0YjYggIuzbt49C4aj5axhZQK6YEVSsWJFt27axd+/eSIti5FEKFSpExYoVIy2GYQRFrlAEBQoUoGrVqpEWwzAMI0eSK0xDhmEYRvCYIjAMw8jjmCIwDMPI4+S4lcXOub2Ar8QxpYHMldAKHyZbcJhswWGyBUdula2KiJRJ60COUwQZ4Zxbmt4y6khjsgWHyRYcJltw5EXZzDRkGIaRxzFFYBiGkcfJjYpgVKQF8IHJFhwmW3CYbMGR52TLdT4CwzAMIzBy44zAMAzDCABTBIZhGHmcHKsInHMfOuf2OOd+T7LvXOfcLOfces97yWwk2xPOue3OuRWe17URkq2Sc262c26tc+4P59w9nv0Rv3c+ZIv4vXPOFXLOLXbOrfTI9qRnf1Xn3CLPfZvknCuYjWQb65zblOS+1c9q2ZLIGOWc+80597VnO+L3zYds2eK+Oec2O+dWe2RY6tkXlt9pjlUEwFjg6hT7hgE/isiFwI+e7UgwltSyAbwmIvU9r2+zWCYvscD9IlITaAYMds7VInvcu/Rkg8jfu1PA5SJSD6gPXO2cawa84JHtQuAAcFs2kg3gwST3LZLFG+4B1ibZzg73zUtK2SD73LfLPDJ41w6E5XeaYxWBiMwF9qfY3Qn4yPP5I+CGLBXKQzqyZQtEZKeILPd8PoL+ACqQDe6dD9kijihHPZsFPC8BLgemePZH6r6lJ1u2wDlXEegAfODZdmSD+5aWbDmAsPxOc6wiSIfzRGQn6KAClI2wPCm5yzm3ymM6iojZKinOuWigAbCIbHbvUsgG2eDeeUwIK4A9wCxgA3BQRGI9TbYRIcWVUjYR8d63Zzz37TXn3FmRkA14HXgIiPdslyKb3DdSy+YlO9w3AWY655Y55wZ49oXld5rbFEF25j3gAnTqvhN4JZLCOOeKAFOBISJyOJKypCQN2bLFvROROBGpD1QEmgA102qWtVJ5LppCNudcHWA4UANoDJwLDM1quZxzHYE9IrIs6e40mmb5fUtHNsgG981DSxFpCFyDmklbh+tCuU0R7HbOlQPwvO+JsDwJiMhuz481HvgfOpBEBOdcAXSgHS8in3t2Z4t7l5Zs2eneeeQ5CMxB/RglnHPeAk8VgR2RkguSyXa1x9QmInIKGENk7ltL4Hrn3GZgImoSep3scd9Syeac+ySb3DdEZIfnfQ/whUeOsPxOc5simA708XzuA0yLoCz/3979hEZ1RXEc//4aJQT/hWoRwdoguhICbaWL0oULcVFX0oIW3Ygbs4krURFcdeOmBdGNxS400oILs+hChCgFURREE6MtVKS7CnEhEhAJ4bi4Z5rXNpNEcDJj3+8Dj7m583icOZPJfe++zLn/0Hjz0i5gvNm+LY5DwDngt4j4rvJU23PXLLZOyJ2kDyT1ZrsH2E65h3Ed+Dp3a1feZovt98ofDFHmkhc9bxFxLCLWR0QfsAe4FhF76YC8NYltXyfkTdIySSsabWBHxtGaz2lEvJMb8BNlmmCKMsd4gDL3OAL8kY/vd1BsF4AHwFi+mevaFNsXlMvwMeB+bl92Qu7miK3tuQP6gXsZwzhwIvs3AneAx8AloLuDYruWeRsHhoDl7fidq8S5DfilU/I2R2xtz1vmZzS3h8Dx7G/J59QlJszMau7/NjVkZmZvyAOBmVnNeSAwM6s5DwRmZjXngcDMrOY8EJglSdOVipP3Jb21wnuS+lSpRmvWSZbMv4tZbbyMUqbBrFZ8RWA2j6wLfzJr/t+RtCn7P5I0ksXJRiRtyP61ki7n+gCjkj7PQ3VJ+iHXDLia3wJG0qCkR3mcn9v0Mq3GPBCYzej519TQ7spzLyLiM+A0pVYO2T4fEf3AReBU9p8Cfo2yPsAnlG+GAmwGzkTEFuA58FX2HwU+zuMcbNWLM2vG3yw2S5ImI2L5LP1/UhZ+eZJF8Z5GxGpJzyjlLqay/6+IWCNpAlgfpWhZ4xh9lPLQm/PnI8DSiPhW0hVgEhgGhmNmbQGzReErArOFiSbtZvvM5lWlPc3MPbqdwBngU+BupSqn2aLwQGC2MLsrj7eyfZNStRJgL3Aj2yPAAPy9YMzKZgeV9B7wYURcpyyQ0gv856rErJV85mE2oydX+Wq4EhGNfyHtlnSbcvL0TfYNAj9KOgxMAPuz/xBwVtIBypn/AKUa7Wy6gCFJqygLtnwfZU0Bs0XjewRm88h7BFsj4lm7YzFrBU8NmZnVnK8IzMxqzlcEZmY154HAzKzmPBCYmdWcBwIzs5rzQGBmVnOvARFX6Tm5Ok5FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "plt.plot(epochs[10:], mae[10:], 'r', label='mean_absolute_error')\n",
    "plt.plot(epochs[10:], val_mae[10:], 'b', label='val_mean_absolute_error')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 - 0s - loss: 17.9982 - mae: 2.7862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.786162"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets, verbose=2)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exercise - tuning model parameters <a id='exc' />\n",
    "Please train the above model in the below two scenerios: make the changes on the indicated training configurations (the rest no change). Train both models for 120 epochs. \n",
    "\n",
    "**Scenerio A**:\n",
    "* change the batch size from 1 to 128\n",
    "\n",
    "**Scenerio B**:\n",
    "* change the learning rate (`optimizers.RMSprop(lr=0.001)`) from 0.001 to 0.0002\n",
    "\n",
    "Observe the training and validation MAE curves for both scenerios.\n",
    "\n",
    "Provide your codes & observations in the below boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scenerio A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Build the model and no changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Compile and Train the model for 200 epochs. Change the batch size from 1 to 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Task 3: Plot the MAE (train & test) curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 4: Comment on your model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Scenerio B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1: Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Task 2: Compile and Fit the model. Change the learning rate from 0.001 to 0.0002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Task 3: Plot the MAE (train & test) curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Task 4: Comment on your model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
