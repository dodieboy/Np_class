{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Practical 2b - Predicting House Prices</h2><h3>AY2020/21 Semester</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras:  2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print('keras: ', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "After completing this practical exercise, students should be able to:\n",
    "1. [Build a neural network model to predict house prices](#demo)\n",
    "2. [Exercise- tuning several model parameters](#exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predicting house prices (a regression example) <a id='demo' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Boston Housing Price dataset\n",
    "\n",
    "We will be attempting to predict the median price of homes in a given Boston suburb in the mid-1970s, given a few data points about the \n",
    "suburb at the time, such as the crime rate, the local property tax rate, etc.\n",
    "\n",
    "The dataset has only 506 samples, split between 404 training samples and 102 test samples. Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1290e-02 2.0000e+01 3.3300e+00 1.0000e+00 4.4290e-01 7.6450e+00\n",
      " 4.9700e+01 5.2119e+00 5.0000e+00 2.1600e+02 1.4900e+01 3.7707e+02\n",
      " 3.0100e+00]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can see, we have 404 training samples and 102 test samples. The data comprises 13 features (details are shown below) and each \"feature\" in the input data (e.g. the crime rate is a feature) has a different scale. For instance some values are proportions, which take a values between 0 and 1, others take values between 1 and 12, others between 0 and 100...\n",
    "\n",
    "1. Per capita crime rate.\n",
    "2. Proportion of residential land zoned for lots over 25,000 square feet.\n",
    "3. Proportion of non-retail business acres per town.\n",
    "4. Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "5. Nitric oxides concentration (parts per 10 million).\n",
    "6. Average number of rooms per dwelling.\n",
    "7. Proportion of owner-occupied units built prior to 1940.\n",
    "8. Weighted distances to five Boston employment centres.\n",
    "9. Index of accessibility to radial highways.\n",
    "10. Full-value property-tax rate per $10,000.\n",
    "11. Pupil-teacher ratio by town.\n",
    "12. 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
    "13. % lower status of the population.\n",
    "\n",
    "The targets are the median values of owner-occupied homes, in thousands of dollars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prices are typically between $10,000  -  $50,000. If that sounds cheap, remember this was the mid-1970s, and these prices are not inflation-adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preparing the data\n",
    "\n",
    "It would be problematic to feed into a neural network values that all take wildly different ranges. The network might be able to \n",
    "automatically adapt to such heterogeneous data, but it would definitely make learning more difficult. A widespread best practice to deal with such data is to do feature-wise normalization: for each feature in the input data (a column in the input data matrix), we will subtract the mean of the feature and divide by the standard deviation, so that the feature will be centered around 0 and will have a unit standard deviation. This is easily done in Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the quantities that we use for normalizing the test data have been computed using the training data. We should never use in our workflow any quantity computed on the test data, even for something as simple as data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39914449  0.35890566 -1.14281587  3.89358447 -0.97702129  1.9437178\n",
      " -0.69198737  0.72576261 -0.51114231 -1.1428069  -1.62718308  0.23710757\n",
      " -1.34300395]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Building our network\n",
    "\n",
    "\n",
    "Because so few samples are available, we will be using a very small network with two \n",
    "hidden layers, each with 64 units. In general, the less training data you have, the worse overfitting will be, and using \n",
    "a small network is one way to mitigate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu',\n",
    "                        input_shape=(train_data.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network ends with a single unit, and no activation (i.e. linear layer). This is a typical setup for scalar regression. Because the last layer is purely linear, the network is free to learn to predict values in any range.\n",
    "\n",
    "Note that we are compiling the network with the `mse` loss function -- Mean Squared Error, the square of the difference between the predictions and the targets, a widely used loss function for regression problems.\n",
    "\n",
    "We are also monitoring a new metric during training: `mae`. This stands for Mean Absolute Error. It is simply the absolute value of the difference between the predictions and the targets. For instance, a MAE of 0.5 on this problem would mean that our predictions are off by \n",
    "\\$500 on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/200\n",
      "323/323 [==============================] - 2s 5ms/sample - loss: 178.4693 - mae: 10.2227 - val_loss: 44.1963 - val_mae: 4.4928\n",
      "Epoch 2/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 28.1654 - mae: 3.4941 - val_loss: 25.2607 - val_mae: 3.5833\n",
      "Epoch 3/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 19.5540 - mae: 2.8768 - val_loss: 14.9192 - val_mae: 2.7480\n",
      "Epoch 4/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 16.3263 - mae: 2.5914 - val_loss: 14.1526 - val_mae: 2.6899\n",
      "Epoch 5/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 13.8739 - mae: 2.4639 - val_loss: 15.7096 - val_mae: 2.7501\n",
      "Epoch 6/200\n",
      "323/323 [==============================] - 1s 5ms/sample - loss: 13.3816 - mae: 2.3355 - val_loss: 12.2108 - val_mae: 2.5636\n",
      "Epoch 7/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 12.3194 - mae: 2.3106 - val_loss: 13.0787 - val_mae: 2.6156\n",
      "Epoch 8/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 11.7457 - mae: 2.2381 - val_loss: 11.2301 - val_mae: 2.4876\n",
      "Epoch 9/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 10.6212 - mae: 2.1618 - val_loss: 11.5772 - val_mae: 2.4939\n",
      "Epoch 10/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 10.5609 - mae: 2.1511 - val_loss: 10.8123 - val_mae: 2.5199\n",
      "Epoch 11/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 10.0451 - mae: 2.0690 - val_loss: 11.0783 - val_mae: 2.4292\n",
      "Epoch 12/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 9.7416 - mae: 2.0957 - val_loss: 10.8863 - val_mae: 2.5368\n",
      "Epoch 13/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 9.3146 - mae: 2.0244 - val_loss: 11.2131 - val_mae: 2.5660\n",
      "Epoch 14/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 9.0015 - mae: 2.0264 - val_loss: 13.9787 - val_mae: 2.8079\n",
      "Epoch 15/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 8.8721 - mae: 1.9159 - val_loss: 12.0659 - val_mae: 2.5275\n",
      "Epoch 16/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 8.6919 - mae: 1.9561 - val_loss: 12.2907 - val_mae: 2.4416\n",
      "Epoch 17/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 8.2272 - mae: 1.9110 - val_loss: 15.0046 - val_mae: 2.7846\n",
      "Epoch 18/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 8.4884 - mae: 1.8930 - val_loss: 13.8053 - val_mae: 2.5226\n",
      "Epoch 19/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 8.0845 - mae: 1.9082 - val_loss: 13.8023 - val_mae: 2.7977\n",
      "Epoch 20/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 7.8604 - mae: 1.9161 - val_loss: 15.0523 - val_mae: 2.6347\n",
      "Epoch 21/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.3519 - mae: 1.8414 - val_loss: 12.9784 - val_mae: 2.6335\n",
      "Epoch 22/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.9366 - mae: 1.8434 - val_loss: 13.0994 - val_mae: 2.5442\n",
      "Epoch 23/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.9278 - mae: 1.8500 - val_loss: 13.3642 - val_mae: 2.5291\n",
      "Epoch 24/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.3960 - mae: 1.8131 - val_loss: 12.4623 - val_mae: 2.6727\n",
      "Epoch 25/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.3056 - mae: 1.8578 - val_loss: 13.2038 - val_mae: 2.6040\n",
      "Epoch 26/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.2415 - mae: 1.7982 - val_loss: 14.3503 - val_mae: 2.6521\n",
      "Epoch 27/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.3846 - mae: 1.7941 - val_loss: 12.6176 - val_mae: 2.6593\n",
      "Epoch 28/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.6615 - mae: 1.8489 - val_loss: 12.4530 - val_mae: 2.5211\n",
      "Epoch 29/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.0481 - mae: 1.7791 - val_loss: 13.6696 - val_mae: 2.5865\n",
      "Epoch 30/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.7161 - mae: 1.7314 - val_loss: 13.2052 - val_mae: 2.4402\n",
      "Epoch 31/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.2009 - mae: 1.7681 - val_loss: 12.8648 - val_mae: 2.3438\n",
      "Epoch 32/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.9204 - mae: 1.7580 - val_loss: 12.1835 - val_mae: 2.4258\n",
      "Epoch 33/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.5851 - mae: 1.6685 - val_loss: 15.3473 - val_mae: 2.5870\n",
      "Epoch 34/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.7972 - mae: 1.7367 - val_loss: 13.9643 - val_mae: 2.5053\n",
      "Epoch 35/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.5284 - mae: 1.6890 - val_loss: 15.5728 - val_mae: 2.6546\n",
      "Epoch 36/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.4994 - mae: 1.6941 - val_loss: 18.0295 - val_mae: 3.0174\n",
      "Epoch 37/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.0503 - mae: 1.6846 - val_loss: 14.4615 - val_mae: 2.4556\n",
      "Epoch 38/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.7330 - mae: 1.6895 - val_loss: 16.1541 - val_mae: 2.5741\n",
      "Epoch 39/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.5277 - mae: 1.6742 - val_loss: 13.0593 - val_mae: 2.5138\n",
      "Epoch 40/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.2891 - mae: 1.7130 - val_loss: 14.6153 - val_mae: 2.4504\n",
      "Epoch 41/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.3984 - mae: 1.6622 - val_loss: 13.4068 - val_mae: 2.4872\n",
      "Epoch 42/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.3027 - mae: 1.6842 - val_loss: 12.8134 - val_mae: 2.3397\n",
      "Epoch 43/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.2271 - mae: 1.6756 - val_loss: 13.3146 - val_mae: 2.5788\n",
      "Epoch 44/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.4261 - mae: 1.6401 - val_loss: 13.0130 - val_mae: 2.3945\n",
      "Epoch 45/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.1676 - mae: 1.6451 - val_loss: 15.2294 - val_mae: 2.5334\n",
      "Epoch 46/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.1822 - mae: 1.6408 - val_loss: 14.4369 - val_mae: 2.4250\n",
      "Epoch 47/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.5885 - mae: 1.5828 - val_loss: 16.5444 - val_mae: 2.5870\n",
      "Epoch 48/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.1823 - mae: 1.6639 - val_loss: 17.9390 - val_mae: 3.0059\n",
      "Epoch 49/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.3119 - mae: 1.6845 - val_loss: 14.5523 - val_mae: 2.3990\n",
      "Epoch 50/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.3933 - mae: 1.6104 - val_loss: 16.3490 - val_mae: 2.4975\n",
      "Epoch 51/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.7747 - mae: 1.6419 - val_loss: 14.8924 - val_mae: 2.4404\n",
      "Epoch 52/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.6842 - mae: 1.5847 - val_loss: 14.6383 - val_mae: 2.4162\n",
      "Epoch 53/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.9910 - mae: 1.5784 - val_loss: 13.8093 - val_mae: 2.4108\n",
      "Epoch 54/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.8866 - mae: 1.5662 - val_loss: 14.3469 - val_mae: 2.4922\n",
      "Epoch 55/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.9043 - mae: 1.6524 - val_loss: 13.8492 - val_mae: 2.3415\n",
      "Epoch 56/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.6155 - mae: 1.5881 - val_loss: 14.0290 - val_mae: 2.5044\n",
      "Epoch 57/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.7353 - mae: 1.6313 - val_loss: 21.5473 - val_mae: 3.2726\n",
      "Epoch 58/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.6978 - mae: 1.5615 - val_loss: 21.3873 - val_mae: 2.9693\n",
      "Epoch 59/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.9072 - mae: 1.5903 - val_loss: 14.3081 - val_mae: 2.4414\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.7532 - mae: 1.6216 - val_loss: 16.7205 - val_mae: 2.8176\n",
      "Epoch 61/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.6324 - mae: 1.5319 - val_loss: 17.0604 - val_mae: 2.5344\n",
      "Epoch 62/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.5976 - mae: 1.5175 - val_loss: 17.5482 - val_mae: 2.5354\n",
      "Epoch 63/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.4466 - mae: 1.5939 - val_loss: 14.9496 - val_mae: 2.5240\n",
      "Epoch 64/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.0951 - mae: 1.4920 - val_loss: 17.7106 - val_mae: 2.6445\n",
      "Epoch 65/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.4897 - mae: 1.5584 - val_loss: 17.1355 - val_mae: 2.5429\n",
      "Epoch 66/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.1571 - mae: 1.5212 - val_loss: 14.9143 - val_mae: 2.4553\n",
      "Epoch 67/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.2135 - mae: 1.5108 - val_loss: 17.5246 - val_mae: 2.7087\n",
      "Epoch 68/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.3622 - mae: 1.5197 - val_loss: 15.4034 - val_mae: 2.4557\n",
      "Epoch 69/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.6369 - mae: 1.5172 - val_loss: 15.9464 - val_mae: 2.4604\n",
      "Epoch 70/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.1358 - mae: 1.5053 - val_loss: 15.7319 - val_mae: 2.5308\n",
      "Epoch 71/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.9974 - mae: 1.4619 - val_loss: 17.8532 - val_mae: 2.5526\n",
      "Epoch 72/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.3256 - mae: 1.4970 - val_loss: 19.5708 - val_mae: 2.6854\n",
      "Epoch 73/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.9604 - mae: 1.5297 - val_loss: 15.8092 - val_mae: 2.4446\n",
      "Epoch 74/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.0144 - mae: 1.4802 - val_loss: 18.3809 - val_mae: 2.6081\n",
      "Epoch 75/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.8299 - mae: 1.4198 - val_loss: 17.5037 - val_mae: 2.4728\n",
      "Epoch 76/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.9056 - mae: 1.4221 - val_loss: 17.5403 - val_mae: 2.5546\n",
      "Epoch 77/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.8662 - mae: 1.5011 - val_loss: 15.7700 - val_mae: 2.5045\n",
      "Epoch 78/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.8822 - mae: 1.4838 - val_loss: 17.9261 - val_mae: 2.6144\n",
      "Epoch 79/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.9731 - mae: 1.4521 - val_loss: 16.9585 - val_mae: 2.6733\n",
      "Epoch 80/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.9221 - mae: 1.4481 - val_loss: 20.4291 - val_mae: 2.6902\n",
      "Epoch 81/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 5.0122 - mae: 1.4532 - val_loss: 16.2876 - val_mae: 2.4564\n",
      "Epoch 82/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.7173 - mae: 1.4899 - val_loss: 17.2624 - val_mae: 2.5847\n",
      "Epoch 83/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.8663 - mae: 1.4542 - val_loss: 15.8897 - val_mae: 2.5994\n",
      "Epoch 84/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.8427 - mae: 1.4280 - val_loss: 14.9892 - val_mae: 2.4037\n",
      "Epoch 85/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.7976 - mae: 1.4751 - val_loss: 16.5117 - val_mae: 2.7014\n",
      "Epoch 86/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.6397 - mae: 1.4555 - val_loss: 16.3367 - val_mae: 2.4941\n",
      "Epoch 87/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.9147 - mae: 1.4142 - val_loss: 16.0076 - val_mae: 2.4858\n",
      "Epoch 88/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.5346 - mae: 1.4322 - val_loss: 16.0759 - val_mae: 2.5071\n",
      "Epoch 89/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.3416 - mae: 1.4436 - val_loss: 15.6892 - val_mae: 2.4326\n",
      "Epoch 90/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.5208 - mae: 1.3808 - val_loss: 17.3786 - val_mae: 2.6788\n",
      "Epoch 91/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.4074 - mae: 1.4184 - val_loss: 16.1350 - val_mae: 2.6341\n",
      "Epoch 92/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.5996 - mae: 1.3841 - val_loss: 18.0981 - val_mae: 2.6769\n",
      "Epoch 93/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.3125 - mae: 1.3782 - val_loss: 19.4256 - val_mae: 2.8371\n",
      "Epoch 94/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.6966 - mae: 1.4209 - val_loss: 16.2638 - val_mae: 2.4486\n",
      "Epoch 95/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.4626 - mae: 1.4240 - val_loss: 16.9890 - val_mae: 2.5870\n",
      "Epoch 96/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.3531 - mae: 1.3396 - val_loss: 17.7301 - val_mae: 2.5902\n",
      "Epoch 97/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.1720 - mae: 1.3653 - val_loss: 17.0991 - val_mae: 2.5094\n",
      "Epoch 98/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.4826 - mae: 1.3883 - val_loss: 17.5865 - val_mae: 2.6359\n",
      "Epoch 99/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.4701 - mae: 1.4147 - val_loss: 18.2674 - val_mae: 2.6340\n",
      "Epoch 100/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.3572 - mae: 1.3755 - val_loss: 16.1820 - val_mae: 2.5837\n",
      "Epoch 101/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.1786 - mae: 1.3261 - val_loss: 17.5582 - val_mae: 2.6899\n",
      "Epoch 102/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.1314 - mae: 1.3558 - val_loss: 18.1034 - val_mae: 2.5814\n",
      "Epoch 103/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.2827 - mae: 1.3563 - val_loss: 16.8429 - val_mae: 2.5786\n",
      "Epoch 104/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.0913 - mae: 1.3343 - val_loss: 15.6405 - val_mae: 2.4111\n",
      "Epoch 105/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.8872 - mae: 1.3287 - val_loss: 15.6756 - val_mae: 2.5043\n",
      "Epoch 106/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.8797 - mae: 1.3370 - val_loss: 17.9551 - val_mae: 2.5969\n",
      "Epoch 107/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.9403 - mae: 1.3581 - val_loss: 15.3505 - val_mae: 2.4270\n",
      "Epoch 108/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.2052 - mae: 1.3850 - val_loss: 15.7736 - val_mae: 2.4797\n",
      "Epoch 109/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.9914 - mae: 1.3110 - val_loss: 16.3195 - val_mae: 2.5116\n",
      "Epoch 110/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.8642 - mae: 1.3343 - val_loss: 16.6193 - val_mae: 2.5952\n",
      "Epoch 111/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.9965 - mae: 1.2859 - val_loss: 14.7313 - val_mae: 2.4325\n",
      "Epoch 112/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.8998 - mae: 1.3117 - val_loss: 17.4886 - val_mae: 2.6589\n",
      "Epoch 113/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.9625 - mae: 1.3446 - val_loss: 17.7268 - val_mae: 2.6503\n",
      "Epoch 114/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.9306 - mae: 1.3173 - val_loss: 15.6243 - val_mae: 2.4593\n",
      "Epoch 115/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.6399 - mae: 1.2805 - val_loss: 16.0506 - val_mae: 2.4595\n",
      "Epoch 116/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.9012 - mae: 1.3499 - val_loss: 16.7731 - val_mae: 2.6692\n",
      "Epoch 117/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.0406 - mae: 1.3539 - val_loss: 16.1378 - val_mae: 2.4963\n",
      "Epoch 118/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.9161 - mae: 1.2961 - val_loss: 16.3712 - val_mae: 2.5602\n",
      "Epoch 119/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.5628 - mae: 1.2459 - val_loss: 16.5341 - val_mae: 2.5582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.9189 - mae: 1.3009 - val_loss: 16.7056 - val_mae: 2.4401\n",
      "Epoch 121/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.6811 - mae: 1.2182 - val_loss: 13.9517 - val_mae: 2.3575\n",
      "Epoch 122/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.5568 - mae: 1.2280 - val_loss: 17.0128 - val_mae: 2.4896\n",
      "Epoch 123/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.7089 - mae: 1.2786 - val_loss: 15.4910 - val_mae: 2.4877\n",
      "Epoch 124/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 4.0739 - mae: 1.3318 - val_loss: 16.3631 - val_mae: 2.5450\n",
      "Epoch 125/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.5983 - mae: 1.2692 - val_loss: 17.5710 - val_mae: 2.4985\n",
      "Epoch 126/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.6232 - mae: 1.2541 - val_loss: 15.3243 - val_mae: 2.4040\n",
      "Epoch 127/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.8393 - mae: 1.3225 - val_loss: 16.4956 - val_mae: 2.4179\n",
      "Epoch 128/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.7082 - mae: 1.2635 - val_loss: 17.0004 - val_mae: 2.6145\n",
      "Epoch 129/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.4499 - mae: 1.2742 - val_loss: 17.8023 - val_mae: 2.4938\n",
      "Epoch 130/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.5282 - mae: 1.2359 - val_loss: 15.1496 - val_mae: 2.3650\n",
      "Epoch 131/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.3723 - mae: 1.2647 - val_loss: 18.5957 - val_mae: 2.7446\n",
      "Epoch 132/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.5308 - mae: 1.2517 - val_loss: 15.9172 - val_mae: 2.4494\n",
      "Epoch 133/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.5255 - mae: 1.2770 - val_loss: 16.4496 - val_mae: 2.6368\n",
      "Epoch 134/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.3128 - mae: 1.2326 - val_loss: 19.0337 - val_mae: 2.7767\n",
      "Epoch 135/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 3.5422 - mae: 1.2697 - val_loss: 15.0509 - val_mae: 2.4093\n",
      "Epoch 136/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.1968 - mae: 1.2673 - val_loss: 14.2690 - val_mae: 2.4575\n",
      "Epoch 137/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.5630 - mae: 1.2608 - val_loss: 24.0873 - val_mae: 3.3598\n",
      "Epoch 138/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.4945 - mae: 1.2308 - val_loss: 16.2196 - val_mae: 2.4885\n",
      "Epoch 139/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 2.9130 - mae: 1.1672 - val_loss: 18.2415 - val_mae: 2.7186\n",
      "Epoch 140/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.1821 - mae: 1.2142 - val_loss: 16.5801 - val_mae: 2.6957\n",
      "Epoch 141/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.4316 - mae: 1.2256 - val_loss: 15.2509 - val_mae: 2.5879\n",
      "Epoch 142/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.0190 - mae: 1.1314 - val_loss: 15.7827 - val_mae: 2.6283\n",
      "Epoch 143/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.2514 - mae: 1.2386 - val_loss: 16.1586 - val_mae: 2.5037\n",
      "Epoch 144/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.2502 - mae: 1.1862 - val_loss: 16.0949 - val_mae: 2.4277\n",
      "Epoch 145/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.1682 - mae: 1.2032 - val_loss: 18.0219 - val_mae: 2.6690\n",
      "Epoch 146/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.2325 - mae: 1.2182 - val_loss: 15.5829 - val_mae: 2.5962\n",
      "Epoch 147/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.0913 - mae: 1.1883 - val_loss: 17.9744 - val_mae: 2.6242\n",
      "Epoch 148/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.3950 - mae: 1.2210 - val_loss: 15.5909 - val_mae: 2.5723\n",
      "Epoch 149/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9706 - mae: 1.1942 - val_loss: 13.6244 - val_mae: 2.4998\n",
      "Epoch 150/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.0631 - mae: 1.1808 - val_loss: 14.9680 - val_mae: 2.5380\n",
      "Epoch 151/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9496 - mae: 1.1564 - val_loss: 14.5994 - val_mae: 2.5249\n",
      "Epoch 152/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.0497 - mae: 1.1532 - val_loss: 16.2991 - val_mae: 2.6461\n",
      "Epoch 153/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8126 - mae: 1.1620 - val_loss: 15.7186 - val_mae: 2.7054\n",
      "Epoch 154/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.2784 - mae: 1.2008 - val_loss: 17.7610 - val_mae: 2.7326\n",
      "Epoch 155/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.1121 - mae: 1.1460 - val_loss: 15.1942 - val_mae: 2.4418\n",
      "Epoch 156/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 2.8806 - mae: 1.1149 - val_loss: 14.2219 - val_mae: 2.4741\n",
      "Epoch 157/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 3.0025 - mae: 1.1882 - val_loss: 15.9101 - val_mae: 2.5165\n",
      "Epoch 158/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 2.9687 - mae: 1.2082 - val_loss: 16.5244 - val_mae: 2.7090\n",
      "Epoch 159/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9534 - mae: 1.1460 - val_loss: 15.6332 - val_mae: 2.4743\n",
      "Epoch 160/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 3.0210 - mae: 1.1848 - val_loss: 13.2904 - val_mae: 2.3517\n",
      "Epoch 161/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6883 - mae: 1.1374 - val_loss: 12.8531 - val_mae: 2.5116\n",
      "Epoch 162/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8491 - mae: 1.1386 - val_loss: 14.6561 - val_mae: 2.6595\n",
      "Epoch 163/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8806 - mae: 1.1480 - val_loss: 14.2424 - val_mae: 2.4671\n",
      "Epoch 164/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9251 - mae: 1.1503 - val_loss: 13.8915 - val_mae: 2.4575\n",
      "Epoch 165/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8024 - mae: 1.1535 - val_loss: 13.8187 - val_mae: 2.4232\n",
      "Epoch 166/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.9389 - mae: 1.1749 - val_loss: 15.3347 - val_mae: 2.5270\n",
      "Epoch 167/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8663 - mae: 1.1307 - val_loss: 15.4328 - val_mae: 2.5904\n",
      "Epoch 168/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7917 - mae: 1.1673 - val_loss: 16.2213 - val_mae: 2.5342\n",
      "Epoch 169/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6934 - mae: 1.1235 - val_loss: 15.5802 - val_mae: 2.4725\n",
      "Epoch 170/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7078 - mae: 1.1024 - val_loss: 14.8479 - val_mae: 2.4839\n",
      "Epoch 171/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6284 - mae: 1.0542 - val_loss: 14.4833 - val_mae: 2.5369\n",
      "Epoch 172/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7727 - mae: 1.1165 - val_loss: 14.7510 - val_mae: 2.4765\n",
      "Epoch 173/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8555 - mae: 1.1429 - val_loss: 14.6942 - val_mae: 2.4900\n",
      "Epoch 174/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.7475 - mae: 1.1476 - val_loss: 16.8860 - val_mae: 2.5996\n",
      "Epoch 175/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6170 - mae: 1.1257 - val_loss: 13.4472 - val_mae: 2.4837\n",
      "Epoch 176/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.4508 - mae: 1.0642 - val_loss: 13.0387 - val_mae: 2.3985\n",
      "Epoch 177/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6708 - mae: 1.1128 - val_loss: 13.4616 - val_mae: 2.3473\n",
      "Epoch 178/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6994 - mae: 1.0950 - val_loss: 15.8382 - val_mae: 2.4748\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6104 - mae: 1.1522 - val_loss: 14.6226 - val_mae: 2.5415\n",
      "Epoch 180/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.4869 - mae: 1.1097 - val_loss: 14.9607 - val_mae: 2.4901\n",
      "Epoch 181/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8103 - mae: 1.1472 - val_loss: 15.2513 - val_mae: 2.5131\n",
      "Epoch 182/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.5705 - mae: 1.0835 - val_loss: 17.7377 - val_mae: 2.6472\n",
      "Epoch 183/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.6789 - mae: 1.1150 - val_loss: 16.3586 - val_mae: 2.5312\n",
      "Epoch 184/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.8413 - mae: 1.0984 - val_loss: 14.0020 - val_mae: 2.5388\n",
      "Epoch 185/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.5991 - mae: 1.0938 - val_loss: 13.1820 - val_mae: 2.4985\n",
      "Epoch 186/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.2816 - mae: 1.0525 - val_loss: 16.5098 - val_mae: 2.7433\n",
      "Epoch 187/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.4277 - mae: 1.0793 - val_loss: 14.8715 - val_mae: 2.5464\n",
      "Epoch 188/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.2652 - mae: 1.0332 - val_loss: 15.4075 - val_mae: 2.5916\n",
      "Epoch 189/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.3925 - mae: 1.0719 - val_loss: 15.0666 - val_mae: 2.5246\n",
      "Epoch 190/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.3470 - mae: 1.1349 - val_loss: 14.8469 - val_mae: 2.5511\n",
      "Epoch 191/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.3565 - mae: 1.0748 - val_loss: 15.0952 - val_mae: 2.5453\n",
      "Epoch 192/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.5076 - mae: 1.0967 - val_loss: 13.6248 - val_mae: 2.4072\n",
      "Epoch 193/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.1313 - mae: 1.0614 - val_loss: 15.4274 - val_mae: 2.4833\n",
      "Epoch 194/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.4433 - mae: 1.0892 - val_loss: 19.1747 - val_mae: 3.2315\n",
      "Epoch 195/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.3875 - mae: 1.0683 - val_loss: 16.9163 - val_mae: 2.6139\n",
      "Epoch 196/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.3613 - mae: 1.1056 - val_loss: 15.3645 - val_mae: 2.6596\n",
      "Epoch 197/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 2.3221 - mae: 1.0531 - val_loss: 14.2071 - val_mae: 2.4473\n",
      "Epoch 198/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.4192 - mae: 1.0818 - val_loss: 12.8371 - val_mae: 2.4413\n",
      "Epoch 199/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.2865 - mae: 1.0490 - val_loss: 13.6797 - val_mae: 2.5978\n",
      "Epoch 200/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 2.4278 - mae: 1.0812 - val_loss: 17.3352 - val_mae: 2.6167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1608b361388>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_targets, validation_split =0.2, epochs = 200, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model very quickly overfits to the training data, so we should stop it before it overfits. Now the question is when to stop? We will use K-fold validation to figure out in the next secsion.  \n",
    "\n",
    "Because you'll need to instantiate the same model multiple times, you use a function to construct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Validating our approach using K-fold validation\n",
    "\n",
    "To evaluate our network while we keep adjusting its parameters (e.g. the number of epochs), we use K-fold cross-validation because we have so few data points. It splits the data into K partitions, then instantiating K identical models, and training each one on K-1 partitions while evaluating on the remaining partition. The validation score for the model used would then be the average of the K validation scores obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "# Some memory clean-up\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 191.5869 - mae: 10.1326 - val_loss: 30.8879 - val_mae: 3.4316\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 27.0201 - mae: 3.6457 - val_loss: 22.6356 - val_mae: 2.7547\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 22.2576 - mae: 3.1892 - val_loss: 17.7842 - val_mae: 2.6901\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 18.1370 - mae: 2.9263 - val_loss: 15.8488 - val_mae: 2.3756\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 16.2374 - mae: 2.6827 - val_loss: 12.6371 - val_mae: 2.1143\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.4570 - mae: 2.5962 - val_loss: 13.3222 - val_mae: 2.5104\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.0459 - mae: 2.5276 - val_loss: 11.9849 - val_mae: 2.2520\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.3094 - mae: 2.4767 - val_loss: 11.5424 - val_mae: 2.2530\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.6128 - mae: 2.3571 - val_loss: 10.7973 - val_mae: 2.1424\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.3397 - mae: 2.3624 - val_loss: 10.5450 - val_mae: 2.0204\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.8657 - mae: 2.3322 - val_loss: 9.4467 - val_mae: 1.9826\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.3308 - mae: 2.2904 - val_loss: 10.1630 - val_mae: 2.1344\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.9940 - mae: 2.2402 - val_loss: 9.2114 - val_mae: 1.8079\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.7250 - mae: 2.2163 - val_loss: 10.2147 - val_mae: 2.1461\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.6155 - mae: 2.2147 - val_loss: 11.1185 - val_mae: 2.6308\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.6060 - mae: 2.1747 - val_loss: 8.3032 - val_mae: 1.7721\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.3296 - mae: 2.1686 - val_loss: 10.2018 - val_mae: 2.0081\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.8307 - mae: 2.1245 - val_loss: 8.0405 - val_mae: 1.8107\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.1283 - mae: 2.1525 - val_loss: 8.5336 - val_mae: 1.9514\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4515 - mae: 2.0586 - val_loss: 9.5135 - val_mae: 1.8682\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.8489 - mae: 2.0938 - val_loss: 7.7560 - val_mae: 1.9572\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.2163 - mae: 2.0366 - val_loss: 7.8167 - val_mae: 1.9141\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.2331 - mae: 2.1096 - val_loss: 9.8150 - val_mae: 1.9008\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.7389 - mae: 2.0269 - val_loss: 9.0361 - val_mae: 1.7539\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.3217 - mae: 2.0306 - val_loss: 8.4568 - val_mae: 1.9016\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.1487 - mae: 2.0277 - val_loss: 8.8288 - val_mae: 1.7843\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.8366 - mae: 2.0422 - val_loss: 8.3604 - val_mae: 1.9561\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.7857 - mae: 1.9839 - val_loss: 7.7613 - val_mae: 1.9203\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.3750 - mae: 1.9499 - val_loss: 12.7325 - val_mae: 2.2075\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.5733 - mae: 1.9752 - val_loss: 8.0161 - val_mae: 1.8953\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.3047 - mae: 1.9283 - val_loss: 9.7215 - val_mae: 1.9672\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8127 - mae: 1.8606 - val_loss: 10.9324 - val_mae: 1.9519\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8623 - mae: 1.9114 - val_loss: 8.6829 - val_mae: 2.0154\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1930 - mae: 1.9229 - val_loss: 11.3917 - val_mae: 2.4582\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7309 - mae: 1.9586 - val_loss: 8.3608 - val_mae: 2.0655\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7774 - mae: 1.8820 - val_loss: 9.1542 - val_mae: 1.9329\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.5631 - mae: 1.9049 - val_loss: 8.3346 - val_mae: 1.8335\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5967 - mae: 1.9078 - val_loss: 8.2139 - val_mae: 1.9859\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5315 - mae: 1.8734 - val_loss: 9.5949 - val_mae: 1.8669\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.4983 - mae: 1.8963 - val_loss: 8.2900 - val_mae: 1.7225\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.4588 - mae: 1.7811 - val_loss: 7.9406 - val_mae: 1.8601\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2636 - mae: 1.7657 - val_loss: 8.2710 - val_mae: 1.9822\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0904 - mae: 1.8149 - val_loss: 9.5686 - val_mae: 2.3816\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9239 - mae: 1.7521 - val_loss: 8.8847 - val_mae: 2.1278\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0905 - mae: 1.7715 - val_loss: 9.6072 - val_mae: 1.7607\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8550 - mae: 1.7673 - val_loss: 8.7355 - val_mae: 1.9883\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6698 - mae: 1.7607 - val_loss: 9.2416 - val_mae: 1.9049\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1784 - mae: 1.7484 - val_loss: 8.5428 - val_mae: 1.9635\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9626 - mae: 1.7503 - val_loss: 9.1191 - val_mae: 1.7197\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8341 - mae: 1.7123 - val_loss: 8.0732 - val_mae: 1.8574\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8179 - mae: 1.6972 - val_loss: 7.6933 - val_mae: 1.8322\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7712 - mae: 1.6681 - val_loss: 7.6787 - val_mae: 1.7929\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6952 - mae: 1.7029 - val_loss: 7.9177 - val_mae: 1.7716\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5903 - mae: 1.7273 - val_loss: 8.5911 - val_mae: 2.0678\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5684 - mae: 1.6316 - val_loss: 8.4140 - val_mae: 1.9087\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2378 - mae: 1.6927 - val_loss: 8.3348 - val_mae: 1.7441\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2477 - mae: 1.6439 - val_loss: 9.0295 - val_mae: 1.9312\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0818 - mae: 1.6042 - val_loss: 8.7734 - val_mae: 1.8257\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4425 - mae: 1.6616 - val_loss: 7.5540 - val_mae: 1.7621\n",
      "Epoch 60/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1826 - mae: 1.6210 - val_loss: 9.0881 - val_mae: 2.2528\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3614 - mae: 1.5848 - val_loss: 10.1884 - val_mae: 2.1301\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9562 - mae: 1.6030 - val_loss: 8.9754 - val_mae: 1.8863\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9269 - mae: 1.5998 - val_loss: 8.4950 - val_mae: 1.8584\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0402 - mae: 1.5686 - val_loss: 8.2146 - val_mae: 1.8986\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7301 - mae: 1.5701 - val_loss: 9.2250 - val_mae: 2.1330\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8202 - mae: 1.6117 - val_loss: 9.4281 - val_mae: 1.8807\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7703 - mae: 1.6140 - val_loss: 9.0382 - val_mae: 1.8788\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7303 - mae: 1.5602 - val_loss: 7.7097 - val_mae: 1.8701\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5745 - mae: 1.5279 - val_loss: 9.2931 - val_mae: 2.0849\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0519 - mae: 1.6084 - val_loss: 7.8112 - val_mae: 1.8102\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0602 - mae: 1.5966 - val_loss: 8.8907 - val_mae: 2.0795\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8388 - mae: 1.5464 - val_loss: 7.5734 - val_mae: 1.7791\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1030 - mae: 1.4605 - val_loss: 8.7777 - val_mae: 2.1773\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4753 - mae: 1.5307 - val_loss: 7.9378 - val_mae: 1.8935\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6129 - mae: 1.4938 - val_loss: 7.7224 - val_mae: 1.9244\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1469 - mae: 1.5079 - val_loss: 9.7302 - val_mae: 2.4140\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2643 - mae: 1.4946 - val_loss: 7.4710 - val_mae: 2.0467\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1146 - mae: 1.5173 - val_loss: 7.8943 - val_mae: 1.7012\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3979 - mae: 1.5372 - val_loss: 8.4268 - val_mae: 1.8717\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2319 - mae: 1.5178 - val_loss: 8.1472 - val_mae: 1.7777\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9817 - mae: 1.4851 - val_loss: 7.9758 - val_mae: 1.7802\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2908 - mae: 1.4929 - val_loss: 7.8456 - val_mae: 1.8198\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8797 - mae: 1.5252 - val_loss: 8.0851 - val_mae: 1.7384\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8633 - mae: 1.4909 - val_loss: 7.2279 - val_mae: 1.8252\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1923 - mae: 1.5056 - val_loss: 8.1692 - val_mae: 1.8572\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1460 - mae: 1.4738 - val_loss: 8.6997 - val_mae: 2.0073\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8610 - mae: 1.4750 - val_loss: 9.4029 - val_mae: 1.9224\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6757 - mae: 1.4506 - val_loss: 8.8053 - val_mae: 1.9164\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8487 - mae: 1.4323 - val_loss: 8.8664 - val_mae: 1.9656\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9993 - mae: 1.4402 - val_loss: 7.6405 - val_mae: 1.7723\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0877 - mae: 1.4388 - val_loss: 7.6549 - val_mae: 1.8007\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4637 - mae: 1.4423 - val_loss: 8.4592 - val_mae: 2.1005\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7039 - mae: 1.4047 - val_loss: 8.5133 - val_mae: 2.0996\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4329 - mae: 1.3761 - val_loss: 8.7668 - val_mae: 2.0157\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8679 - mae: 1.4334 - val_loss: 8.0750 - val_mae: 1.7606\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5305 - mae: 1.4397 - val_loss: 10.4023 - val_mae: 2.5275\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6184 - mae: 1.4130 - val_loss: 8.1259 - val_mae: 2.0001\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3218 - mae: 1.3797 - val_loss: 7.6122 - val_mae: 1.7345\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4015 - mae: 1.3751 - val_loss: 9.0152 - val_mae: 2.3217\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4281 - mae: 1.3717 - val_loss: 7.8863 - val_mae: 1.9711\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4448 - mae: 1.4442 - val_loss: 10.9697 - val_mae: 2.2504\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4391 - mae: 1.4161 - val_loss: 8.7565 - val_mae: 2.0715\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4635 - mae: 1.3832 - val_loss: 8.8344 - val_mae: 2.1450\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6910 - mae: 1.4080 - val_loss: 9.0759 - val_mae: 2.2612\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3902 - mae: 1.4029 - val_loss: 9.8630 - val_mae: 2.2800\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4304 - mae: 1.3576 - val_loss: 8.6439 - val_mae: 1.9695\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0793 - mae: 1.3516 - val_loss: 8.3985 - val_mae: 1.7917\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2186 - mae: 1.3590 - val_loss: 8.6616 - val_mae: 1.8158\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2870 - mae: 1.3711 - val_loss: 8.4375 - val_mae: 1.8276\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3268 - mae: 1.3800 - val_loss: 11.7910 - val_mae: 2.5542\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4291 - mae: 1.3703 - val_loss: 8.2846 - val_mae: 2.0268\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0117 - mae: 1.3697 - val_loss: 11.3701 - val_mae: 2.2720\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9535 - mae: 1.3777 - val_loss: 9.1231 - val_mae: 2.2213\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0955 - mae: 1.3277 - val_loss: 10.2065 - val_mae: 2.3923\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0497 - mae: 1.3105 - val_loss: 8.2559 - val_mae: 1.8702\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7041 - mae: 1.3337 - val_loss: 9.8783 - val_mae: 2.1272\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1033 - mae: 1.3013 - val_loss: 8.0632 - val_mae: 1.9438\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8838 - mae: 1.3057 - val_loss: 9.5427 - val_mae: 2.1281\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9933 - mae: 1.3382 - val_loss: 8.3853 - val_mae: 1.9993\n",
      "Epoch 120/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9472 - mae: 1.3284 - val_loss: 8.5385 - val_mae: 1.9138\n",
      "processing fold # 1\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 200.2631 - mae: 10.6419 - val_loss: 43.4214 - val_mae: 5.0336\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 29.5270 - mae: 3.5602 - val_loss: 20.0620 - val_mae: 3.4214\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 21.1604 - mae: 3.0177 - val_loss: 17.8533 - val_mae: 3.1456\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 17.6528 - mae: 2.7028 - val_loss: 15.0381 - val_mae: 3.0259\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.7928 - mae: 2.5703 - val_loss: 16.1892 - val_mae: 3.0351\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.6795 - mae: 2.3903 - val_loss: 14.0729 - val_mae: 2.9538\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.6386 - mae: 2.3419 - val_loss: 14.7809 - val_mae: 3.0042\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.1695 - mae: 2.3127 - val_loss: 13.5266 - val_mae: 2.9198\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.6608 - mae: 2.2524 - val_loss: 13.2157 - val_mae: 2.8368\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.3179 - mae: 2.2574 - val_loss: 13.8198 - val_mae: 2.8811\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.2303 - mae: 2.1727 - val_loss: 13.8729 - val_mae: 2.9108\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.2534 - mae: 2.1066 - val_loss: 12.8197 - val_mae: 2.8270\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.2023 - mae: 2.1380 - val_loss: 12.6470 - val_mae: 2.8297\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.0872 - mae: 2.0357 - val_loss: 13.7326 - val_mae: 2.9233\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4181 - mae: 2.0541 - val_loss: 14.3585 - val_mae: 2.9300\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4429 - mae: 2.1182 - val_loss: 12.4225 - val_mae: 2.7215\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.0927 - mae: 2.0521 - val_loss: 10.9167 - val_mae: 2.5592\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.1098 - mae: 2.0122 - val_loss: 12.7978 - val_mae: 2.8101\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.1458 - mae: 1.9831 - val_loss: 11.8849 - val_mae: 2.7006\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.7044 - mae: 2.0065 - val_loss: 12.1234 - val_mae: 2.6651\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.5458 - mae: 1.9459 - val_loss: 11.2900 - val_mae: 2.6025\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6868 - mae: 1.9692 - val_loss: 12.6561 - val_mae: 2.7985\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.8356 - mae: 1.9404 - val_loss: 11.0176 - val_mae: 2.5883\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1704 - mae: 1.8912 - val_loss: 10.4085 - val_mae: 2.5466\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1046 - mae: 1.9153 - val_loss: 12.9534 - val_mae: 2.8074\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.9500 - mae: 1.8726 - val_loss: 12.1830 - val_mae: 2.6810\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.6447 - mae: 1.8598 - val_loss: 12.1655 - val_mae: 2.6721\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8065 - mae: 1.8821 - val_loss: 10.9004 - val_mae: 2.5617\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8388 - mae: 1.8785 - val_loss: 12.3094 - val_mae: 2.7429\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.6849 - mae: 1.8486 - val_loss: 10.4218 - val_mae: 2.5100\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2947 - mae: 1.8653 - val_loss: 12.0819 - val_mae: 2.6227\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1065 - mae: 1.7924 - val_loss: 13.0310 - val_mae: 2.7601\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0672 - mae: 1.7912 - val_loss: 12.8647 - val_mae: 2.7133\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2020 - mae: 1.7614 - val_loss: 10.9931 - val_mae: 2.5643\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7278 - mae: 1.7598 - val_loss: 11.9762 - val_mae: 2.6062\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.9188 - mae: 1.7141 - val_loss: 11.5003 - val_mae: 2.6187\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.8865 - mae: 1.7811 - val_loss: 11.6627 - val_mae: 2.5845\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.4460 - mae: 1.7343 - val_loss: 13.2439 - val_mae: 2.6658\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.6128 - mae: 1.7419 - val_loss: 12.5239 - val_mae: 2.6376\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.5486 - mae: 1.6865 - val_loss: 10.7439 - val_mae: 2.5089\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.2167 - mae: 1.6613 - val_loss: 12.7549 - val_mae: 2.6533\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.2143 - mae: 1.6878 - val_loss: 10.1362 - val_mae: 2.4517\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.9598 - mae: 1.6039 - val_loss: 15.1259 - val_mae: 2.8971\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.3407 - mae: 1.6854 - val_loss: 12.3699 - val_mae: 2.6513\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.2695 - mae: 1.6810 - val_loss: 12.6940 - val_mae: 2.6952\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.2109 - mae: 1.6486 - val_loss: 14.4216 - val_mae: 2.7157\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.8997 - mae: 1.5809 - val_loss: 11.7986 - val_mae: 2.5514\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7996 - mae: 1.5413 - val_loss: 12.2386 - val_mae: 2.5505\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9006 - mae: 1.5890 - val_loss: 11.2187 - val_mae: 2.4933\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.8107 - mae: 1.5985 - val_loss: 14.6554 - val_mae: 2.7351\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.5505 - mae: 1.5840 - val_loss: 11.4705 - val_mae: 2.5528\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3823 - mae: 1.5677 - val_loss: 16.2442 - val_mae: 2.9049\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.9662 - mae: 1.5086 - val_loss: 14.5335 - val_mae: 2.8604\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.3045 - mae: 1.4943 - val_loss: 16.2675 - val_mae: 2.9370\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.2820 - mae: 1.5294 - val_loss: 15.6325 - val_mae: 2.8386\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.1588 - mae: 1.5306 - val_loss: 11.2890 - val_mae: 2.4622\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8209 - mae: 1.5267 - val_loss: 11.1188 - val_mae: 2.4949\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1557 - mae: 1.5615 - val_loss: 14.3185 - val_mae: 2.7099\n",
      "Epoch 59/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1234 - mae: 1.5349 - val_loss: 12.2337 - val_mae: 2.6556\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8720 - mae: 1.5123 - val_loss: 11.9658 - val_mae: 2.5875\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8383 - mae: 1.5432 - val_loss: 13.3134 - val_mae: 2.8003\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6096 - mae: 1.4985 - val_loss: 15.6620 - val_mae: 2.7190\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7763 - mae: 1.4545 - val_loss: 9.9259 - val_mae: 2.3597\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6649 - mae: 1.4428 - val_loss: 17.7803 - val_mae: 2.9874\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5447 - mae: 1.4438 - val_loss: 12.5568 - val_mae: 2.6774\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.4440 - mae: 1.4316 - val_loss: 13.5484 - val_mae: 2.6712\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3644 - mae: 1.3649 - val_loss: 13.0245 - val_mae: 2.6540\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5469 - mae: 1.4432 - val_loss: 14.4990 - val_mae: 2.6892\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7213 - mae: 1.4033 - val_loss: 14.1340 - val_mae: 2.7769\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3720 - mae: 1.4394 - val_loss: 17.8636 - val_mae: 3.0118\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5661 - mae: 1.4034 - val_loss: 14.1469 - val_mae: 2.6899\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.3099 - mae: 1.4256 - val_loss: 15.7476 - val_mae: 2.7618\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2261 - mae: 1.3944 - val_loss: 13.7351 - val_mae: 2.6956\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1302 - mae: 1.4135 - val_loss: 14.0744 - val_mae: 2.7380\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2527 - mae: 1.3856 - val_loss: 13.1409 - val_mae: 2.5907\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0144 - mae: 1.3935 - val_loss: 12.9895 - val_mae: 2.5534\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1417 - mae: 1.4232 - val_loss: 17.5306 - val_mae: 2.8609\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7908 - mae: 1.3939 - val_loss: 12.9942 - val_mae: 2.5996\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8884 - mae: 1.3098 - val_loss: 13.4950 - val_mae: 2.5771\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7274 - mae: 1.3310 - val_loss: 12.4113 - val_mae: 2.4472\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2247 - mae: 1.3858 - val_loss: 13.0305 - val_mae: 2.6216\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9469 - mae: 1.3450 - val_loss: 14.1486 - val_mae: 2.6840\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5659 - mae: 1.2838 - val_loss: 14.1645 - val_mae: 2.6927\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.9952 - mae: 1.3432 - val_loss: 13.8939 - val_mae: 2.5820\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0129 - mae: 1.3570 - val_loss: 21.0293 - val_mae: 3.0960\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.8213 - mae: 1.3608 - val_loss: 16.0727 - val_mae: 2.7196\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0235 - mae: 1.3612 - val_loss: 11.2778 - val_mae: 2.4421\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6700 - mae: 1.2709 - val_loss: 11.6563 - val_mae: 2.5622\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6959 - mae: 1.2903 - val_loss: 26.3930 - val_mae: 3.5699\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6339 - mae: 1.2810 - val_loss: 12.1369 - val_mae: 2.5659\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6703 - mae: 1.3219 - val_loss: 11.9568 - val_mae: 2.4450\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8476 - mae: 1.3587 - val_loss: 11.3509 - val_mae: 2.3955\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4345 - mae: 1.3028 - val_loss: 15.8648 - val_mae: 3.0299\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4775 - mae: 1.2457 - val_loss: 13.1847 - val_mae: 2.6353\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.5298 - mae: 1.2799 - val_loss: 14.8893 - val_mae: 2.8448\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6188 - mae: 1.2898 - val_loss: 15.4929 - val_mae: 2.7688\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6412 - mae: 1.2931 - val_loss: 12.0256 - val_mae: 2.4966\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4586 - mae: 1.2754 - val_loss: 14.2776 - val_mae: 2.6362\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4919 - mae: 1.2548 - val_loss: 22.4429 - val_mae: 3.0719\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1505 - mae: 1.2609 - val_loss: 12.3068 - val_mae: 2.4324\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3951 - mae: 1.2374 - val_loss: 13.5323 - val_mae: 2.6876\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2105 - mae: 1.2433 - val_loss: 10.2677 - val_mae: 2.4059\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2016 - mae: 1.2150 - val_loss: 12.8755 - val_mae: 2.5754\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3974 - mae: 1.2525 - val_loss: 11.5875 - val_mae: 2.3806\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2697 - mae: 1.2560 - val_loss: 16.8118 - val_mae: 2.8684\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1739 - mae: 1.2633 - val_loss: 12.2162 - val_mae: 2.6174\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1343 - mae: 1.2493 - val_loss: 16.8708 - val_mae: 2.6784\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1168 - mae: 1.2530 - val_loss: 13.4331 - val_mae: 2.5388\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2701 - mae: 1.2394 - val_loss: 15.8730 - val_mae: 2.6433\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.2272 - mae: 1.2323 - val_loss: 14.7548 - val_mae: 2.6916\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1161 - mae: 1.2118 - val_loss: 14.2353 - val_mae: 2.6468\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3657 - mae: 1.2823 - val_loss: 14.3443 - val_mae: 2.5284\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0204 - mae: 1.2004 - val_loss: 12.1748 - val_mae: 2.5071\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8857 - mae: 1.1947 - val_loss: 17.8737 - val_mae: 2.7340\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.0542 - mae: 1.2435 - val_loss: 14.3859 - val_mae: 2.6456\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.0615 - mae: 1.2138 - val_loss: 12.1947 - val_mae: 2.4065\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2098 - mae: 1.2196 - val_loss: 21.8120 - val_mae: 3.1967\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1075 - mae: 1.2355 - val_loss: 17.1472 - val_mae: 2.8539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8173 - mae: 1.1407 - val_loss: 21.9297 - val_mae: 2.8412\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8776 - mae: 1.2035 - val_loss: 14.4391 - val_mae: 2.5279\n",
      "processing fold # 2\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 218.1128 - mae: 11.0426 - val_loss: 22.5374 - val_mae: 3.5735\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 31.6712 - mae: 3.8418 - val_loss: 15.9706 - val_mae: 3.0209\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 22.7739 - mae: 3.1863 - val_loss: 11.8251 - val_mae: 2.6756\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 17.8269 - mae: 2.7939 - val_loss: 11.6909 - val_mae: 2.6696\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.7806 - mae: 2.6555 - val_loss: 9.2201 - val_mae: 2.3534\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.0966 - mae: 2.6142 - val_loss: 8.9575 - val_mae: 2.2636\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.2745 - mae: 2.4505 - val_loss: 9.4388 - val_mae: 2.3994\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.9064 - mae: 2.4024 - val_loss: 8.9094 - val_mae: 2.4111\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.4730 - mae: 2.2971 - val_loss: 10.0723 - val_mae: 2.4977\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.0574 - mae: 2.2971 - val_loss: 8.2640 - val_mae: 2.2882\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.5652 - mae: 2.1862 - val_loss: 13.0716 - val_mae: 2.8903\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.8371 - mae: 2.2248 - val_loss: 8.8624 - val_mae: 2.3837\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.4384 - mae: 2.1500 - val_loss: 7.9568 - val_mae: 2.2147\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.1529 - mae: 2.1470 - val_loss: 8.1500 - val_mae: 2.2714\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.5949 - mae: 2.0593 - val_loss: 8.9401 - val_mae: 2.3933\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4911 - mae: 2.1081 - val_loss: 10.3888 - val_mae: 2.5880\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.5152 - mae: 2.0397 - val_loss: 9.9526 - val_mae: 2.5214\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.3948 - mae: 1.9992 - val_loss: 8.5010 - val_mae: 2.3501\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.0590 - mae: 1.9948 - val_loss: 9.0425 - val_mae: 2.3815\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.9625 - mae: 2.0210 - val_loss: 9.9975 - val_mae: 2.5027\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.1656 - mae: 1.9489 - val_loss: 9.3835 - val_mae: 2.4257\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.3997 - mae: 1.9031 - val_loss: 8.8852 - val_mae: 2.3322\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.0385 - mae: 1.9334 - val_loss: 8.9534 - val_mae: 2.3706\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.4051 - mae: 1.8824 - val_loss: 11.2204 - val_mae: 2.6407\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.3796 - mae: 1.8515 - val_loss: 9.9550 - val_mae: 2.5446\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1315 - mae: 1.8972 - val_loss: 9.2511 - val_mae: 2.4513\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8327 - mae: 1.8235 - val_loss: 7.8207 - val_mae: 2.2793\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.8785 - mae: 1.8363 - val_loss: 10.0387 - val_mae: 2.4820\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.4374 - mae: 1.8459 - val_loss: 8.5335 - val_mae: 2.2974\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.2584 - mae: 1.8515 - val_loss: 8.7757 - val_mae: 2.3598\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.9228 - mae: 1.7796 - val_loss: 9.5366 - val_mae: 2.3535\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.8574 - mae: 1.7861 - val_loss: 11.0022 - val_mae: 2.5503\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.0698 - mae: 1.8314 - val_loss: 8.2155 - val_mae: 2.2900\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5379 - mae: 1.8054 - val_loss: 9.1025 - val_mae: 2.3443\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.1662 - mae: 1.7389 - val_loss: 7.6344 - val_mae: 2.1918\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7317 - mae: 1.7378 - val_loss: 9.5112 - val_mae: 2.4708\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8734 - mae: 1.7648 - val_loss: 8.8476 - val_mae: 2.3341\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9203 - mae: 1.7611 - val_loss: 7.8669 - val_mae: 2.1982\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0635 - mae: 1.7179 - val_loss: 9.5933 - val_mae: 2.4407\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7834 - mae: 1.7081 - val_loss: 8.5569 - val_mae: 2.3418\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5724 - mae: 1.6262 - val_loss: 8.6011 - val_mae: 2.2788\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4028 - mae: 1.7196 - val_loss: 10.8108 - val_mae: 2.5038\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.9192 - mae: 1.7427 - val_loss: 8.5989 - val_mae: 2.2622\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.8106 - mae: 1.7011 - val_loss: 8.8827 - val_mae: 2.3980\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.4340 - mae: 1.7036 - val_loss: 8.5652 - val_mae: 2.2893\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4593 - mae: 1.6760 - val_loss: 8.5390 - val_mae: 2.2766\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.5291 - mae: 1.6534 - val_loss: 9.1288 - val_mae: 2.3796\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.0136 - mae: 1.6486 - val_loss: 7.2207 - val_mae: 2.1219\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1915 - mae: 1.6265 - val_loss: 11.1165 - val_mae: 2.4827\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4910 - mae: 1.6253 - val_loss: 7.9126 - val_mae: 2.2537\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9346 - mae: 1.6164 - val_loss: 11.7324 - val_mae: 2.5421\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.6293 - mae: 1.6136 - val_loss: 8.2572 - val_mae: 2.2112\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1723 - mae: 1.6379 - val_loss: 7.8193 - val_mae: 2.1835\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.9191 - mae: 1.5609 - val_loss: 7.9227 - val_mae: 2.1441\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.6512 - mae: 1.5648 - val_loss: 7.4918 - val_mae: 2.1390\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.7619 - mae: 1.5873 - val_loss: 8.4783 - val_mae: 2.3072\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5850 - mae: 1.5849 - val_loss: 8.6849 - val_mae: 2.2416\n",
      "Epoch 58/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6796 - mae: 1.6009 - val_loss: 10.1907 - val_mae: 2.4150\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4486 - mae: 1.5367 - val_loss: 7.0041 - val_mae: 2.0137\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6566 - mae: 1.5391 - val_loss: 7.6085 - val_mae: 2.1402\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7992 - mae: 1.5294 - val_loss: 9.3565 - val_mae: 2.3544\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5544 - mae: 1.5069 - val_loss: 8.6923 - val_mae: 2.2726\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2540 - mae: 1.4796 - val_loss: 12.7693 - val_mae: 2.6298\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2223 - mae: 1.5150 - val_loss: 7.4636 - val_mae: 2.1565\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4849 - mae: 1.5302 - val_loss: 9.4349 - val_mae: 2.3501\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1686 - mae: 1.4311 - val_loss: 7.3803 - val_mae: 2.1212\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.0648 - mae: 1.5067 - val_loss: 7.0324 - val_mae: 2.0800\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1781 - mae: 1.5251 - val_loss: 9.1229 - val_mae: 2.3442\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6528 - mae: 1.4518 - val_loss: 9.2853 - val_mae: 2.3040\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2829 - mae: 1.4660 - val_loss: 9.0973 - val_mae: 2.2725\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0615 - mae: 1.4435 - val_loss: 12.0966 - val_mae: 2.7283\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6200 - mae: 1.4314 - val_loss: 8.7078 - val_mae: 2.2230\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8352 - mae: 1.4362 - val_loss: 7.0443 - val_mae: 2.1393\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6283 - mae: 1.3629 - val_loss: 9.2733 - val_mae: 2.3461\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6368 - mae: 1.4007 - val_loss: 11.0478 - val_mae: 2.4332\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8552 - mae: 1.4412 - val_loss: 11.1955 - val_mae: 2.5339\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6424 - mae: 1.3958 - val_loss: 8.5731 - val_mae: 2.1646\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5685 - mae: 1.4288 - val_loss: 7.9422 - val_mae: 2.1626\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5466 - mae: 1.4560 - val_loss: 8.6792 - val_mae: 2.2661\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5272 - mae: 1.4101 - val_loss: 7.6155 - val_mae: 2.1778\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4038 - mae: 1.3943 - val_loss: 8.3504 - val_mae: 2.2465\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1561 - mae: 1.3419 - val_loss: 8.5042 - val_mae: 2.2025\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3280 - mae: 1.3639 - val_loss: 9.0605 - val_mae: 2.2334\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2258 - mae: 1.3832 - val_loss: 8.7314 - val_mae: 2.3047\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4552 - mae: 1.3885 - val_loss: 8.3545 - val_mae: 2.2287\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1266 - mae: 1.3149 - val_loss: 9.4279 - val_mae: 2.3163\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0897 - mae: 1.3542 - val_loss: 7.5189 - val_mae: 2.1278\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8189 - mae: 1.3239 - val_loss: 8.2528 - val_mae: 2.2959\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2416 - mae: 1.3785 - val_loss: 8.9147 - val_mae: 2.2573\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1182 - mae: 1.3166 - val_loss: 13.1374 - val_mae: 2.7985\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9601 - mae: 1.3123 - val_loss: 8.7154 - val_mae: 2.2833\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9052 - mae: 1.3281 - val_loss: 7.3404 - val_mae: 2.0543\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6056 - mae: 1.2905 - val_loss: 8.4821 - val_mae: 2.2248\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0087 - mae: 1.2877 - val_loss: 8.8666 - val_mae: 2.2192\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8981 - mae: 1.3557 - val_loss: 7.4387 - val_mae: 2.1614\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9382 - mae: 1.2912 - val_loss: 8.4584 - val_mae: 2.1897\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3558 - mae: 1.2383 - val_loss: 10.8580 - val_mae: 2.3688\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7151 - mae: 1.3163 - val_loss: 8.3785 - val_mae: 2.3277\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6808 - mae: 1.3105 - val_loss: 8.2345 - val_mae: 2.1914\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4115 - mae: 1.2904 - val_loss: 9.3270 - val_mae: 2.3149\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6905 - mae: 1.2676 - val_loss: 9.1319 - val_mae: 2.3143\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5322 - mae: 1.2851 - val_loss: 7.8034 - val_mae: 2.1242\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.4839 - mae: 1.2879 - val_loss: 9.9420 - val_mae: 2.3566\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0357 - mae: 1.1879 - val_loss: 9.4011 - val_mae: 2.3154\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2906 - mae: 1.2986 - val_loss: 9.5825 - val_mae: 2.2875\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3326 - mae: 1.2595 - val_loss: 8.8256 - val_mae: 2.2921\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3149 - mae: 1.2365 - val_loss: 9.6279 - val_mae: 2.3153\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4003 - mae: 1.2530 - val_loss: 7.5752 - val_mae: 2.1876\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3952 - mae: 1.2384 - val_loss: 7.4134 - val_mae: 2.0901\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5135 - mae: 1.2770 - val_loss: 8.7925 - val_mae: 2.2689\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3840 - mae: 1.1767 - val_loss: 9.4692 - val_mae: 2.2757\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.9561 - mae: 1.1879 - val_loss: 11.3562 - val_mae: 2.5164\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2834 - mae: 1.2339 - val_loss: 8.4135 - val_mae: 2.3033\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0768 - mae: 1.1519 - val_loss: 8.0996 - val_mae: 2.2197\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3751 - mae: 1.2152 - val_loss: 11.3861 - val_mae: 2.5155\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.2511 - mae: 1.2045 - val_loss: 9.9073 - val_mae: 2.4494\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1744 - mae: 1.1781 - val_loss: 9.2560 - val_mae: 2.2922\n",
      "Epoch 118/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.9076 - mae: 1.2057 - val_loss: 7.6273 - val_mae: 2.0737\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.9970 - mae: 1.1150 - val_loss: 8.0070 - val_mae: 2.1958\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4303 - mae: 1.2319 - val_loss: 9.5216 - val_mae: 2.4327\n",
      "processing fold # 3\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 197.2120 - mae: 10.1427 - val_loss: 36.9568 - val_mae: 4.2457\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 24.8924 - mae: 3.4030 - val_loss: 26.1399 - val_mae: 3.2422\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 18.6330 - mae: 2.9631 - val_loss: 23.2561 - val_mae: 3.0569\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 15.2794 - mae: 2.6865 - val_loss: 21.2531 - val_mae: 2.8167\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.9775 - mae: 2.4573 - val_loss: 20.7193 - val_mae: 2.8476\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.9951 - mae: 2.3744 - val_loss: 20.5748 - val_mae: 2.9394\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.7240 - mae: 2.3000 - val_loss: 20.0472 - val_mae: 2.8921\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.9152 - mae: 2.2422 - val_loss: 20.2658 - val_mae: 2.8384\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.0638 - mae: 2.2239 - val_loss: 21.0905 - val_mae: 3.0223\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.8307 - mae: 2.1962 - val_loss: 21.9322 - val_mae: 3.1068\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.6482 - mae: 2.1730 - val_loss: 20.2716 - val_mae: 2.8928\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4777 - mae: 2.2070 - val_loss: 19.2521 - val_mae: 2.7541\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.8098 - mae: 2.1051 - val_loss: 19.6101 - val_mae: 2.7586\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.4293 - mae: 2.0560 - val_loss: 19.3346 - val_mae: 2.9429\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2855 - mae: 2.0762 - val_loss: 18.7791 - val_mae: 2.7851\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.0737 - mae: 2.0512 - val_loss: 19.4458 - val_mae: 2.6097\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8996 - mae: 1.9635 - val_loss: 18.7684 - val_mae: 2.8008\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.4779 - mae: 1.9404 - val_loss: 19.3931 - val_mae: 2.9358\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.4462 - mae: 1.9635 - val_loss: 21.3847 - val_mae: 2.8877\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7481 - mae: 1.9520 - val_loss: 18.7567 - val_mae: 2.7918\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8882 - mae: 1.9013 - val_loss: 19.4821 - val_mae: 3.1325\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5784 - mae: 1.9328 - val_loss: 19.0447 - val_mae: 2.7267\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0006 - mae: 1.8908 - val_loss: 18.8023 - val_mae: 2.6201\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6329 - mae: 1.8563 - val_loss: 19.7188 - val_mae: 2.9061\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5037 - mae: 1.8705 - val_loss: 18.3466 - val_mae: 2.8492\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6187 - mae: 1.8155 - val_loss: 17.5506 - val_mae: 2.6323\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6265 - mae: 1.8434 - val_loss: 17.2618 - val_mae: 2.7154\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6155 - mae: 1.8000 - val_loss: 17.1657 - val_mae: 2.6376\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1359 - mae: 1.7690 - val_loss: 19.0726 - val_mae: 2.7311\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3568 - mae: 1.7349 - val_loss: 16.6453 - val_mae: 2.5430\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4098 - mae: 1.7400 - val_loss: 17.1314 - val_mae: 2.6560\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1976 - mae: 1.7814 - val_loss: 18.1448 - val_mae: 2.6191\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0569 - mae: 1.7159 - val_loss: 17.6895 - val_mae: 2.6544\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7197 - mae: 1.7085 - val_loss: 17.9724 - val_mae: 2.6191\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9079 - mae: 1.6624 - val_loss: 16.9685 - val_mae: 2.6324\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8448 - mae: 1.6603 - val_loss: 18.4080 - val_mae: 2.8152\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4180 - mae: 1.6452 - val_loss: 19.1476 - val_mae: 2.6564\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7817 - mae: 1.6465 - val_loss: 16.2456 - val_mae: 2.5857\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3682 - mae: 1.6248 - val_loss: 14.9888 - val_mae: 2.4205\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3280 - mae: 1.5980 - val_loss: 17.0421 - val_mae: 2.8489\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2851 - mae: 1.6423 - val_loss: 16.2217 - val_mae: 2.5141\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2419 - mae: 1.6123 - val_loss: 18.8866 - val_mae: 2.7218\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1600 - mae: 1.5609 - val_loss: 19.0436 - val_mae: 2.6452\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0614 - mae: 1.5775 - val_loss: 16.8834 - val_mae: 2.4974\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7309 - mae: 1.5699 - val_loss: 16.0922 - val_mae: 2.4845\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0899 - mae: 1.5660 - val_loss: 16.3727 - val_mae: 2.5504\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6320 - mae: 1.5308 - val_loss: 16.4263 - val_mae: 2.8083\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5971 - mae: 1.5394 - val_loss: 17.2688 - val_mae: 2.6429\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8994 - mae: 1.5719 - val_loss: 16.6085 - val_mae: 2.5851\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0348 - mae: 1.5107 - val_loss: 15.2535 - val_mae: 2.4142\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6698 - mae: 1.5130 - val_loss: 15.3957 - val_mae: 2.5551\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4324 - mae: 1.4916 - val_loss: 15.7600 - val_mae: 2.4316\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4192 - mae: 1.4455 - val_loss: 15.4816 - val_mae: 2.6390\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3765 - mae: 1.4693 - val_loss: 17.0303 - val_mae: 2.5835\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3242 - mae: 1.4457 - val_loss: 15.6735 - val_mae: 2.4689\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1401 - mae: 1.4023 - val_loss: 17.1645 - val_mae: 2.4911\n",
      "Epoch 57/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0471 - mae: 1.4545 - val_loss: 18.6431 - val_mae: 2.8500\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0507 - mae: 1.4566 - val_loss: 15.5809 - val_mae: 2.4004\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.1828 - mae: 1.3870 - val_loss: 16.6029 - val_mae: 2.5189\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.2025 - mae: 1.4493 - val_loss: 16.4619 - val_mae: 2.5567\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0895 - mae: 1.4166 - val_loss: 16.3900 - val_mae: 2.6764\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9342 - mae: 1.4294 - val_loss: 18.4723 - val_mae: 2.5888\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8215 - mae: 1.4023 - val_loss: 16.0803 - val_mae: 2.4735\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9078 - mae: 1.3973 - val_loss: 17.0528 - val_mae: 2.7107\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6904 - mae: 1.3716 - val_loss: 15.5707 - val_mae: 2.5932\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6160 - mae: 1.3151 - val_loss: 17.2579 - val_mae: 2.6918\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6824 - mae: 1.3588 - val_loss: 15.5872 - val_mae: 2.4814\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7099 - mae: 1.3990 - val_loss: 15.1517 - val_mae: 2.4930\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4104 - mae: 1.3303 - val_loss: 17.6838 - val_mae: 2.8445\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3904 - mae: 1.2778 - val_loss: 15.5244 - val_mae: 2.4009\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4192 - mae: 1.3404 - val_loss: 17.2798 - val_mae: 2.7690\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3862 - mae: 1.3088 - val_loss: 15.4050 - val_mae: 2.3912\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6117 - mae: 1.3123 - val_loss: 16.5432 - val_mae: 2.6675\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6534 - mae: 1.3686 - val_loss: 15.1200 - val_mae: 2.5194\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1073 - mae: 1.2517 - val_loss: 16.5595 - val_mae: 2.6135\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4299 - mae: 1.3174 - val_loss: 16.9484 - val_mae: 2.7364\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2464 - mae: 1.2864 - val_loss: 16.3605 - val_mae: 2.6474\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1740 - mae: 1.2916 - val_loss: 16.6089 - val_mae: 2.6807\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0916 - mae: 1.2841 - val_loss: 15.7208 - val_mae: 2.6559\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1211 - mae: 1.2907 - val_loss: 15.3628 - val_mae: 2.5075\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.9034 - mae: 1.2244 - val_loss: 15.1569 - val_mae: 2.5810\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0073 - mae: 1.2444 - val_loss: 17.4778 - val_mae: 2.8583\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0056 - mae: 1.2555 - val_loss: 16.6476 - val_mae: 2.6103\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1084 - mae: 1.2377 - val_loss: 14.1419 - val_mae: 2.4253\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0443 - mae: 1.2294 - val_loss: 17.4211 - val_mae: 2.7772\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.9104 - mae: 1.2241 - val_loss: 15.8073 - val_mae: 2.6217\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8596 - mae: 1.2254 - val_loss: 15.3513 - val_mae: 2.5480\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8675 - mae: 1.2438 - val_loss: 16.4489 - val_mae: 2.5686\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7196 - mae: 1.1993 - val_loss: 16.0360 - val_mae: 2.5503\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8221 - mae: 1.2087 - val_loss: 19.0776 - val_mae: 2.7978\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7057 - mae: 1.1746 - val_loss: 17.1768 - val_mae: 2.7815\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.6427 - mae: 1.1618 - val_loss: 14.9295 - val_mae: 2.5828\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7388 - mae: 1.2369 - val_loss: 16.6666 - val_mae: 2.5947\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7274 - mae: 1.2135 - val_loss: 15.9355 - val_mae: 2.6448\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5504 - mae: 1.1794 - val_loss: 18.1962 - val_mae: 2.8802\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.6468 - mae: 1.1568 - val_loss: 15.3531 - val_mae: 2.5750\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.4950 - mae: 1.1490 - val_loss: 15.7790 - val_mae: 2.5028\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.4533 - mae: 1.1183 - val_loss: 15.7963 - val_mae: 2.7082\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5470 - mae: 1.1877 - val_loss: 17.7256 - val_mae: 2.6836\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.4998 - mae: 1.1698 - val_loss: 15.7789 - val_mae: 2.6191\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5725 - mae: 1.1401 - val_loss: 16.1846 - val_mae: 2.6123\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5421 - mae: 1.1081 - val_loss: 14.6389 - val_mae: 2.6280\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.3260 - mae: 1.1217 - val_loss: 18.0456 - val_mae: 2.9270\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5755 - mae: 1.1273 - val_loss: 19.1047 - val_mae: 2.9868\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.5003 - mae: 1.1359 - val_loss: 15.4719 - val_mae: 2.5598\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.2479 - mae: 1.1108 - val_loss: 15.9477 - val_mae: 2.6337\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.3007 - mae: 1.1019 - val_loss: 14.6878 - val_mae: 2.5404\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.3556 - mae: 1.1262 - val_loss: 16.5328 - val_mae: 2.6843\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.2480 - mae: 1.1059 - val_loss: 15.5405 - val_mae: 2.6541\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.4800 - mae: 1.1592 - val_loss: 16.8532 - val_mae: 2.8017\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.3581 - mae: 1.1202 - val_loss: 16.8323 - val_mae: 2.6147\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.2650 - mae: 1.0752 - val_loss: 21.7574 - val_mae: 3.1023\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.2956 - mae: 1.1055 - val_loss: 14.6626 - val_mae: 2.5858\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.2585 - mae: 1.0517 - val_loss: 16.4042 - val_mae: 2.6626\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.3764 - mae: 1.0828 - val_loss: 16.5059 - val_mae: 2.6783\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.2530 - mae: 1.0782 - val_loss: 15.7916 - val_mae: 2.6998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.4195 - mae: 1.1211 - val_loss: 15.4110 - val_mae: 2.5838\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 1.9765 - mae: 0.9778 - val_loss: 19.6516 - val_mae: 3.1049\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.0205 - mae: 1.0547 - val_loss: 17.2270 - val_mae: 2.6905\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.3317 - mae: 1.0742 - val_loss: 15.4924 - val_mae: 2.7116\n",
      "processing fold # 4\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 182.2348 - mae: 10.1056 - val_loss: 51.0856 - val_mae: 4.6270\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 29.0905 - mae: 3.6456 - val_loss: 44.7403 - val_mae: 4.0898\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 19.6147 - mae: 3.0475 - val_loss: 36.9193 - val_mae: 3.7208\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 16.1240 - mae: 2.6484 - val_loss: 37.7861 - val_mae: 3.7643\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 15.1263 - mae: 2.5124 - val_loss: 28.7937 - val_mae: 3.1636\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.7522 - mae: 2.3876 - val_loss: 29.0599 - val_mae: 3.1882\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.9541 - mae: 2.2770 - val_loss: 30.7522 - val_mae: 3.3026\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.2832 - mae: 2.3044 - val_loss: 32.9953 - val_mae: 3.4613\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.9275 - mae: 2.2383 - val_loss: 25.3608 - val_mae: 2.9660\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.9817 - mae: 2.2060 - val_loss: 26.0176 - val_mae: 3.0643\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.1148 - mae: 2.1510 - val_loss: 21.8951 - val_mae: 2.8416\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.4446 - mae: 2.1499 - val_loss: 23.0610 - val_mae: 2.8859\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.1047 - mae: 2.0616 - val_loss: 19.9203 - val_mae: 2.8099\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.7811 - mae: 2.0392 - val_loss: 20.6745 - val_mae: 2.8505\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.3673 - mae: 2.0838 - val_loss: 18.8782 - val_mae: 2.7264\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.5498 - mae: 2.0651 - val_loss: 20.9400 - val_mae: 2.8148\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4979 - mae: 1.9573 - val_loss: 20.6687 - val_mae: 3.0278\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4200 - mae: 1.9850 - val_loss: 18.1225 - val_mae: 2.8345\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.3338 - mae: 1.9300 - val_loss: 18.0949 - val_mae: 2.8079\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.8543 - mae: 1.8839 - val_loss: 17.7988 - val_mae: 2.7192\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6098 - mae: 1.9372 - val_loss: 18.1590 - val_mae: 2.6191\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.3694 - mae: 1.8835 - val_loss: 17.2557 - val_mae: 2.7045\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1267 - mae: 1.9232 - val_loss: 16.4123 - val_mae: 2.6003\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6093 - mae: 1.8756 - val_loss: 15.9658 - val_mae: 2.4968\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8818 - mae: 1.8192 - val_loss: 16.4713 - val_mae: 2.6444\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.9689 - mae: 1.8691 - val_loss: 16.6638 - val_mae: 2.6907\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7551 - mae: 1.7575 - val_loss: 13.4336 - val_mae: 2.5413\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.9993 - mae: 1.8419 - val_loss: 14.2783 - val_mae: 2.6046\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5972 - mae: 1.8268 - val_loss: 17.3070 - val_mae: 2.7477\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.7292 - mae: 1.8476 - val_loss: 13.7167 - val_mae: 2.4987\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2190 - mae: 1.7848 - val_loss: 13.6638 - val_mae: 2.5554\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.5784 - mae: 1.8361 - val_loss: 14.3617 - val_mae: 2.4917\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9596 - mae: 1.7111 - val_loss: 13.1101 - val_mae: 2.4603\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7258 - mae: 1.7508 - val_loss: 13.9076 - val_mae: 2.5167\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9383 - mae: 1.8023 - val_loss: 15.0553 - val_mae: 2.6251\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.1733 - mae: 1.7128 - val_loss: 14.9282 - val_mae: 2.8002\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8447 - mae: 1.7837 - val_loss: 14.8229 - val_mae: 2.5583\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.9459 - mae: 1.7218 - val_loss: 14.1050 - val_mae: 2.5688\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.7197 - mae: 1.7014 - val_loss: 15.1088 - val_mae: 2.7203\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.0567 - mae: 1.7158 - val_loss: 15.2628 - val_mae: 2.6015\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8874 - mae: 1.6812 - val_loss: 13.1210 - val_mae: 2.4730\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8656 - mae: 1.6766 - val_loss: 13.7250 - val_mae: 2.6777\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6108 - mae: 1.6267 - val_loss: 13.0105 - val_mae: 2.5014\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3659 - mae: 1.6695 - val_loss: 13.3748 - val_mae: 2.5028\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4206 - mae: 1.7008 - val_loss: 12.4409 - val_mae: 2.4049\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4246 - mae: 1.6902 - val_loss: 12.6210 - val_mae: 2.4901\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4203 - mae: 1.6493 - val_loss: 12.7731 - val_mae: 2.4639\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2860 - mae: 1.6255 - val_loss: 14.6344 - val_mae: 2.6651\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1766 - mae: 1.6714 - val_loss: 13.0159 - val_mae: 2.5035\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2247 - mae: 1.6684 - val_loss: 13.3270 - val_mae: 2.5797\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9846 - mae: 1.5806 - val_loss: 14.3503 - val_mae: 2.6602\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2363 - mae: 1.6233 - val_loss: 12.7538 - val_mae: 2.4376\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8651 - mae: 1.5951 - val_loss: 13.7393 - val_mae: 2.7067\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9636 - mae: 1.6524 - val_loss: 11.7409 - val_mae: 2.3665\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6833 - mae: 1.5741 - val_loss: 14.7350 - val_mae: 2.6702\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5815 - mae: 1.5652 - val_loss: 12.1428 - val_mae: 2.4199\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9126 - mae: 1.6309 - val_loss: 12.3171 - val_mae: 2.4557\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0380 - mae: 1.5607 - val_loss: 12.3705 - val_mae: 2.4918\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5549 - mae: 1.5828 - val_loss: 13.2298 - val_mae: 2.5574\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7753 - mae: 1.6068 - val_loss: 14.7033 - val_mae: 2.8129\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6810 - mae: 1.5425 - val_loss: 15.9862 - val_mae: 2.7940\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4995 - mae: 1.5169 - val_loss: 11.8925 - val_mae: 2.3821\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6404 - mae: 1.5592 - val_loss: 12.6612 - val_mae: 2.4169\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6171 - mae: 1.5334 - val_loss: 11.7998 - val_mae: 2.3926\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4766 - mae: 1.5821 - val_loss: 12.5473 - val_mae: 2.3803\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4050 - mae: 1.4896 - val_loss: 16.4930 - val_mae: 2.9347\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7650 - mae: 1.5851 - val_loss: 12.3787 - val_mae: 2.4649\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2585 - mae: 1.5208 - val_loss: 12.4638 - val_mae: 2.4319\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2441 - mae: 1.5630 - val_loss: 12.9360 - val_mae: 2.4310\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3506 - mae: 1.5010 - val_loss: 12.6701 - val_mae: 2.4053\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4978 - mae: 1.5451 - val_loss: 11.4306 - val_mae: 2.3865\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3525 - mae: 1.4901 - val_loss: 13.4630 - val_mae: 2.5323\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0816 - mae: 1.4981 - val_loss: 14.8636 - val_mae: 2.9119\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2461 - mae: 1.5614 - val_loss: 14.3174 - val_mae: 2.6676\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1370 - mae: 1.5205 - val_loss: 13.2476 - val_mae: 2.4974\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2486 - mae: 1.5322 - val_loss: 11.9140 - val_mae: 2.4049\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8831 - mae: 1.4706 - val_loss: 11.8994 - val_mae: 2.3039\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1971 - mae: 1.5067 - val_loss: 11.6751 - val_mae: 2.3225\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8396 - mae: 1.4139 - val_loss: 13.4160 - val_mae: 2.5945\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8553 - mae: 1.4683 - val_loss: 11.8946 - val_mae: 2.3618\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0764 - mae: 1.5244 - val_loss: 13.6865 - val_mae: 2.7538\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8559 - mae: 1.4601 - val_loss: 11.9144 - val_mae: 2.2889\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9999 - mae: 1.4566 - val_loss: 12.7909 - val_mae: 2.4298\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6518 - mae: 1.3825 - val_loss: 15.0378 - val_mae: 2.6277\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9154 - mae: 1.4415 - val_loss: 12.2809 - val_mae: 2.3494\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0679 - mae: 1.5233 - val_loss: 12.1713 - val_mae: 2.4358\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4266 - mae: 1.4704 - val_loss: 11.5176 - val_mae: 2.3702\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0672 - mae: 1.4627 - val_loss: 11.6497 - val_mae: 2.3102\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7074 - mae: 1.4320 - val_loss: 12.7267 - val_mae: 2.4681\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5420 - mae: 1.3962 - val_loss: 11.1268 - val_mae: 2.3512\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8620 - mae: 1.4296 - val_loss: 12.0833 - val_mae: 2.4715\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5331 - mae: 1.4162 - val_loss: 12.4639 - val_mae: 2.4980\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2133 - mae: 1.4058 - val_loss: 11.7244 - val_mae: 2.4212\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8659 - mae: 1.4415 - val_loss: 13.0092 - val_mae: 2.6019\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4498 - mae: 1.3362 - val_loss: 11.3609 - val_mae: 2.2746\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7545 - mae: 1.4545 - val_loss: 11.9230 - val_mae: 2.4500\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4460 - mae: 1.3864 - val_loss: 11.0951 - val_mae: 2.3898\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6483 - mae: 1.3677 - val_loss: 11.4821 - val_mae: 2.4477\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7292 - mae: 1.3941 - val_loss: 11.8028 - val_mae: 2.4064\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2516 - mae: 1.4075 - val_loss: 12.8745 - val_mae: 2.6101\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8291 - mae: 1.2934 - val_loss: 12.4468 - val_mae: 2.4338\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5292 - mae: 1.3980 - val_loss: 12.4242 - val_mae: 2.5335\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1423 - mae: 1.4013 - val_loss: 13.1417 - val_mae: 2.6006\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1251 - mae: 1.3378 - val_loss: 11.5748 - val_mae: 2.3755\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2843 - mae: 1.4006 - val_loss: 14.1104 - val_mae: 2.7586\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5243 - mae: 1.4530 - val_loss: 11.3219 - val_mae: 2.3521\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2654 - mae: 1.3726 - val_loss: 11.0077 - val_mae: 2.3091\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0874 - mae: 1.3342 - val_loss: 13.0283 - val_mae: 2.5771\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0214 - mae: 1.3246 - val_loss: 12.5878 - val_mae: 2.6864\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0616 - mae: 1.2848 - val_loss: 13.5355 - val_mae: 2.6979\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4190 - mae: 1.3643 - val_loss: 12.1842 - val_mae: 2.4531\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0818 - mae: 1.3427 - val_loss: 12.0314 - val_mae: 2.4693\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8638 - mae: 1.3011 - val_loss: 13.5217 - val_mae: 2.7161\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2818 - mae: 1.3479 - val_loss: 11.8647 - val_mae: 2.5724\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8670 - mae: 1.2893 - val_loss: 13.2558 - val_mae: 2.5121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3239 - mae: 1.2953 - val_loss: 13.4016 - val_mae: 2.7626\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7824 - mae: 1.2623 - val_loss: 14.5704 - val_mae: 2.8613\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8832 - mae: 1.3571 - val_loss: 10.7831 - val_mae: 2.3400\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9071 - mae: 1.3296 - val_loss: 10.8433 - val_mae: 2.3436\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8448 - mae: 1.3792 - val_loss: 11.3492 - val_mae: 2.4715\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 5\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 120\n",
    "all_scores = []\n",
    "\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the average of the per-epoch MAE scores for all folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(1, len(average_mae_history) + 1)[5:], average_mae_history[5:])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that validation MAE stops improving significantly after 50 epochs. We can now train a final \"production\" model on all of the training data, with the best parameters, then look at its performance on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 212.7267 - mae: 10.9149 - val_loss: 46.8454 - val_mae: 4.7857\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 27.8497 - mae: 3.4460 - val_loss: 21.5750 - val_mae: 3.3239\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 19.6248 - mae: 2.9420 - val_loss: 15.2871 - val_mae: 2.9287\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 16.5835 - mae: 2.6455 - val_loss: 14.4579 - val_mae: 2.8861\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 14.5913 - mae: 2.4426 - val_loss: 13.0982 - val_mae: 2.8360\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 13.8170 - mae: 2.4475 - val_loss: 12.5205 - val_mae: 2.7959\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 12.6099 - mae: 2.3448 - val_loss: 11.6538 - val_mae: 2.6013\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.3472 - mae: 2.2825 - val_loss: 12.6731 - val_mae: 2.7263\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.7879 - mae: 2.2662 - val_loss: 10.9295 - val_mae: 2.5884\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.4595 - mae: 2.2484 - val_loss: 13.3273 - val_mae: 2.8225\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.7846 - mae: 2.1935 - val_loss: 12.4704 - val_mae: 2.8320\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.6904 - mae: 2.1859 - val_loss: 10.9413 - val_mae: 2.5379\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.1575 - mae: 2.1576 - val_loss: 11.3015 - val_mae: 2.6168\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.1467 - mae: 2.1280 - val_loss: 11.2238 - val_mae: 2.5668\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.4870 - mae: 1.9963 - val_loss: 11.3460 - val_mae: 2.5830\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.5704 - mae: 2.0357 - val_loss: 11.0930 - val_mae: 2.5057\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.6295 - mae: 1.9960 - val_loss: 11.6746 - val_mae: 2.5567\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.2578 - mae: 2.0001 - val_loss: 12.4572 - val_mae: 2.5219\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.1141 - mae: 1.9950 - val_loss: 13.2640 - val_mae: 2.5688\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.7479 - mae: 1.9570 - val_loss: 12.4327 - val_mae: 2.5792\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.7304 - mae: 1.9422 - val_loss: 14.7685 - val_mae: 3.0358\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.7720 - mae: 1.9630 - val_loss: 11.7900 - val_mae: 2.4864\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.1419 - mae: 1.8857 - val_loss: 12.9992 - val_mae: 2.5717\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.1413 - mae: 1.8923 - val_loss: 12.4750 - val_mae: 2.5793\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.8023 - mae: 1.8147 - val_loss: 13.3822 - val_mae: 2.7625\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.3386 - mae: 1.8291 - val_loss: 11.8679 - val_mae: 2.4861\n",
      "Epoch 27/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.9102 - mae: 1.8261 - val_loss: 15.0017 - val_mae: 2.9305\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.3976 - mae: 1.8009 - val_loss: 15.4058 - val_mae: 2.6179\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.7202 - mae: 1.8565 - val_loss: 12.1628 - val_mae: 2.4666\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.7105 - mae: 1.8639 - val_loss: 11.4932 - val_mae: 2.3229\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.5649 - mae: 1.8194 - val_loss: 12.1523 - val_mae: 2.4357\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.3099 - mae: 1.7995 - val_loss: 13.8619 - val_mae: 2.4868\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.4413 - mae: 1.7918 - val_loss: 11.7419 - val_mae: 2.3611\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.3478 - mae: 1.7684 - val_loss: 13.8411 - val_mae: 2.5774\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.2028 - mae: 1.8144 - val_loss: 15.6509 - val_mae: 2.9471\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.8214 - mae: 1.7426 - val_loss: 16.3041 - val_mae: 2.9583\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.3525 - mae: 1.7339 - val_loss: 14.0888 - val_mae: 2.7580\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.3787 - mae: 1.7469 - val_loss: 12.0177 - val_mae: 2.4637\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.6807 - mae: 1.7235 - val_loss: 14.5887 - val_mae: 2.5504\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.7187 - mae: 1.7169 - val_loss: 15.2550 - val_mae: 2.6006\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.8502 - mae: 1.7654 - val_loss: 13.6901 - val_mae: 2.6654\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.7918 - mae: 1.7133 - val_loss: 14.5138 - val_mae: 2.6740\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.1025 - mae: 1.6282 - val_loss: 14.7543 - val_mae: 2.7147\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.6737 - mae: 1.7154 - val_loss: 14.2038 - val_mae: 2.6668\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.4278 - mae: 1.6470 - val_loss: 13.0951 - val_mae: 2.4640\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.2569 - mae: 1.6715 - val_loss: 12.1633 - val_mae: 2.4453\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.1737 - mae: 1.6352 - val_loss: 13.7270 - val_mae: 2.5453\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.0676 - mae: 1.6299 - val_loss: 13.1634 - val_mae: 2.5715\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3709 - mae: 1.6525 - val_loss: 11.5364 - val_mae: 2.3340\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.0867 - mae: 1.6835 - val_loss: 13.3146 - val_mae: 2.6378\n"
     ]
    }
   ],
   "source": [
    "# Get a fresh, compiled model.\n",
    "model = build_model()\n",
    "# Train it on the entirety of the data.\n",
    "history = model.fit(train_data, train_targets, validation_split =0.2,\n",
    "          epochs=50, batch_size=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "plt.plot(epochs[10:], mae[10:], 'r', label='mean_absolute_error')\n",
    "plt.plot(epochs[10:], val_mae[10:], 'b', label='val_mean_absolute_error')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 - 0s - loss: 19.9372 - mae: 2.8951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.895068"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets, verbose=2)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exercise - tuning model parameters <a id='exc' />\n",
    "Please train the above model in the below two scenerios: make the changes on the indicated training configurations (the rest no change). Train both models for 120 epochs. \n",
    "\n",
    "**Scenerio A**:\n",
    "* change the batch size from 1 to 128\n",
    "\n",
    "**Scenerio B**:\n",
    "* change the learning rate (`optimizers.RMSprop(lr=0.001)`) from 0.001 to 0.0002\n",
    "\n",
    "Observe the training and validation MAE curves for both scenerios.\n",
    "\n",
    "Provide your codes & observations in the below boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scenerio A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Build the model and no changes\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()\n",
    "\n",
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/200\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 551.5434 - mae: 21.6466 - val_loss: 596.7510 - val_mae: 22.6800\n",
      "Epoch 2/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 520.1315 - mae: 20.9450 - val_loss: 568.5994 - val_mae: 22.0923\n",
      "Epoch 3/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 495.2437 - mae: 20.3736 - val_loss: 543.2614 - val_mae: 21.5532\n",
      "Epoch 4/200\n",
      "323/323 [==============================] - 0s 401us/sample - loss: 471.8371 - mae: 19.8337 - val_loss: 517.2541 - val_mae: 20.9919\n",
      "Epoch 5/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 448.0203 - mae: 19.2765 - val_loss: 491.9008 - val_mae: 20.4255\n",
      "Epoch 6/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 424.4227 - mae: 18.7058 - val_loss: 465.0474 - val_mae: 19.8133\n",
      "Epoch 7/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 399.7820 - mae: 18.1038 - val_loss: 437.1873 - val_mae: 19.1552\n",
      "Epoch 8/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 374.5030 - mae: 17.4691 - val_loss: 409.4355 - val_mae: 18.4719\n",
      "Epoch 9/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 349.0864 - mae: 16.8005 - val_loss: 381.0613 - val_mae: 17.7524\n",
      "Epoch 10/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 322.7808 - mae: 16.0870 - val_loss: 351.1329 - val_mae: 16.9674\n",
      "Epoch 11/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 295.9782 - mae: 15.3290 - val_loss: 323.5248 - val_mae: 16.1987\n",
      "Epoch 12/200\n",
      "323/323 [==============================] - 0s 61us/sample - loss: 270.7167 - mae: 14.5676 - val_loss: 295.4265 - val_mae: 15.3699\n",
      "Epoch 13/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 245.6371 - mae: 13.7602 - val_loss: 269.0062 - val_mae: 14.5383\n",
      "Epoch 14/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 222.1155 - mae: 12.9682 - val_loss: 243.5474 - val_mae: 13.6789\n",
      "Epoch 15/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 199.7560 - mae: 12.1578 - val_loss: 220.0026 - val_mae: 12.8140\n",
      "Epoch 16/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 179.0086 - mae: 11.3667 - val_loss: 197.6339 - val_mae: 11.9168\n",
      "Epoch 17/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 159.6516 - mae: 10.5970 - val_loss: 176.8412 - val_mae: 11.0598\n",
      "Epoch 18/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 141.9866 - mae: 9.8985 - val_loss: 157.2932 - val_mae: 10.2657\n",
      "Epoch 19/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 125.7487 - mae: 9.2278 - val_loss: 140.6979 - val_mae: 9.5833\n",
      "Epoch 20/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 112.0177 - mae: 8.6402 - val_loss: 125.3107 - val_mae: 8.9549\n",
      "Epoch 21/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 99.7344 - mae: 8.0810 - val_loss: 111.9250 - val_mae: 8.3920\n",
      "Epoch 22/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 89.2850 - mae: 7.5643 - val_loss: 100.8610 - val_mae: 7.8791\n",
      "Epoch 23/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 80.4604 - mae: 7.1114 - val_loss: 90.1806 - val_mae: 7.4092\n",
      "Epoch 24/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 72.4690 - mae: 6.6929 - val_loss: 81.5071 - val_mae: 7.0293\n",
      "Epoch 25/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 65.8900 - mae: 6.3338 - val_loss: 73.6452 - val_mae: 6.6765\n",
      "Epoch 26/200\n",
      "323/323 [==============================] - 0s 67us/sample - loss: 60.0390 - mae: 6.0012 - val_loss: 67.0940 - val_mae: 6.3510\n",
      "Epoch 27/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 55.0221 - mae: 5.7104 - val_loss: 61.1142 - val_mae: 6.0438\n",
      "Epoch 28/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 50.5483 - mae: 5.4300 - val_loss: 55.8003 - val_mae: 5.7437\n",
      "Epoch 29/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 46.5207 - mae: 5.1768 - val_loss: 51.0927 - val_mae: 5.4639\n",
      "Epoch 30/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 43.0146 - mae: 4.9396 - val_loss: 46.5512 - val_mae: 5.2123\n",
      "Epoch 31/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 39.7800 - mae: 4.7015 - val_loss: 42.9921 - val_mae: 4.9999\n",
      "Epoch 32/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 37.1868 - mae: 4.5258 - val_loss: 39.4514 - val_mae: 4.8128\n",
      "Epoch 33/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 34.7920 - mae: 4.3432 - val_loss: 36.9896 - val_mae: 4.6365\n",
      "Epoch 34/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 32.6525 - mae: 4.1800 - val_loss: 34.5431 - val_mae: 4.4879\n",
      "Epoch 35/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 30.8269 - mae: 4.0246 - val_loss: 32.3375 - val_mae: 4.3394\n",
      "Epoch 36/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 29.2002 - mae: 3.8731 - val_loss: 30.2705 - val_mae: 4.2073\n",
      "Epoch 37/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 27.7678 - mae: 3.7952 - val_loss: 28.7867 - val_mae: 4.1305\n",
      "Epoch 38/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 26.5710 - mae: 3.6750 - val_loss: 27.3021 - val_mae: 4.0533\n",
      "Epoch 39/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 25.5017 - mae: 3.5940 - val_loss: 25.9643 - val_mae: 3.9834\n",
      "Epoch 40/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 24.5195 - mae: 3.4943 - val_loss: 24.7127 - val_mae: 3.8545\n",
      "Epoch 41/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 23.7858 - mae: 3.4265 - val_loss: 23.9577 - val_mae: 3.8523\n",
      "Epoch 42/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 23.2491 - mae: 3.4081 - val_loss: 23.4214 - val_mae: 3.7873\n",
      "Epoch 43/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 22.3505 - mae: 3.3303 - val_loss: 22.3802 - val_mae: 3.7080\n",
      "Epoch 44/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 21.8127 - mae: 3.2850 - val_loss: 21.7592 - val_mae: 3.7051\n",
      "Epoch 45/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 21.2135 - mae: 3.2884 - val_loss: 20.8738 - val_mae: 3.6105\n",
      "Epoch 46/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 20.7831 - mae: 3.2491 - val_loss: 20.5698 - val_mae: 3.5707\n",
      "Epoch 47/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 20.0973 - mae: 3.1401 - val_loss: 19.8545 - val_mae: 3.5165\n",
      "Epoch 48/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 19.5879 - mae: 3.1341 - val_loss: 19.7515 - val_mae: 3.5327\n",
      "Epoch 49/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 19.0564 - mae: 3.0905 - val_loss: 18.9890 - val_mae: 3.4265\n",
      "Epoch 50/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 18.5213 - mae: 3.0288 - val_loss: 18.4207 - val_mae: 3.3761\n",
      "Epoch 51/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 18.1596 - mae: 2.9869 - val_loss: 18.4040 - val_mae: 3.4128\n",
      "Epoch 52/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 17.6229 - mae: 2.9574 - val_loss: 17.6282 - val_mae: 3.2493\n",
      "Epoch 53/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 17.3126 - mae: 2.9178 - val_loss: 17.4832 - val_mae: 3.3038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 16.9752 - mae: 2.8827 - val_loss: 16.8391 - val_mae: 3.2185\n",
      "Epoch 55/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 16.6078 - mae: 2.8598 - val_loss: 16.5219 - val_mae: 3.1685\n",
      "Epoch 56/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 16.0265 - mae: 2.8060 - val_loss: 16.2516 - val_mae: 3.1469\n",
      "Epoch 57/200\n",
      "323/323 [==============================] - ETA: 0s - loss: 19.7839 - mae: 2.91 - 0s 56us/sample - loss: 15.7360 - mae: 2.7579 - val_loss: 16.1323 - val_mae: 3.1290\n",
      "Epoch 58/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 15.4206 - mae: 2.7337 - val_loss: 16.2367 - val_mae: 3.1716\n",
      "Epoch 59/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 15.3524 - mae: 2.7439 - val_loss: 15.9647 - val_mae: 3.1396\n",
      "Epoch 60/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 14.8736 - mae: 2.6961 - val_loss: 15.1416 - val_mae: 3.0405\n",
      "Epoch 61/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 14.3609 - mae: 2.6384 - val_loss: 14.7747 - val_mae: 2.9768\n",
      "Epoch 62/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 14.2093 - mae: 2.6316 - val_loss: 14.7323 - val_mae: 3.0117\n",
      "Epoch 63/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 13.8528 - mae: 2.5805 - val_loss: 14.7739 - val_mae: 3.0330\n",
      "Epoch 64/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 13.6878 - mae: 2.5650 - val_loss: 14.2806 - val_mae: 2.9575\n",
      "Epoch 65/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 13.2981 - mae: 2.5342 - val_loss: 14.1897 - val_mae: 2.9458\n",
      "Epoch 66/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 13.2825 - mae: 2.5093 - val_loss: 13.9774 - val_mae: 2.8922\n",
      "Epoch 67/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 12.8430 - mae: 2.4922 - val_loss: 13.8462 - val_mae: 2.8187\n",
      "Epoch 68/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 12.6085 - mae: 2.4714 - val_loss: 13.8539 - val_mae: 2.8859\n",
      "Epoch 69/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 12.7698 - mae: 2.4539 - val_loss: 13.9189 - val_mae: 2.8308\n",
      "Epoch 70/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 12.1754 - mae: 2.4597 - val_loss: 13.4466 - val_mae: 2.8190\n",
      "Epoch 71/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 11.9351 - mae: 2.4032 - val_loss: 13.3309 - val_mae: 2.7750\n",
      "Epoch 72/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 11.7562 - mae: 2.4142 - val_loss: 13.3741 - val_mae: 2.7724\n",
      "Epoch 73/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 11.5102 - mae: 2.3788 - val_loss: 13.7726 - val_mae: 2.8152\n",
      "Epoch 74/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 11.7122 - mae: 2.4165 - val_loss: 13.5317 - val_mae: 2.7434\n",
      "Epoch 75/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 11.1325 - mae: 2.3807 - val_loss: 12.9793 - val_mae: 2.7331\n",
      "Epoch 76/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 11.0158 - mae: 2.3249 - val_loss: 13.5491 - val_mae: 2.7843\n",
      "Epoch 77/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 10.7979 - mae: 2.2904 - val_loss: 13.1366 - val_mae: 2.6876\n",
      "Epoch 78/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 10.9293 - mae: 2.3536 - val_loss: 12.7873 - val_mae: 2.6521\n",
      "Epoch 79/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 10.5233 - mae: 2.2950 - val_loss: 13.0547 - val_mae: 2.7546\n",
      "Epoch 80/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 10.5895 - mae: 2.2423 - val_loss: 12.9739 - val_mae: 2.6771\n",
      "Epoch 81/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 10.3956 - mae: 2.2814 - val_loss: 12.5725 - val_mae: 2.6395\n",
      "Epoch 82/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 10.1651 - mae: 2.2459 - val_loss: 12.6293 - val_mae: 2.6373\n",
      "Epoch 83/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 10.1016 - mae: 2.2266 - val_loss: 12.8856 - val_mae: 2.5971\n",
      "Epoch 84/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 10.0086 - mae: 2.2449 - val_loss: 13.0553 - val_mae: 2.6414\n",
      "Epoch 85/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 9.9345 - mae: 2.2316 - val_loss: 12.7079 - val_mae: 2.6645\n",
      "Epoch 86/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 9.9365 - mae: 2.2139 - val_loss: 13.0170 - val_mae: 2.6396\n",
      "Epoch 87/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 9.8045 - mae: 2.2419 - val_loss: 12.9997 - val_mae: 2.6339\n",
      "Epoch 88/200\n",
      "323/323 [==============================] - 0s 57us/sample - loss: 9.5385 - mae: 2.1946 - val_loss: 12.7881 - val_mae: 2.6613\n",
      "Epoch 89/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 9.5281 - mae: 2.1856 - val_loss: 13.0357 - val_mae: 2.6343\n",
      "Epoch 90/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 9.4334 - mae: 2.1910 - val_loss: 12.7367 - val_mae: 2.6519\n",
      "Epoch 91/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 9.4962 - mae: 2.1821 - val_loss: 12.5871 - val_mae: 2.6158\n",
      "Epoch 92/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 9.2312 - mae: 2.1293 - val_loss: 12.7223 - val_mae: 2.6220\n",
      "Epoch 93/200\n",
      "323/323 [==============================] - 0s 64us/sample - loss: 9.2333 - mae: 2.1483 - val_loss: 12.7808 - val_mae: 2.6491\n",
      "Epoch 94/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 9.2979 - mae: 2.1360 - val_loss: 12.8095 - val_mae: 2.5871\n",
      "Epoch 95/200\n",
      "323/323 [==============================] - ETA: 0s - loss: 8.1444 - mae: 2.047 - 0s 65us/sample - loss: 9.1932 - mae: 2.1285 - val_loss: 12.5423 - val_mae: 2.5526\n",
      "Epoch 96/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.9180 - mae: 2.1107 - val_loss: 12.9758 - val_mae: 2.6382\n",
      "Epoch 97/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 9.2554 - mae: 2.1252 - val_loss: 13.6002 - val_mae: 2.6006\n",
      "Epoch 98/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 9.1234 - mae: 2.1561 - val_loss: 13.1865 - val_mae: 2.5824\n",
      "Epoch 99/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.7830 - mae: 2.1298 - val_loss: 12.3964 - val_mae: 2.5632\n",
      "Epoch 100/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.6937 - mae: 2.0728 - val_loss: 12.6320 - val_mae: 2.5084\n",
      "Epoch 101/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.8048 - mae: 2.0874 - val_loss: 13.5125 - val_mae: 2.6262\n",
      "Epoch 102/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.7083 - mae: 2.1311 - val_loss: 12.7459 - val_mae: 2.5568\n",
      "Epoch 103/200\n",
      "323/323 [==============================] - 0s 60us/sample - loss: 8.5617 - mae: 2.0653 - val_loss: 12.9604 - val_mae: 2.5747\n",
      "Epoch 104/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.4481 - mae: 2.0596 - val_loss: 12.5370 - val_mae: 2.5329\n",
      "Epoch 105/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 8.6847 - mae: 2.0993 - val_loss: 12.5239 - val_mae: 2.5381\n",
      "Epoch 106/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.4708 - mae: 2.0577 - val_loss: 12.7312 - val_mae: 2.5405\n",
      "Epoch 107/200\n",
      "323/323 [==============================] - 0s 61us/sample - loss: 8.3996 - mae: 2.0474 - val_loss: 12.5183 - val_mae: 2.5530\n",
      "Epoch 108/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 8.2767 - mae: 2.0039 - val_loss: 13.1791 - val_mae: 2.5304\n",
      "Epoch 109/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 8.2794 - mae: 2.0565 - val_loss: 12.7655 - val_mae: 2.5173\n",
      "Epoch 110/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.2351 - mae: 2.0248 - val_loss: 12.7485 - val_mae: 2.4785\n",
      "Epoch 111/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.1292 - mae: 2.0181 - val_loss: 13.1204 - val_mae: 2.5282\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 62us/sample - loss: 8.1045 - mae: 2.0140 - val_loss: 13.3906 - val_mae: 2.4902\n",
      "Epoch 113/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.1610 - mae: 2.0623 - val_loss: 12.4647 - val_mae: 2.5395\n",
      "Epoch 114/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 8.3586 - mae: 2.0321 - val_loss: 13.2297 - val_mae: 2.5483\n",
      "Epoch 115/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.0033 - mae: 2.0104 - val_loss: 12.6486 - val_mae: 2.4793\n",
      "Epoch 116/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.0988 - mae: 2.0127 - val_loss: 13.0652 - val_mae: 2.5600\n",
      "Epoch 117/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.9097 - mae: 1.9771 - val_loss: 12.6664 - val_mae: 2.4460\n",
      "Epoch 118/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.9427 - mae: 2.0161 - val_loss: 12.5607 - val_mae: 2.4534\n",
      "Epoch 119/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.8654 - mae: 1.9641 - val_loss: 13.5493 - val_mae: 2.5601\n",
      "Epoch 120/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.9328 - mae: 1.9985 - val_loss: 12.5279 - val_mae: 2.4656\n",
      "Epoch 121/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.7334 - mae: 1.9659 - val_loss: 12.8858 - val_mae: 2.4671\n",
      "Epoch 122/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.7033 - mae: 1.9765 - val_loss: 12.5427 - val_mae: 2.5235\n",
      "Epoch 123/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.8247 - mae: 1.9553 - val_loss: 13.0986 - val_mae: 2.5077\n",
      "Epoch 124/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.8998 - mae: 2.0113 - val_loss: 12.4804 - val_mae: 2.4806\n",
      "Epoch 125/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.8821 - mae: 1.9814 - val_loss: 12.3990 - val_mae: 2.4568\n",
      "Epoch 126/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.5336 - mae: 1.9344 - val_loss: 12.3647 - val_mae: 2.4300\n",
      "Epoch 127/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.6152 - mae: 1.9282 - val_loss: 13.7799 - val_mae: 2.5653\n",
      "Epoch 128/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.7136 - mae: 2.0070 - val_loss: 12.4836 - val_mae: 2.4708\n",
      "Epoch 129/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.5894 - mae: 1.9324 - val_loss: 12.3376 - val_mae: 2.4527\n",
      "Epoch 130/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.3951 - mae: 1.8999 - val_loss: 12.6982 - val_mae: 2.4479\n",
      "Epoch 131/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.7941 - mae: 1.9971 - val_loss: 12.6284 - val_mae: 2.4910\n",
      "Epoch 132/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.4343 - mae: 1.9209 - val_loss: 12.3524 - val_mae: 2.4662\n",
      "Epoch 133/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.4142 - mae: 1.8950 - val_loss: 12.9442 - val_mae: 2.4506\n",
      "Epoch 134/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.2583 - mae: 1.9112 - val_loss: 12.5002 - val_mae: 2.4650\n",
      "Epoch 135/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.5670 - mae: 1.9296 - val_loss: 12.4208 - val_mae: 2.4447\n",
      "Epoch 136/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 7.4899 - mae: 1.9107 - val_loss: 12.4411 - val_mae: 2.4417\n",
      "Epoch 137/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.3957 - mae: 1.8974 - val_loss: 12.7696 - val_mae: 2.4516\n",
      "Epoch 138/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.2501 - mae: 1.8924 - val_loss: 12.7136 - val_mae: 2.4448\n",
      "Epoch 139/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.3408 - mae: 1.9128 - val_loss: 12.8518 - val_mae: 2.4498\n",
      "Epoch 140/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.3528 - mae: 1.9264 - val_loss: 12.5679 - val_mae: 2.4385\n",
      "Epoch 141/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.1388 - mae: 1.8686 - val_loss: 12.7764 - val_mae: 2.4481\n",
      "Epoch 142/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.2353 - mae: 1.8638 - val_loss: 13.3067 - val_mae: 2.4859\n",
      "Epoch 143/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.1968 - mae: 1.8710 - val_loss: 13.6694 - val_mae: 2.5027\n",
      "Epoch 144/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 7.2483 - mae: 1.9353 - val_loss: 13.0837 - val_mae: 2.4500\n",
      "Epoch 145/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 7.2757 - mae: 1.9157 - val_loss: 13.1854 - val_mae: 2.5032\n",
      "Epoch 146/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.0483 - mae: 1.8787 - val_loss: 12.8782 - val_mae: 2.4680\n",
      "Epoch 147/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.1565 - mae: 1.8876 - val_loss: 13.0907 - val_mae: 2.4908\n",
      "Epoch 148/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.0734 - mae: 1.8996 - val_loss: 13.2786 - val_mae: 2.5180\n",
      "Epoch 149/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.0648 - mae: 1.8539 - val_loss: 12.8842 - val_mae: 2.4369\n",
      "Epoch 150/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.9359 - mae: 1.8505 - val_loss: 13.0169 - val_mae: 2.4355\n",
      "Epoch 151/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.9961 - mae: 1.8688 - val_loss: 13.2407 - val_mae: 2.5053\n",
      "Epoch 152/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.9187 - mae: 1.8658 - val_loss: 12.6240 - val_mae: 2.4706\n",
      "Epoch 153/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.9093 - mae: 1.8597 - val_loss: 12.8726 - val_mae: 2.4897\n",
      "Epoch 154/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.0186 - mae: 1.8562 - val_loss: 12.6696 - val_mae: 2.4366\n",
      "Epoch 155/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 6.7647 - mae: 1.8068 - val_loss: 12.6936 - val_mae: 2.4409\n",
      "Epoch 156/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.7598 - mae: 1.8206 - val_loss: 12.8306 - val_mae: 2.4964\n",
      "Epoch 157/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.9447 - mae: 1.8158 - val_loss: 13.8587 - val_mae: 2.4375\n",
      "Epoch 158/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.7927 - mae: 1.8509 - val_loss: 13.3786 - val_mae: 2.5079\n",
      "Epoch 159/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.8418 - mae: 1.8358 - val_loss: 12.8368 - val_mae: 2.4486\n",
      "Epoch 160/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.7601 - mae: 1.7970 - val_loss: 14.0628 - val_mae: 2.4729\n",
      "Epoch 161/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.9753 - mae: 1.8486 - val_loss: 13.5767 - val_mae: 2.4452\n",
      "Epoch 162/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 6.6910 - mae: 1.8433 - val_loss: 12.9495 - val_mae: 2.4437\n",
      "Epoch 163/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.0949 - mae: 1.8934 - val_loss: 13.0589 - val_mae: 2.4489\n",
      "Epoch 164/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.5658 - mae: 1.7874 - val_loss: 12.9160 - val_mae: 2.4298\n",
      "Epoch 165/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.6196 - mae: 1.7940 - val_loss: 12.9871 - val_mae: 2.4327\n",
      "Epoch 166/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.5680 - mae: 1.7924 - val_loss: 12.9554 - val_mae: 2.4492\n",
      "Epoch 167/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.5368 - mae: 1.7711 - val_loss: 12.8222 - val_mae: 2.4185\n",
      "Epoch 168/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 6.5663 - mae: 1.7800 - val_loss: 13.1714 - val_mae: 2.4823\n",
      "Epoch 169/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.5415 - mae: 1.7878 - val_loss: 13.4743 - val_mae: 2.5103\n",
      "Epoch 170/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.4865 - mae: 1.7949 - val_loss: 12.9611 - val_mae: 2.4865\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 65us/sample - loss: 6.7610 - mae: 1.8083 - val_loss: 12.8257 - val_mae: 2.4647\n",
      "Epoch 172/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.5002 - mae: 1.7598 - val_loss: 13.1178 - val_mae: 2.4460\n",
      "Epoch 173/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.3732 - mae: 1.7476 - val_loss: 13.4566 - val_mae: 2.4733\n",
      "Epoch 174/200\n",
      "323/323 [==============================] - 0s 63us/sample - loss: 6.3465 - mae: 1.7554 - val_loss: 13.4684 - val_mae: 2.5086\n",
      "Epoch 175/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.5334 - mae: 1.7914 - val_loss: 13.8621 - val_mae: 2.4668\n",
      "Epoch 176/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.3939 - mae: 1.7654 - val_loss: 13.5727 - val_mae: 2.4244\n",
      "Epoch 177/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 6.4529 - mae: 1.7682 - val_loss: 13.4447 - val_mae: 2.5216\n",
      "Epoch 178/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.6120 - mae: 1.7851 - val_loss: 13.3136 - val_mae: 2.4356\n",
      "Epoch 179/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.2443 - mae: 1.7378 - val_loss: 13.8861 - val_mae: 2.5550\n",
      "Epoch 180/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.5772 - mae: 1.7990 - val_loss: 14.4591 - val_mae: 2.5152\n",
      "Epoch 181/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.2651 - mae: 1.7705 - val_loss: 13.2273 - val_mae: 2.4192\n",
      "Epoch 182/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.1907 - mae: 1.7395 - val_loss: 13.1977 - val_mae: 2.4288\n",
      "Epoch 183/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.1678 - mae: 1.7201 - val_loss: 13.6941 - val_mae: 2.4506\n",
      "Epoch 184/200\n",
      "323/323 [==============================] - 0s 93us/sample - loss: 6.2967 - mae: 1.7447 - val_loss: 14.3602 - val_mae: 2.5344\n",
      "Epoch 185/200\n",
      "323/323 [==============================] - 0s 83us/sample - loss: 6.4623 - mae: 1.7975 - val_loss: 13.4977 - val_mae: 2.4454\n",
      "Epoch 186/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.1741 - mae: 1.7150 - val_loss: 13.9688 - val_mae: 2.4373\n",
      "Epoch 187/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 6.3003 - mae: 1.7610 - val_loss: 13.3528 - val_mae: 2.4945\n",
      "Epoch 188/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.1414 - mae: 1.7171 - val_loss: 13.8956 - val_mae: 2.4571\n",
      "Epoch 189/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.1483 - mae: 1.7421 - val_loss: 13.5623 - val_mae: 2.5285\n",
      "Epoch 190/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.3620 - mae: 1.7522 - val_loss: 13.4333 - val_mae: 2.4714\n",
      "Epoch 191/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.1730 - mae: 1.7257 - val_loss: 13.2188 - val_mae: 2.4393\n",
      "Epoch 192/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.0572 - mae: 1.6970 - val_loss: 13.3717 - val_mae: 2.4529\n",
      "Epoch 193/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 5.9987 - mae: 1.6883 - val_loss: 13.1940 - val_mae: 2.4214\n",
      "Epoch 194/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 6.1374 - mae: 1.7322 - val_loss: 13.4831 - val_mae: 2.4609\n",
      "Epoch 195/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.1312 - mae: 1.7175 - val_loss: 14.3756 - val_mae: 2.4750\n",
      "Epoch 196/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.0654 - mae: 1.7252 - val_loss: 13.5718 - val_mae: 2.4185\n",
      "Epoch 197/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 5.9652 - mae: 1.6857 - val_loss: 13.6306 - val_mae: 2.5109\n",
      "Epoch 198/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.2055 - mae: 1.7291 - val_loss: 12.9966 - val_mae: 2.4317\n",
      "Epoch 199/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 5.8913 - mae: 1.6773 - val_loss: 13.0025 - val_mae: 2.4545\n",
      "Epoch 200/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.1745 - mae: 1.7167 - val_loss: 13.7123 - val_mae: 2.4963\n",
      "processing fold # 0\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 0s 2ms/sample - loss: 579.4291 - mae: 22.2913 - val_loss: 430.8582 - val_mae: 19.0148\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 555.1465 - mae: 21.7503 - val_loss: 413.2674 - val_mae: 18.5554\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 533.3602 - mae: 21.2669 - val_loss: 395.5735 - val_mae: 18.0898\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 510.9180 - mae: 20.7717 - val_loss: 376.6249 - val_mae: 17.5872\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 487.2838 - mae: 20.2260 - val_loss: 357.3285 - val_mae: 17.0621\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 462.7797 - mae: 19.6574 - val_loss: 337.1566 - val_mae: 16.5008\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 436.7045 - mae: 19.0447 - val_loss: 315.6502 - val_mae: 15.8959\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 408.9910 - mae: 18.3615 - val_loss: 294.3856 - val_mae: 15.2821\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 381.3744 - mae: 17.6772 - val_loss: 272.8355 - val_mae: 14.6266\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 353.1120 - mae: 16.9358 - val_loss: 250.4385 - val_mae: 13.9410\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 323.7768 - mae: 16.1476 - val_loss: 228.3308 - val_mae: 13.2178\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 295.1066 - mae: 15.3119 - val_loss: 206.5540 - val_mae: 12.4618\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 266.7463 - mae: 14.4441 - val_loss: 185.6286 - val_mae: 11.6966\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 239.1125 - mae: 13.5638 - val_loss: 165.4935 - val_mae: 10.9126\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 212.5946 - mae: 12.6644 - val_loss: 146.6001 - val_mae: 10.1097\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 187.6347 - mae: 11.7282 - val_loss: 129.4995 - val_mae: 9.3329\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 165.1854 - mae: 10.8399 - val_loss: 114.1084 - val_mae: 8.6078\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 144.9047 - mae: 10.0116 - val_loss: 100.4710 - val_mae: 7.9400\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 126.7114 - mae: 9.2069 - val_loss: 88.4737 - val_mae: 7.2992\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 110.8271 - mae: 8.5029 - val_loss: 78.3016 - val_mae: 6.7289\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 97.0219 - mae: 7.8873 - val_loss: 69.9098 - val_mae: 6.2378\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 85.3424 - mae: 7.3231 - val_loss: 62.8092 - val_mae: 5.7954\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 75.2790 - mae: 6.8386 - val_loss: 56.7294 - val_mae: 5.3969\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 66.6294 - mae: 6.3865 - val_loss: 51.5666 - val_mae: 5.0575\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 59.4514 - mae: 5.9890 - val_loss: 47.6703 - val_mae: 4.7914\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 54.0445 - mae: 5.6972 - val_loss: 44.0594 - val_mae: 4.5542\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 48.9837 - mae: 5.4278 - val_loss: 40.8498 - val_mae: 4.3402\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 44.4139 - mae: 5.1394 - val_loss: 38.2343 - val_mae: 4.1921\n",
      "Epoch 29/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 68us/sample - loss: 40.8655 - mae: 4.9217 - val_loss: 35.8802 - val_mae: 4.0100\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 37.8974 - mae: 4.7104 - val_loss: 33.8387 - val_mae: 3.8307\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 35.1288 - mae: 4.4987 - val_loss: 31.9489 - val_mae: 3.6958\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 32.8102 - mae: 4.3351 - val_loss: 30.1963 - val_mae: 3.6310\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 30.3910 - mae: 4.1802 - val_loss: 28.6955 - val_mae: 3.5421\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 28.4624 - mae: 4.0249 - val_loss: 27.3575 - val_mae: 3.4279\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 26.8710 - mae: 3.8858 - val_loss: 26.2669 - val_mae: 3.3967\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 25.4876 - mae: 3.7863 - val_loss: 25.2465 - val_mae: 3.3389\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 24.4673 - mae: 3.7134 - val_loss: 24.2355 - val_mae: 3.1756\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 23.3327 - mae: 3.5934 - val_loss: 23.4712 - val_mae: 3.1100\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 22.4004 - mae: 3.5037 - val_loss: 22.6961 - val_mae: 3.0575\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 21.6165 - mae: 3.4326 - val_loss: 22.0644 - val_mae: 3.0191\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 20.9478 - mae: 3.3763 - val_loss: 21.7939 - val_mae: 3.0680\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 20.3882 - mae: 3.3125 - val_loss: 20.8758 - val_mae: 3.0293\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 19.6695 - mae: 3.2660 - val_loss: 20.3465 - val_mae: 2.9412\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 19.3240 - mae: 3.2289 - val_loss: 20.1110 - val_mae: 2.9414\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 18.8788 - mae: 3.1339 - val_loss: 19.2611 - val_mae: 2.8665\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 18.1054 - mae: 3.0869 - val_loss: 18.8007 - val_mae: 2.8403\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 17.7039 - mae: 3.0292 - val_loss: 18.5633 - val_mae: 2.8944\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 17.3373 - mae: 3.0504 - val_loss: 17.9685 - val_mae: 2.8725\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 16.8340 - mae: 2.9703 - val_loss: 17.5332 - val_mae: 2.8533\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 16.5241 - mae: 2.9274 - val_loss: 17.0467 - val_mae: 2.7630\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 16.0152 - mae: 2.9003 - val_loss: 16.6001 - val_mae: 2.7122\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 15.6604 - mae: 2.8326 - val_loss: 16.2924 - val_mae: 2.7278\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 15.2758 - mae: 2.7945 - val_loss: 15.8500 - val_mae: 2.7036\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 15.0710 - mae: 2.7812 - val_loss: 15.6297 - val_mae: 2.6643\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 14.7074 - mae: 2.7127 - val_loss: 15.0457 - val_mae: 2.6812\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 14.3415 - mae: 2.7027 - val_loss: 14.6773 - val_mae: 2.6424\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 14.2214 - mae: 2.6687 - val_loss: 14.4872 - val_mae: 2.5760\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 13.9160 - mae: 2.6500 - val_loss: 14.0167 - val_mae: 2.5886\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 13.5274 - mae: 2.6134 - val_loss: 13.8058 - val_mae: 2.4873\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 0s 64us/sample - loss: 13.6746 - mae: 2.6029 - val_loss: 13.6288 - val_mae: 2.4650\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 13.0802 - mae: 2.5270 - val_loss: 13.5439 - val_mae: 2.5106\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 13.1015 - mae: 2.5816 - val_loss: 13.1966 - val_mae: 2.4914\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 12.9398 - mae: 2.5332 - val_loss: 12.8487 - val_mae: 2.4746\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 12.6670 - mae: 2.4964 - val_loss: 12.7001 - val_mae: 2.4920\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 12.5204 - mae: 2.5040 - val_loss: 12.3310 - val_mae: 2.4626\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 12.2738 - mae: 2.4761 - val_loss: 12.2394 - val_mae: 2.4326\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 12.2764 - mae: 2.4867 - val_loss: 12.1339 - val_mae: 2.3808\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 12.1691 - mae: 2.4356 - val_loss: 11.7700 - val_mae: 2.3306\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 11.8933 - mae: 2.4148 - val_loss: 11.4683 - val_mae: 2.3044\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 11.7206 - mae: 2.4095 - val_loss: 11.3842 - val_mae: 2.3776\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 11.8029 - mae: 2.4123 - val_loss: 11.2417 - val_mae: 2.3899\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.6337 - mae: 2.4007 - val_loss: 11.1731 - val_mae: 2.4145\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 0s 102us/sample - loss: 11.5839 - mae: 2.4246 - val_loss: 10.7464 - val_mae: 2.2605\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 11.6060 - mae: 2.4231 - val_loss: 10.5662 - val_mae: 2.2374\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 11.1884 - mae: 2.3733 - val_loss: 10.7250 - val_mae: 2.2281\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.1114 - mae: 2.3523 - val_loss: 10.4232 - val_mae: 2.2043\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.1462 - mae: 2.3497 - val_loss: 10.3040 - val_mae: 2.2231\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 0s 72us/sample - loss: 11.1710 - mae: 2.3531 - val_loss: 10.3038 - val_mae: 2.2570\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.8314 - mae: 2.3350 - val_loss: 10.1291 - val_mae: 2.1800\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 6.8522 - mae: 2.082 - 0s 61us/sample - loss: 10.8855 - mae: 2.3136 - val_loss: 10.2296 - val_mae: 2.2052\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.8499 - mae: 2.3497 - val_loss: 10.1303 - val_mae: 2.1564\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.9132 - mae: 2.3248 - val_loss: 10.4727 - val_mae: 2.2018\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.7403 - mae: 2.3170 - val_loss: 9.8253 - val_mae: 2.1364\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.6270 - mae: 2.3012 - val_loss: 10.0487 - val_mae: 2.1505\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.5286 - mae: 2.2798 - val_loss: 9.6144 - val_mae: 2.1832\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 10.4122 - mae: 2.3005 - val_loss: 9.4950 - val_mae: 2.1262\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.5923 - mae: 2.2772 - val_loss: 9.5889 - val_mae: 2.2085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 13.4909 - mae: 2.38 - 0s 62us/sample - loss: 10.3704 - mae: 2.2866 - val_loss: 9.4615 - val_mae: 2.1114\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.2817 - mae: 2.2638 - val_loss: 9.3466 - val_mae: 2.1283\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 10.2207 - mae: 2.2852 - val_loss: 9.1768 - val_mae: 2.1195\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.1156 - mae: 2.2551 - val_loss: 9.2362 - val_mae: 2.0757\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.2746 - mae: 2.2336 - val_loss: 9.2075 - val_mae: 2.1196\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 10.0943 - mae: 2.2389 - val_loss: 9.0575 - val_mae: 2.1000\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.0999 - mae: 2.2570 - val_loss: 9.2470 - val_mae: 2.1289\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.9898 - mae: 2.2124 - val_loss: 8.9775 - val_mae: 2.0750\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.9407 - mae: 2.2026 - val_loss: 9.1134 - val_mae: 2.1353\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.0265 - mae: 2.2258 - val_loss: 8.8307 - val_mae: 2.0384\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.9212 - mae: 2.2119 - val_loss: 8.8321 - val_mae: 2.0698\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.7883 - mae: 2.1948 - val_loss: 8.8448 - val_mae: 2.0059\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.7177 - mae: 2.1720 - val_loss: 8.8410 - val_mae: 2.1312\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.6804 - mae: 2.1899 - val_loss: 8.6968 - val_mae: 2.0775\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 9.5638 - mae: 2.1760 - val_loss: 8.7209 - val_mae: 2.0451\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 9.5436 - mae: 2.1650 - val_loss: 8.6294 - val_mae: 2.0420\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.4624 - mae: 2.1424 - val_loss: 8.7625 - val_mae: 2.1148\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.5241 - mae: 2.2001 - val_loss: 8.6993 - val_mae: 2.0257\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.6743 - mae: 2.1904 - val_loss: 8.5869 - val_mae: 1.9646\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.4984 - mae: 2.1664 - val_loss: 8.3325 - val_mae: 1.9920\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.3540 - mae: 2.1342 - val_loss: 8.4900 - val_mae: 2.1017\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.3226 - mae: 2.1548 - val_loss: 8.2841 - val_mae: 1.9923\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.4213 - mae: 2.1548 - val_loss: 8.3764 - val_mae: 2.0569\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 9.3445 - mae: 2.1667 - val_loss: 8.2151 - val_mae: 2.0370\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 9.2079 - mae: 2.1098 - val_loss: 8.2740 - val_mae: 2.0747\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.2145 - mae: 2.1528 - val_loss: 8.1165 - val_mae: 1.9793\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.2858 - mae: 2.1357 - val_loss: 7.9993 - val_mae: 1.9678\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.0593 - mae: 2.1068 - val_loss: 8.3263 - val_mae: 2.0302\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.0400 - mae: 2.1242 - val_loss: 8.0388 - val_mae: 1.9244\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.0244 - mae: 2.1133 - val_loss: 8.3022 - val_mae: 1.9825\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.3802 - mae: 2.1589 - val_loss: 7.9600 - val_mae: 1.9656\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.1497 - mae: 2.1505 - val_loss: 7.8466 - val_mae: 1.9326\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.9386 - mae: 2.0905 - val_loss: 7.9482 - val_mae: 1.9235\n",
      "processing fold # 1\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 0s 2ms/sample - loss: 557.0711 - mae: 21.8422 - val_loss: 638.4682 - val_mae: 23.1099\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 531.3839 - mae: 21.2698 - val_loss: 613.8944 - val_mae: 22.6086\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 511.2795 - mae: 20.8005 - val_loss: 591.5387 - val_mae: 22.1354\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 492.1835 - mae: 20.3568 - val_loss: 568.0865 - val_mae: 21.6363\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 472.3651 - mae: 19.8790 - val_loss: 543.7592 - val_mae: 21.1130\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 451.8880 - mae: 19.3797 - val_loss: 518.5558 - val_mae: 20.5772\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 430.9383 - mae: 18.8488 - val_loss: 493.2914 - val_mae: 20.0225\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 0s 77us/sample - loss: 409.4381 - mae: 18.3045 - val_loss: 465.8729 - val_mae: 19.4109\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 0s 77us/sample - loss: 386.9051 - mae: 17.7188 - val_loss: 437.6413 - val_mae: 18.7647\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 363.7805 - mae: 17.1033 - val_loss: 408.8936 - val_mae: 18.0917\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 340.5692 - mae: 16.4735 - val_loss: 380.1701 - val_mae: 17.4058\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 317.2627 - mae: 15.8138 - val_loss: 351.1681 - val_mae: 16.6877\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 0s 52us/sample - loss: 294.0974 - mae: 15.1301 - val_loss: 322.3629 - val_mae: 15.9339\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 271.0600 - mae: 14.4308 - val_loss: 293.2231 - val_mae: 15.1341\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 247.8396 - mae: 13.6784 - val_loss: 264.4461 - val_mae: 14.3066\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 225.5985 - mae: 12.9191 - val_loss: 237.8639 - val_mae: 13.4893\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 0s 99us/sample - loss: 204.6308 - mae: 12.1734 - val_loss: 211.8289 - val_mae: 12.6470\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 184.4016 - mae: 11.4031 - val_loss: 187.5704 - val_mae: 11.7954\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 165.6175 - mae: 10.6232 - val_loss: 165.4691 - val_mae: 10.9608\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 148.2885 - mae: 9.8976 - val_loss: 144.4689 - val_mae: 10.1489\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 132.0544 - mae: 9.1975 - val_loss: 125.5737 - val_mae: 9.3910\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 117.2691 - mae: 8.5594 - val_loss: 108.8010 - val_mae: 8.6752\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 104.3357 - mae: 7.9796 - val_loss: 94.0998 - val_mae: 7.9764\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 92.9710 - mae: 7.4559 - val_loss: 81.9871 - val_mae: 7.4034\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 83.1077 - mae: 6.9870 - val_loss: 71.1088 - val_mae: 6.8662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 74.4489 - mae: 6.5592 - val_loss: 62.7624 - val_mae: 6.4254\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 67.1674 - mae: 6.1771 - val_loss: 54.5033 - val_mae: 5.9543\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 60.4228 - mae: 5.8032 - val_loss: 48.2254 - val_mae: 5.5907\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 54.8766 - mae: 5.4855 - val_loss: 42.7459 - val_mae: 5.2428\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 50.4910 - mae: 4.95 - 0s 58us/sample - loss: 50.0548 - mae: 5.1834 - val_loss: 38.7927 - val_mae: 4.9808\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 46.3875 - mae: 4.9496 - val_loss: 35.2819 - val_mae: 4.7284\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 42.6415 - mae: 4.7394 - val_loss: 32.5736 - val_mae: 4.5273\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 39.6714 - mae: 4.5324 - val_loss: 30.3067 - val_mae: 4.3468\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 37.1031 - mae: 4.3693 - val_loss: 28.1316 - val_mae: 4.1788\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 34.7097 - mae: 4.1836 - val_loss: 26.2854 - val_mae: 4.0243\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 33.0886 - mae: 3.91 - 0s 61us/sample - loss: 32.7488 - mae: 4.0493 - val_loss: 25.2421 - val_mae: 3.9545\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 30.8136 - mae: 3.9206 - val_loss: 24.1531 - val_mae: 3.8635\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 29.1225 - mae: 3.7850 - val_loss: 23.6184 - val_mae: 3.8174\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 26.6901 - mae: 3.49 - 0s 71us/sample - loss: 27.7136 - mae: 3.6833 - val_loss: 22.9009 - val_mae: 3.7456\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 0s 66us/sample - loss: 26.5935 - mae: 3.5898 - val_loss: 22.2936 - val_mae: 3.6875\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 25.5418 - mae: 3.5089 - val_loss: 22.0890 - val_mae: 3.6561\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 24.3969 - mae: 3.4563 - val_loss: 21.6657 - val_mae: 3.6112\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 23.5392 - mae: 3.3732 - val_loss: 21.2904 - val_mae: 3.5800\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 22.7995 - mae: 3.3177 - val_loss: 21.1572 - val_mae: 3.5486\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 22.1929 - mae: 3.2920 - val_loss: 21.2237 - val_mae: 3.4995\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 21.5879 - mae: 3.1926 - val_loss: 20.7730 - val_mae: 3.4864\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 21.1564 - mae: 3.1818 - val_loss: 20.1535 - val_mae: 3.4709\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 20.6022 - mae: 3.1181 - val_loss: 19.8158 - val_mae: 3.4710\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 0s 67us/sample - loss: 20.4632 - mae: 3.0894 - val_loss: 19.5625 - val_mae: 3.4323\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 19.5798 - mae: 3.0474 - val_loss: 19.3962 - val_mae: 3.3867\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 19.1183 - mae: 3.0175 - val_loss: 19.3596 - val_mae: 3.4400\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 18.7640 - mae: 3.0034 - val_loss: 19.2603 - val_mae: 3.4230\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 18.3339 - mae: 2.9835 - val_loss: 19.3803 - val_mae: 3.3692\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 17.8707 - mae: 2.9365 - val_loss: 19.1390 - val_mae: 3.3422\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 17.4285 - mae: 2.8693 - val_loss: 18.9599 - val_mae: 3.3231\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 17.0328 - mae: 2.8740 - val_loss: 18.8222 - val_mae: 3.3101\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 16.7641 - mae: 2.8185 - val_loss: 17.9706 - val_mae: 3.2944\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 16.3234 - mae: 2.7920 - val_loss: 18.3516 - val_mae: 3.2650\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 16.1876 - mae: 2.7620 - val_loss: 17.2756 - val_mae: 3.2439\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 15.8420 - mae: 2.7240 - val_loss: 17.2587 - val_mae: 3.2519\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 15.6092 - mae: 2.7282 - val_loss: 17.3627 - val_mae: 3.2667\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 15.2775 - mae: 2.7281 - val_loss: 16.9636 - val_mae: 3.2298\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 14.9051 - mae: 2.6716 - val_loss: 16.7462 - val_mae: 3.2137\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 14.8304 - mae: 2.6285 - val_loss: 16.7813 - val_mae: 3.2118\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 14.2963 - mae: 2.6185 - val_loss: 16.9792 - val_mae: 3.1857\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 14.0674 - mae: 2.5749 - val_loss: 16.9968 - val_mae: 3.1718\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 14.0092 - mae: 2.5333 - val_loss: 16.7411 - val_mae: 3.1949\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 13.6390 - mae: 2.5837 - val_loss: 16.2168 - val_mae: 3.1185\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 13.4630 - mae: 2.5221 - val_loss: 15.9319 - val_mae: 3.0987\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 13.2234 - mae: 2.5062 - val_loss: 15.6064 - val_mae: 3.1231\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 13.2327 - mae: 2.5101 - val_loss: 15.6795 - val_mae: 3.1154\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 12.8144 - mae: 2.4913 - val_loss: 15.4256 - val_mae: 3.0852\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 0s 63us/sample - loss: 12.6710 - mae: 2.4540 - val_loss: 15.4048 - val_mae: 3.0860\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 12.4135 - mae: 2.4473 - val_loss: 15.3838 - val_mae: 3.0635\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 12.2837 - mae: 2.4242 - val_loss: 15.2676 - val_mae: 3.0569\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 12.3155 - mae: 2.4090 - val_loss: 15.2114 - val_mae: 3.0515\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 12.0579 - mae: 2.3997 - val_loss: 15.6744 - val_mae: 3.0657\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 11.7336 - mae: 2.3638 - val_loss: 15.0496 - val_mae: 3.0592\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 10.7796 - mae: 2.27 - 0s 62us/sample - loss: 11.5687 - mae: 2.3693 - val_loss: 15.1071 - val_mae: 3.0376\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.4751 - mae: 2.3300 - val_loss: 15.3011 - val_mae: 3.0399\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.6058 - mae: 2.3719 - val_loss: 14.5852 - val_mae: 3.0074\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 11.3361 - mae: 2.3402 - val_loss: 14.9278 - val_mae: 3.0087\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 11.1130 - mae: 2.2988 - val_loss: 15.3188 - val_mae: 3.0268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 10.9143 - mae: 2.2855 - val_loss: 14.5655 - val_mae: 2.9880\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.8708 - mae: 2.2833 - val_loss: 14.6995 - val_mae: 2.9848\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.6839 - mae: 2.2667 - val_loss: 14.7811 - val_mae: 2.9912\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 10.5590 - mae: 2.2630 - val_loss: 15.5708 - val_mae: 3.0542\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.6133 - mae: 2.2610 - val_loss: 15.5044 - val_mae: 3.0429\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.4286 - mae: 2.2474 - val_loss: 15.2888 - val_mae: 3.0346\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 10.3807 - mae: 2.2779 - val_loss: 14.4259 - val_mae: 2.9797\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.3331 - mae: 2.1849 - val_loss: 14.5293 - val_mae: 2.9738\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.1263 - mae: 2.1901 - val_loss: 15.1347 - val_mae: 3.0094\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 10.1048 - mae: 2.2373 - val_loss: 14.9238 - val_mae: 2.9806\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.9505 - mae: 2.1945 - val_loss: 15.4248 - val_mae: 3.0392\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.9564 - mae: 2.2171 - val_loss: 14.3484 - val_mae: 2.9424\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.7615 - mae: 2.1622 - val_loss: 14.6251 - val_mae: 2.9588\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 9.6956 - mae: 2.1785 - val_loss: 14.8723 - val_mae: 2.9916\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 9.6108 - mae: 2.1664 - val_loss: 14.4167 - val_mae: 2.9492\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.6536 - mae: 2.1473 - val_loss: 15.2862 - val_mae: 3.0263\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.4858 - mae: 2.1836 - val_loss: 14.9862 - val_mae: 3.0093\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 9.4167 - mae: 2.1381 - val_loss: 14.5066 - val_mae: 2.9727\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 9.5063 - mae: 2.1548 - val_loss: 14.5220 - val_mae: 2.9564\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.3356 - mae: 2.1394 - val_loss: 14.1164 - val_mae: 2.9165\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.1764 - mae: 2.1069 - val_loss: 14.5268 - val_mae: 2.9585\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 9.1845 - mae: 2.1284 - val_loss: 14.5362 - val_mae: 2.9431\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.1554 - mae: 2.1376 - val_loss: 14.1335 - val_mae: 2.9118\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.0166 - mae: 2.0841 - val_loss: 15.0417 - val_mae: 3.0040\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 9.0091 - mae: 2.1243 - val_loss: 15.7802 - val_mae: 3.0967\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.3088 - mae: 2.1365 - val_loss: 15.5747 - val_mae: 3.0549\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.0808 - mae: 2.1520 - val_loss: 15.4933 - val_mae: 3.0475\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 8.8401 - mae: 2.1080 - val_loss: 15.2698 - val_mae: 3.0368\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 8.9938 - mae: 2.1242 - val_loss: 14.4532 - val_mae: 2.9606\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.8240 - mae: 2.0754 - val_loss: 14.4652 - val_mae: 2.9602\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.7169 - mae: 2.0565 - val_loss: 15.0360 - val_mae: 3.0028\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 8.8446 - mae: 2.0767 - val_loss: 14.7271 - val_mae: 2.9599\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 8.7494 - mae: 2.1120 - val_loss: 14.4487 - val_mae: 2.9279\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 8.5338 - mae: 2.0416 - val_loss: 15.2119 - val_mae: 3.0198\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 8.5209 - mae: 2.0609 - val_loss: 14.4277 - val_mae: 2.9469\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.5573 - mae: 2.0557 - val_loss: 14.6917 - val_mae: 2.9500\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 0s 66us/sample - loss: 8.4620 - mae: 2.0674 - val_loss: 14.5885 - val_mae: 2.9578\n",
      "processing fold # 2\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 558.2799 - mae: 21.5487 - val_loss: 478.1175 - val_mae: 20.6138\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 526.5878 - mae: 20.7604 - val_loss: 454.6915 - val_mae: 20.0129\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 0s 69us/sample - loss: 501.1121 - mae: 20.1191 - val_loss: 431.7960 - val_mae: 19.4177\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 476.1341 - mae: 19.4773 - val_loss: 409.3047 - val_mae: 18.8202\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 451.1066 - mae: 18.8352 - val_loss: 386.3174 - val_mae: 18.1962\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 425.7254 - mae: 18.1912 - val_loss: 363.5168 - val_mae: 17.5520\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 400.3590 - mae: 17.5426 - val_loss: 339.5203 - val_mae: 16.8597\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 373.6430 - mae: 16.8402 - val_loss: 315.0351 - val_mae: 16.1697\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 346.6171 - mae: 16.1224 - val_loss: 290.7853 - val_mae: 15.4545\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 319.6485 - mae: 15.3945 - val_loss: 266.3336 - val_mae: 14.6981\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 292.8027 - mae: 14.6278 - val_loss: 242.8276 - val_mae: 13.9273\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 267.0114 - mae: 13.8486 - val_loss: 220.3488 - val_mae: 13.1383\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 242.2680 - mae: 13.0860 - val_loss: 198.4090 - val_mae: 12.3220\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 217.9888 - mae: 12.2845 - val_loss: 176.7491 - val_mae: 11.5006\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 194.7479 - mae: 11.4470 - val_loss: 157.7477 - val_mae: 10.7468\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 174.0704 - mae: 10.6805 - val_loss: 140.2758 - val_mae: 10.0001\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 155.5351 - mae: 9.9510 - val_loss: 125.3347 - val_mae: 9.3428\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 139.0775 - mae: 9.2918 - val_loss: 110.6902 - val_mae: 8.6774\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 123.5880 - mae: 8.6190 - val_loss: 98.1276 - val_mae: 8.1129\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 110.4981 - mae: 8.0561 - val_loss: 87.6310 - val_mae: 7.6366\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 0s 64us/sample - loss: 99.1789 - mae: 7.5910 - val_loss: 77.6738 - val_mae: 7.1616\n",
      "Epoch 22/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 62us/sample - loss: 89.0799 - mae: 7.1685 - val_loss: 69.8938 - val_mae: 6.7740\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 81.0416 - mae: 6.7989 - val_loss: 62.9887 - val_mae: 6.4294\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 73.7206 - mae: 6.4772 - val_loss: 56.2687 - val_mae: 6.0803\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 66.9346 - mae: 6.1472 - val_loss: 50.8900 - val_mae: 5.7688\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 61.2960 - mae: 5.8887 - val_loss: 46.1890 - val_mae: 5.4865\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 56.5501 - mae: 5.6238 - val_loss: 41.8391 - val_mae: 5.2506\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 52.0818 - mae: 5.4065 - val_loss: 37.9763 - val_mae: 5.0236\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 48.1318 - mae: 5.1784 - val_loss: 34.7489 - val_mae: 4.8191\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 44.5040 - mae: 4.9668 - val_loss: 31.7601 - val_mae: 4.6154\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 41.2682 - mae: 4.7522 - val_loss: 29.1027 - val_mae: 4.4208\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 38.3140 - mae: 4.5715 - val_loss: 26.5496 - val_mae: 4.2312\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 35.5927 - mae: 4.3829 - val_loss: 24.3635 - val_mae: 4.0749\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 33.3887 - mae: 4.2440 - val_loss: 22.5537 - val_mae: 3.9263\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 31.3630 - mae: 4.0951 - val_loss: 20.9994 - val_mae: 3.7732\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 29.6903 - mae: 3.9703 - val_loss: 19.6446 - val_mae: 3.6346\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 28.3027 - mae: 3.8279 - val_loss: 18.5075 - val_mae: 3.5054\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 26.9982 - mae: 3.7124 - val_loss: 17.4291 - val_mae: 3.3799\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 25.6906 - mae: 3.5936 - val_loss: 16.6841 - val_mae: 3.2892\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 24.8357 - mae: 3.5217 - val_loss: 15.9016 - val_mae: 3.1994\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 23.8049 - mae: 3.3941 - val_loss: 15.2089 - val_mae: 3.0937\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 22.9514 - mae: 3.3455 - val_loss: 14.5958 - val_mae: 2.9971\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 22.3057 - mae: 3.3099 - val_loss: 13.9461 - val_mae: 2.9104\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 21.6085 - mae: 3.2484 - val_loss: 13.4548 - val_mae: 2.8578\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 0s 63us/sample - loss: 21.2320 - mae: 3.1748 - val_loss: 13.3393 - val_mae: 2.8164\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 20.2746 - mae: 3.1538 - val_loss: 12.7574 - val_mae: 2.7483\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 19.7408 - mae: 3.0774 - val_loss: 12.3175 - val_mae: 2.7076\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 19.2017 - mae: 2.9934 - val_loss: 12.4658 - val_mae: 2.6970\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 18.8136 - mae: 3.0245 - val_loss: 11.7145 - val_mae: 2.6435\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 18.5201 - mae: 2.9650 - val_loss: 11.3442 - val_mae: 2.5920\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 17.9180 - mae: 2.8705 - val_loss: 11.4598 - val_mae: 2.5826\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 17.4165 - mae: 2.8947 - val_loss: 10.9288 - val_mae: 2.5343\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 17.0269 - mae: 2.8201 - val_loss: 10.7837 - val_mae: 2.5037\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 16.8331 - mae: 2.8103 - val_loss: 10.5880 - val_mae: 2.5010\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 16.1866 - mae: 2.7430 - val_loss: 10.6392 - val_mae: 2.4929\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 15.9213 - mae: 2.7255 - val_loss: 10.2621 - val_mae: 2.4440\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 15.6819 - mae: 2.7063 - val_loss: 10.0735 - val_mae: 2.4551\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 15.3565 - mae: 2.6836 - val_loss: 9.7315 - val_mae: 2.3865\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 15.0168 - mae: 2.6645 - val_loss: 9.6596 - val_mae: 2.3911\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 14.8488 - mae: 2.6342 - val_loss: 9.5646 - val_mae: 2.3904\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 14.6657 - mae: 2.6558 - val_loss: 9.4994 - val_mae: 2.3854\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 14.1086 - mae: 2.5918 - val_loss: 9.8302 - val_mae: 2.4458\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 13.9694 - mae: 2.5826 - val_loss: 9.9866 - val_mae: 2.4821\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 0s 60us/sample - loss: 13.8974 - mae: 2.5846 - val_loss: 9.6029 - val_mae: 2.4313\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 13.3171 - mae: 2.5318 - val_loss: 9.3135 - val_mae: 2.4098\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 13.2698 - mae: 2.5388 - val_loss: 9.5297 - val_mae: 2.4389\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 13.1901 - mae: 2.5462 - val_loss: 9.0513 - val_mae: 2.3823\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 13.2100 - mae: 2.5486 - val_loss: 9.3082 - val_mae: 2.4154\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 12.9412 - mae: 2.4851 - val_loss: 8.9156 - val_mae: 2.3683\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 12.5375 - mae: 2.4617 - val_loss: 9.2213 - val_mae: 2.4056\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 12.3409 - mae: 2.4565 - val_loss: 8.7090 - val_mae: 2.3372\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 12.1664 - mae: 2.4057 - val_loss: 9.2656 - val_mae: 2.4080\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 0s 63us/sample - loss: 12.2224 - mae: 2.4401 - val_loss: 9.2725 - val_mae: 2.4176\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 11.9469 - mae: 2.4018 - val_loss: 9.0890 - val_mae: 2.3982\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 11.7301 - mae: 2.3816 - val_loss: 9.6038 - val_mae: 2.4551\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 11.6043 - mae: 2.3947 - val_loss: 8.9953 - val_mae: 2.3829\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 11.4652 - mae: 2.3611 - val_loss: 9.1572 - val_mae: 2.3986\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 11.4812 - mae: 2.3647 - val_loss: 9.2223 - val_mae: 2.4131\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.2795 - mae: 2.3515 - val_loss: 9.6689 - val_mae: 2.4663\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 11.2636 - mae: 2.3634 - val_loss: 9.5324 - val_mae: 2.4512\n",
      "Epoch 81/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 62us/sample - loss: 11.0757 - mae: 2.3378 - val_loss: 8.7885 - val_mae: 2.3753\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 13.3741 - mae: 2.36 - 0s 61us/sample - loss: 10.8743 - mae: 2.3054 - val_loss: 8.4099 - val_mae: 2.3100\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.9562 - mae: 2.3047 - val_loss: 8.5183 - val_mae: 2.3283\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.6378 - mae: 2.2802 - val_loss: 8.5989 - val_mae: 2.3297\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 11.0896 - mae: 2.3364 - val_loss: 10.0205 - val_mae: 2.5148\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.6193 - mae: 2.2958 - val_loss: 9.0646 - val_mae: 2.4014\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.3607 - mae: 2.2476 - val_loss: 8.7040 - val_mae: 2.3515\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.3062 - mae: 2.2480 - val_loss: 8.9708 - val_mae: 2.3909\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.2732 - mae: 2.2444 - val_loss: 9.0503 - val_mae: 2.3922\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.2272 - mae: 2.2302 - val_loss: 9.0440 - val_mae: 2.3959\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.0390 - mae: 2.2155 - val_loss: 8.7737 - val_mae: 2.3558\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.2016 - mae: 2.2248 - val_loss: 8.8924 - val_mae: 2.3766\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.1890 - mae: 2.2087 - val_loss: 9.2761 - val_mae: 2.4295\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 9.8876 - mae: 2.2290 - val_loss: 8.6015 - val_mae: 2.3306\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.0486 - mae: 2.2287 - val_loss: 8.6675 - val_mae: 2.3425\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 9.6677 - mae: 2.1658 - val_loss: 8.6071 - val_mae: 2.3320\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 10.0174 - mae: 2.2102 - val_loss: 9.6651 - val_mae: 2.4797\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 9.6003 - mae: 2.1973 - val_loss: 8.4897 - val_mae: 2.3095\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.5624 - mae: 2.1660 - val_loss: 9.0734 - val_mae: 2.4022\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 11.5138 - mae: 2.28 - 0s 62us/sample - loss: 9.4514 - mae: 2.1680 - val_loss: 8.5637 - val_mae: 2.3265\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 9.4600 - mae: 2.1645 - val_loss: 8.8372 - val_mae: 2.3703\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 9.4034 - mae: 2.1565 - val_loss: 8.4692 - val_mae: 2.3036\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 9.2312 - mae: 2.1368 - val_loss: 8.3144 - val_mae: 2.2800\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.2379 - mae: 2.1255 - val_loss: 8.2581 - val_mae: 2.2873\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 9.5912 - mae: 2.1761 - val_loss: 8.4030 - val_mae: 2.3061\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.1633 - mae: 2.1263 - val_loss: 8.0410 - val_mae: 2.2449\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 8.0223 - mae: 2.044 - 0s 62us/sample - loss: 9.0306 - mae: 2.0971 - val_loss: 9.5303 - val_mae: 2.4577\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.1480 - mae: 2.1516 - val_loss: 8.4984 - val_mae: 2.3082\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.9200 - mae: 2.0957 - val_loss: 7.9773 - val_mae: 2.2404\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.0061 - mae: 2.1070 - val_loss: 8.7173 - val_mae: 2.3541\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.8339 - mae: 2.0827 - val_loss: 8.2481 - val_mae: 2.2687\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.7285 - mae: 2.0674 - val_loss: 8.2434 - val_mae: 2.2612\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.1232 - mae: 2.0994 - val_loss: 8.1944 - val_mae: 2.2619\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.0123 - mae: 2.0839 - val_loss: 9.0460 - val_mae: 2.3884\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.8606 - mae: 2.0676 - val_loss: 9.0778 - val_mae: 2.3929\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.7355 - mae: 2.0798 - val_loss: 8.8217 - val_mae: 2.3619\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 8.6742 - mae: 2.0776 - val_loss: 8.1916 - val_mae: 2.2533\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 8.4859 - mae: 2.0240 - val_loss: 8.5743 - val_mae: 2.3151\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 8.4449 - mae: 2.0313 - val_loss: 8.5298 - val_mae: 2.3185\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 8.3668 - mae: 2.0280 - val_loss: 8.7030 - val_mae: 2.3336\n",
      "processing fold # 3\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 568.2121 - mae: 22.0614 - val_loss: 548.3282 - val_mae: 21.2780\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 544.2414 - mae: 21.5006 - val_loss: 529.3053 - val_mae: 20.8068\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 525.7327 - mae: 21.0667 - val_loss: 510.4732 - val_mae: 20.3324\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 507.3114 - mae: 20.6195 - val_loss: 490.9178 - val_mae: 19.8349\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 488.1584 - mae: 20.1472 - val_loss: 470.6356 - val_mae: 19.3020\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 468.1933 - mae: 19.6416 - val_loss: 449.7996 - val_mae: 18.7524\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 447.6901 - mae: 19.1191 - val_loss: 428.6481 - val_mae: 18.1875\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 426.8347 - mae: 18.5664 - val_loss: 407.7018 - val_mae: 17.6069\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 405.5782 - mae: 18.0047 - val_loss: 385.2365 - val_mae: 16.9870\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 383.1861 - mae: 17.3903 - val_loss: 362.5821 - val_mae: 16.3557\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 360.4972 - mae: 16.7599 - val_loss: 340.1382 - val_mae: 15.7388\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 337.7593 - mae: 16.1248 - val_loss: 317.5911 - val_mae: 15.1298\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 314.4748 - mae: 15.4476 - val_loss: 294.8309 - val_mae: 14.5027\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 291.5049 - mae: 14.7600 - val_loss: 273.3039 - val_mae: 13.8734\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 269.2949 - mae: 14.0765 - val_loss: 252.6020 - val_mae: 13.2689\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 247.7678 - mae: 13.3753 - val_loss: 232.2416 - val_mae: 12.6415\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 226.8172 - mae: 12.6786 - val_loss: 213.3643 - val_mae: 12.0106\n",
      "Epoch 18/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 61us/sample - loss: 206.9588 - mae: 11.9889 - val_loss: 195.3022 - val_mae: 11.3670\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 187.9227 - mae: 11.2899 - val_loss: 178.2485 - val_mae: 10.7339\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 169.6410 - mae: 10.6249 - val_loss: 161.9722 - val_mae: 10.1291\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 152.5499 - mae: 9.9555 - val_loss: 148.0432 - val_mae: 9.5951\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 137.3005 - mae: 9.3780 - val_loss: 134.8849 - val_mae: 9.1048\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 123.3163 - mae: 8.7883 - val_loss: 123.5403 - val_mae: 8.7181\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 110.9054 - mae: 8.2888 - val_loss: 113.2139 - val_mae: 8.3648\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 99.6597 - mae: 7.7914 - val_loss: 104.3025 - val_mae: 8.0412\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 89.8831 - mae: 7.3803 - val_loss: 96.5209 - val_mae: 7.7619\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 81.2856 - mae: 6.9795 - val_loss: 89.6639 - val_mae: 7.4962\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 74.0415 - mae: 6.6235 - val_loss: 83.7149 - val_mae: 7.2442\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 67.6820 - mae: 6.3327 - val_loss: 78.0520 - val_mae: 7.0063\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 61.8357 - mae: 6.0467 - val_loss: 72.7125 - val_mae: 6.7542\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 56.6041 - mae: 5.7629 - val_loss: 68.2025 - val_mae: 6.5214\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 51.9720 - mae: 5.5208 - val_loss: 63.8653 - val_mae: 6.2702\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 48.1887 - mae: 5.3188 - val_loss: 59.8550 - val_mae: 6.0363\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 44.5956 - mae: 5.0849 - val_loss: 56.4791 - val_mae: 5.8300\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 41.3999 - mae: 4.8935 - val_loss: 53.0032 - val_mae: 5.6117\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 38.4237 - mae: 4.6696 - val_loss: 50.1844 - val_mae: 5.4362\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 35.7390 - mae: 4.5113 - val_loss: 47.2356 - val_mae: 5.2327\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 33.3299 - mae: 4.3214 - val_loss: 44.8563 - val_mae: 5.0481\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 31.0421 - mae: 4.1858 - val_loss: 42.4632 - val_mae: 4.8516\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 0s 81us/sample - loss: 29.1379 - mae: 4.0329 - val_loss: 40.2165 - val_mae: 4.6640\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 0s 83us/sample - loss: 27.4033 - mae: 3.9232 - val_loss: 38.2774 - val_mae: 4.4827\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 0s 83us/sample - loss: 25.9296 - mae: 3.7979 - val_loss: 36.6441 - val_mae: 4.3312\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 0s 77us/sample - loss: 24.7322 - mae: 3.7320 - val_loss: 34.8880 - val_mae: 4.1707\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 23.2208 - mae: 3.5882 - val_loss: 33.4898 - val_mae: 4.0618\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 0s 77us/sample - loss: 22.2226 - mae: 3.5201 - val_loss: 32.3345 - val_mae: 3.9636\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 21.3628 - mae: 3.4339 - val_loss: 31.3321 - val_mae: 3.9025\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 20.4507 - mae: 3.3802 - val_loss: 30.5401 - val_mae: 3.8537\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 0s 76us/sample - loss: 19.8358 - mae: 3.3274 - val_loss: 29.5865 - val_mae: 3.7641\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 19.3566 - mae: 3.2915 - val_loss: 28.5511 - val_mae: 3.6502\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 18.3588 - mae: 3.1853 - val_loss: 27.6761 - val_mae: 3.5740\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 17.8794 - mae: 3.1283 - val_loss: 27.1285 - val_mae: 3.5298\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 17.3544 - mae: 3.0794 - val_loss: 26.5557 - val_mae: 3.4753\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 16.8683 - mae: 3.0438 - val_loss: 25.9180 - val_mae: 3.3992\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 16.2423 - mae: 2.9821 - val_loss: 25.1555 - val_mae: 3.3270\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 15.7408 - mae: 2.9398 - val_loss: 24.5985 - val_mae: 3.2571\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 15.5726 - mae: 2.9021 - val_loss: 24.3636 - val_mae: 3.2419\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 14.8665 - mae: 2.8460 - val_loss: 23.9016 - val_mae: 3.1953\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 14.5822 - mae: 2.8148 - val_loss: 23.5210 - val_mae: 3.1619\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 14.2580 - mae: 2.7758 - val_loss: 23.1587 - val_mae: 3.1227\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 13.8030 - mae: 2.7296 - val_loss: 22.8502 - val_mae: 3.0638\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 13.3737 - mae: 2.6712 - val_loss: 22.3999 - val_mae: 3.0435\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 13.1981 - mae: 2.6502 - val_loss: 22.0621 - val_mae: 3.0578\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 12.7227 - mae: 2.6293 - val_loss: 21.7970 - val_mae: 3.0002\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 12.4971 - mae: 2.5717 - val_loss: 21.6652 - val_mae: 2.9562\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 12.1629 - mae: 2.5281 - val_loss: 21.3439 - val_mae: 2.9849\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.9806 - mae: 2.5355 - val_loss: 20.9023 - val_mae: 2.9123\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 11.5723 - mae: 2.5056 - val_loss: 20.7417 - val_mae: 2.8661\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 11.2929 - mae: 2.4460 - val_loss: 20.4510 - val_mae: 2.8499\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.0541 - mae: 2.4340 - val_loss: 20.2920 - val_mae: 2.8411\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 10.8911 - mae: 2.4211 - val_loss: 20.1460 - val_mae: 2.8337\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.6312 - mae: 2.3834 - val_loss: 19.4712 - val_mae: 2.8102\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.5460 - mae: 2.3808 - val_loss: 19.5418 - val_mae: 2.7975\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 10.2979 - mae: 2.3449 - val_loss: 19.3882 - val_mae: 2.7973\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.2478 - mae: 2.3529 - val_loss: 19.4412 - val_mae: 2.8143\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.1137 - mae: 2.3523 - val_loss: 19.1933 - val_mae: 2.8052\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.8051 - mae: 2.3080 - val_loss: 19.4963 - val_mae: 2.7798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.6101 - mae: 2.2746 - val_loss: 18.8435 - val_mae: 2.7723\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.4848 - mae: 2.2621 - val_loss: 18.8529 - val_mae: 2.7663\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.4158 - mae: 2.2389 - val_loss: 18.6266 - val_mae: 2.7615\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 12.2205 - mae: 2.37 - 0s 65us/sample - loss: 9.3660 - mae: 2.2465 - val_loss: 18.6327 - val_mae: 2.7584\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.1137 - mae: 2.2089 - val_loss: 18.1934 - val_mae: 2.7625\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 9.1501 - mae: 2.2432 - val_loss: 18.6523 - val_mae: 2.7338\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.8809 - mae: 2.1899 - val_loss: 18.0729 - val_mae: 2.7322\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.8783 - mae: 2.1982 - val_loss: 18.4399 - val_mae: 2.7825\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 9.1694 - mae: 2.2285 - val_loss: 18.2080 - val_mae: 2.7483\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.7485 - mae: 2.1559 - val_loss: 17.9016 - val_mae: 2.7261\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 8.6234 - mae: 2.1441 - val_loss: 17.9032 - val_mae: 2.7135\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.4789 - mae: 2.1562 - val_loss: 17.9634 - val_mae: 2.7104\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.6820 - mae: 2.1638 - val_loss: 17.5492 - val_mae: 2.7062\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 8.4656 - mae: 2.1490 - val_loss: 17.9464 - val_mae: 2.7374\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.4138 - mae: 2.1416 - val_loss: 17.5968 - val_mae: 2.7253\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 8.3078 - mae: 2.1381 - val_loss: 17.4454 - val_mae: 2.6772\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 8.2309 - mae: 2.1280 - val_loss: 17.3063 - val_mae: 2.6754\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 8.0870 - mae: 2.0944 - val_loss: 17.6164 - val_mae: 2.6735\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 8.0246 - mae: 2.0864 - val_loss: 17.0539 - val_mae: 2.6575\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.1652 - mae: 2.1095 - val_loss: 17.1558 - val_mae: 2.6528\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 7.9782 - mae: 2.0671 - val_loss: 16.5948 - val_mae: 2.6446\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 7.7618 - mae: 2.0615 - val_loss: 17.3785 - val_mae: 2.6526\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 7.8551 - mae: 2.0651 - val_loss: 16.2921 - val_mae: 2.6458\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 7.7903 - mae: 2.0813 - val_loss: 17.0975 - val_mae: 2.6704\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 7.6820 - mae: 2.0540 - val_loss: 16.8066 - val_mae: 2.6308\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 7.5947 - mae: 2.0273 - val_loss: 16.2714 - val_mae: 2.6105\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 7.5492 - mae: 2.0261 - val_loss: 16.6206 - val_mae: 2.5977\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 7.5365 - mae: 2.0307 - val_loss: 17.0821 - val_mae: 2.6064\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 7.4548 - mae: 2.0148 - val_loss: 16.2280 - val_mae: 2.5998\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 7.4257 - mae: 2.0329 - val_loss: 17.2612 - val_mae: 2.6915\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 6.6826 - mae: 1.813 - 0s 65us/sample - loss: 7.3828 - mae: 1.9740 - val_loss: 16.5392 - val_mae: 2.5769\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 7.2402 - mae: 1.9814 - val_loss: 16.4292 - val_mae: 2.6125\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 7.2330 - mae: 1.9822 - val_loss: 16.8416 - val_mae: 2.6072\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 7.2468 - mae: 2.0015 - val_loss: 16.2229 - val_mae: 2.5947\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 7.0566 - mae: 1.9555 - val_loss: 15.8926 - val_mae: 2.5582\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 7.3160 - mae: 1.9720 - val_loss: 16.3699 - val_mae: 2.5605\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 7.0025 - mae: 1.9688 - val_loss: 16.4345 - val_mae: 2.6025\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 7.0429 - mae: 1.9528 - val_loss: 16.6362 - val_mae: 2.6460\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 7.3675 - mae: 2.0039 - val_loss: 15.8882 - val_mae: 2.5405\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 6.9730 - mae: 1.9404 - val_loss: 16.4566 - val_mae: 2.5526\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 6.9927 - mae: 1.9395 - val_loss: 15.6907 - val_mae: 2.5304\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 6.7677 - mae: 1.9085 - val_loss: 15.7611 - val_mae: 2.5140\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 6.7832 - mae: 1.9098 - val_loss: 15.6025 - val_mae: 2.5151\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 6.8715 - mae: 1.9073 - val_loss: 15.8353 - val_mae: 2.5289\n",
      "processing fold # 4\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 547.7074 - mae: 21.6442 - val_loss: 624.2645 - val_mae: 23.0467\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 520.1394 - mae: 20.9697 - val_loss: 601.9645 - val_mae: 22.5314\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 498.6994 - mae: 20.4217 - val_loss: 580.4694 - val_mae: 22.0258\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 477.7426 - mae: 19.8748 - val_loss: 558.9752 - val_mae: 21.5120\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 456.4908 - mae: 19.3223 - val_loss: 535.9720 - val_mae: 20.9593\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 434.3594 - mae: 18.7427 - val_loss: 513.0477 - val_mae: 20.4135\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 412.2289 - mae: 18.1533 - val_loss: 489.2169 - val_mae: 19.8406\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 389.3512 - mae: 17.5289 - val_loss: 463.9824 - val_mae: 19.2245\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 365.7938 - mae: 16.8777 - val_loss: 439.4779 - val_mae: 18.5941\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 342.5108 - mae: 16.2291 - val_loss: 413.7409 - val_mae: 17.9156\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 318.5279 - mae: 15.5439 - val_loss: 388.5233 - val_mae: 17.2143\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 295.3502 - mae: 14.8707 - val_loss: 363.6816 - val_mae: 16.5165\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 272.6475 - mae: 14.1873 - val_loss: 338.4498 - val_mae: 15.8159\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 250.0112 - mae: 13.4618 - val_loss: 313.5010 - val_mae: 15.0976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 228.1371 - mae: 12.7441 - val_loss: 289.6640 - val_mae: 14.3873\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 0s 74us/sample - loss: 207.0766 - mae: 12.0435 - val_loss: 265.8384 - val_mae: 13.6380\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 186.5993 - mae: 11.3061 - val_loss: 243.2082 - val_mae: 12.8959\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 167.6477 - mae: 10.5973 - val_loss: 221.4406 - val_mae: 12.1314\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 150.1849 - mae: 9.8922 - val_loss: 201.3971 - val_mae: 11.4132\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 134.1599 - mae: 9.2860 - val_loss: 182.2540 - val_mae: 10.7063\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 141.5847 - mae: 9.388 - 0s 74us/sample - loss: 119.5844 - mae: 8.6894 - val_loss: 164.8015 - val_mae: 10.0376\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 106.3102 - mae: 8.1110 - val_loss: 149.7492 - val_mae: 9.4650\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 95.2330 - mae: 7.6270 - val_loss: 135.7099 - val_mae: 8.9119\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 85.3950 - mae: 7.1903 - val_loss: 123.2826 - val_mae: 8.4091\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 76.8882 - mae: 6.8014 - val_loss: 111.3330 - val_mae: 7.9190\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 69.1154 - mae: 6.4104 - val_loss: 101.3013 - val_mae: 7.5025\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 62.5295 - mae: 6.0664 - val_loss: 92.3594 - val_mae: 7.1056\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 56.8948 - mae: 5.7513 - val_loss: 83.7123 - val_mae: 6.7247\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 51.7067 - mae: 5.4365 - val_loss: 77.3090 - val_mae: 6.4165\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 0s 71us/sample - loss: 47.4827 - mae: 5.1658 - val_loss: 71.9265 - val_mae: 6.1271\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 43.8716 - mae: 4.9307 - val_loss: 66.4837 - val_mae: 5.8319\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 40.6056 - mae: 4.6983 - val_loss: 61.2693 - val_mae: 5.5592\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 37.6926 - mae: 4.5038 - val_loss: 57.7680 - val_mae: 5.3232\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 34.9004 - mae: 4.3004 - val_loss: 53.7350 - val_mae: 5.1160\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 32.3737 - mae: 4.1263 - val_loss: 49.4504 - val_mae: 4.9222\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 33.0631 - mae: 4.12 - 0s 68us/sample - loss: 30.0641 - mae: 3.9412 - val_loss: 46.7954 - val_mae: 4.7430\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 28.0806 - mae: 3.7952 - val_loss: 43.8855 - val_mae: 4.5818\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 26.3910 - mae: 3.6585 - val_loss: 41.8043 - val_mae: 4.4379\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 24.7098 - mae: 3.5338 - val_loss: 39.0324 - val_mae: 4.2762\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 23.2643 - mae: 3.4388 - val_loss: 36.7504 - val_mae: 4.1645\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 22.1016 - mae: 3.3375 - val_loss: 34.0841 - val_mae: 4.0892\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 20.9996 - mae: 3.2664 - val_loss: 32.5960 - val_mae: 3.9892\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 19.9465 - mae: 3.1866 - val_loss: 31.2365 - val_mae: 3.8987\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 19.2318 - mae: 3.0954 - val_loss: 30.4349 - val_mae: 3.8176\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 18.4942 - mae: 3.0420 - val_loss: 28.7690 - val_mae: 3.7494\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 17.8958 - mae: 2.9873 - val_loss: 28.4578 - val_mae: 3.6701\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 0s 63us/sample - loss: 17.3023 - mae: 2.9104 - val_loss: 27.0769 - val_mae: 3.6291\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 0s 92us/sample - loss: 16.7711 - mae: 2.8792 - val_loss: 25.7479 - val_mae: 3.6199\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 0s 77us/sample - loss: 16.4501 - mae: 2.8834 - val_loss: 25.7632 - val_mae: 3.5020\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 16.0671 - mae: 2.8014 - val_loss: 25.4817 - val_mae: 3.4484\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 15.5870 - mae: 2.7442 - val_loss: 23.9882 - val_mae: 3.4387\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 15.1626 - mae: 2.7319 - val_loss: 23.6203 - val_mae: 3.3999\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 14.9245 - mae: 2.6946 - val_loss: 22.8022 - val_mae: 3.4095\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 14.6665 - mae: 2.7117 - val_loss: 22.1407 - val_mae: 3.3798\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 14.2786 - mae: 2.6930 - val_loss: 22.1312 - val_mae: 3.2590\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 14.0164 - mae: 2.6258 - val_loss: 21.4509 - val_mae: 3.2843\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 13.8581 - mae: 2.6298 - val_loss: 21.4830 - val_mae: 3.2353\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 13.7229 - mae: 2.5828 - val_loss: 21.1521 - val_mae: 3.1812\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 13.4619 - mae: 2.5562 - val_loss: 20.6715 - val_mae: 3.1641\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 13.1852 - mae: 2.5094 - val_loss: 19.7342 - val_mae: 3.1798\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 12.8829 - mae: 2.5180 - val_loss: 19.5153 - val_mae: 3.1040\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 12.6399 - mae: 2.4888 - val_loss: 19.7274 - val_mae: 3.0964\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 12.6073 - mae: 2.4701 - val_loss: 18.6641 - val_mae: 3.0649\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 12.2630 - mae: 2.4669 - val_loss: 18.4663 - val_mae: 3.0507\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 12.1391 - mae: 2.4700 - val_loss: 18.3932 - val_mae: 3.0530\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 11.9341 - mae: 2.4218 - val_loss: 18.0854 - val_mae: 3.0242\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.8184 - mae: 2.4175 - val_loss: 18.0034 - val_mae: 3.0153\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 11.6342 - mae: 2.4128 - val_loss: 17.9016 - val_mae: 3.0602\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 11.5168 - mae: 2.3687 - val_loss: 18.1233 - val_mae: 3.0084\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 11.6310 - mae: 2.3880 - val_loss: 17.3260 - val_mae: 2.9529\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.3166 - mae: 2.3588 - val_loss: 17.0319 - val_mae: 2.9407\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 11.2153 - mae: 2.3596 - val_loss: 16.7616 - val_mae: 2.9787\n",
      "Epoch 73/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 62us/sample - loss: 11.0997 - mae: 2.3159 - val_loss: 16.4132 - val_mae: 2.9008\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 11.0375 - mae: 2.3846 - val_loss: 16.4482 - val_mae: 2.9574\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.9109 - mae: 2.3428 - val_loss: 16.3552 - val_mae: 2.8925\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.8127 - mae: 2.3097 - val_loss: 16.1536 - val_mae: 2.9139\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.7444 - mae: 2.3082 - val_loss: 16.0840 - val_mae: 2.8760\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.6633 - mae: 2.2922 - val_loss: 15.7625 - val_mae: 2.8889\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 10.3493 - mae: 2.2677 - val_loss: 15.7622 - val_mae: 2.8690\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.4949 - mae: 2.2867 - val_loss: 15.8042 - val_mae: 2.9070\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.2887 - mae: 2.2316 - val_loss: 15.5199 - val_mae: 2.8646\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 10.2080 - mae: 2.2555 - val_loss: 15.4591 - val_mae: 2.8764\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 10.2249 - mae: 2.2602 - val_loss: 15.3581 - val_mae: 2.8645\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 10.0722 - mae: 2.2160 - val_loss: 15.2122 - val_mae: 2.8218\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 10.0587 - mae: 2.2198 - val_loss: 14.8064 - val_mae: 2.7689\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 9.8567 - mae: 2.2336 - val_loss: 14.9299 - val_mae: 2.8401\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.8462 - mae: 2.1862 - val_loss: 14.6551 - val_mae: 2.7847\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.7591 - mae: 2.1763 - val_loss: 14.6800 - val_mae: 2.7916\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.6507 - mae: 2.1732 - val_loss: 14.5415 - val_mae: 2.7745\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.6559 - mae: 2.1907 - val_loss: 14.6813 - val_mae: 2.8027\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.6220 - mae: 2.1695 - val_loss: 14.4123 - val_mae: 2.7319\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.5606 - mae: 2.1800 - val_loss: 14.3088 - val_mae: 2.7628\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.4344 - mae: 2.1769 - val_loss: 14.1920 - val_mae: 2.7611\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.3207 - mae: 2.1329 - val_loss: 14.0381 - val_mae: 2.7262\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 9.2017 - mae: 2.1532 - val_loss: 14.0308 - val_mae: 2.7407\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 9.3659 - mae: 2.1510 - val_loss: 14.0180 - val_mae: 2.7469\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.2765 - mae: 2.1155 - val_loss: 13.8729 - val_mae: 2.6836\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 9.3585 - mae: 2.1570 - val_loss: 13.7729 - val_mae: 2.7134\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 9.0673 - mae: 2.1311 - val_loss: 13.6989 - val_mae: 2.7114\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 8.9245 - mae: 2.0874 - val_loss: 13.5902 - val_mae: 2.6963\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 8.9035 - mae: 2.0960 - val_loss: 13.8141 - val_mae: 2.7440\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 0s 58us/sample - loss: 8.9418 - mae: 2.0837 - val_loss: 13.8398 - val_mae: 2.7407\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 0s 68us/sample - loss: 9.0587 - mae: 2.1121 - val_loss: 13.4988 - val_mae: 2.7124\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 0s 60us/sample - loss: 8.8800 - mae: 2.0746 - val_loss: 13.3190 - val_mae: 2.6615\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.7191 - mae: 2.0496 - val_loss: 13.4409 - val_mae: 2.6533\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.8410 - mae: 2.0858 - val_loss: 13.6453 - val_mae: 2.7030\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 8.7873 - mae: 2.0865 - val_loss: 13.3859 - val_mae: 2.6757\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.6266 - mae: 2.0449 - val_loss: 13.4127 - val_mae: 2.7005\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.5278 - mae: 2.0204 - val_loss: 13.3556 - val_mae: 2.6180\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.5514 - mae: 2.0665 - val_loss: 13.1773 - val_mae: 2.6534\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.4830 - mae: 2.0334 - val_loss: 13.4874 - val_mae: 2.6993\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.4278 - mae: 2.0553 - val_loss: 13.2524 - val_mae: 2.6719\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 0s 65us/sample - loss: 8.4179 - mae: 2.0211 - val_loss: 13.0088 - val_mae: 2.6594\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 8.4195 - mae: 2.0347 - val_loss: 12.8805 - val_mae: 2.6052\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 0s 62us/sample - loss: 8.2673 - mae: 2.0348 - val_loss: 13.1689 - val_mae: 2.7101\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 8.2914 - mae: 1.9907 - val_loss: 12.8312 - val_mae: 2.5981\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 0s 59us/sample - loss: 8.2490 - mae: 1.9963 - val_loss: 12.6495 - val_mae: 2.5761\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 0s 55us/sample - loss: 8.5522 - mae: 2.0651 - val_loss: 12.9592 - val_mae: 2.5844\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 0s 60us/sample - loss: 8.2306 - mae: 2.0528 - val_loss: 12.7095 - val_mae: 2.6289\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 0s 61us/sample - loss: 7.9906 - mae: 1.9547 - val_loss: 12.5643 - val_mae: 2.5744\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/200\n",
      "323/323 [==============================] - 0s 2ms/sample - loss: 573.0325 - mae: 22.1006 - val_loss: 621.5005 - val_mae: 23.1582\n",
      "Epoch 2/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 545.2034 - mae: 21.4598 - val_loss: 600.2365 - val_mae: 22.6839\n",
      "Epoch 3/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 525.2746 - mae: 20.9785 - val_loss: 580.8751 - val_mae: 22.2489\n",
      "Epoch 4/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 506.8532 - mae: 20.5308 - val_loss: 562.1609 - val_mae: 21.8194\n",
      "Epoch 5/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 488.7679 - mae: 20.0795 - val_loss: 543.0430 - val_mae: 21.3757\n",
      "Epoch 6/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 469.9510 - mae: 19.6176 - val_loss: 522.1832 - val_mae: 20.8883\n",
      "Epoch 7/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 450.1714 - mae: 19.1127 - val_loss: 501.2375 - val_mae: 20.3879\n",
      "Epoch 8/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 429.8108 - mae: 18.5951 - val_loss: 479.0604 - val_mae: 19.8504\n",
      "Epoch 9/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 408.7789 - mae: 18.0414 - val_loss: 456.6708 - val_mae: 19.2899\n",
      "Epoch 10/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 387.6134 - mae: 17.4705 - val_loss: 433.9288 - val_mae: 18.7200\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 59us/sample - loss: 366.0495 - mae: 16.8849 - val_loss: 410.7727 - val_mae: 18.1299\n",
      "Epoch 12/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 344.0229 - mae: 16.2666 - val_loss: 386.6731 - val_mae: 17.4900\n",
      "Epoch 13/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 321.4125 - mae: 15.6155 - val_loss: 363.6079 - val_mae: 16.8477\n",
      "Epoch 14/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 299.6203 - mae: 14.9774 - val_loss: 340.3428 - val_mae: 16.1754\n",
      "Epoch 15/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 277.7450 - mae: 14.3187 - val_loss: 316.5882 - val_mae: 15.4565\n",
      "Epoch 16/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 255.7825 - mae: 13.6199 - val_loss: 293.3517 - val_mae: 14.7193\n",
      "Epoch 17/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 234.4133 - mae: 12.9130 - val_loss: 270.7436 - val_mae: 13.9712\n",
      "Epoch 18/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 213.8499 - mae: 12.1948 - val_loss: 248.6578 - val_mae: 13.2095\n",
      "Epoch 19/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 194.0673 - mae: 11.4835 - val_loss: 227.7847 - val_mae: 12.4712\n",
      "Epoch 20/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 175.5261 - mae: 10.7663 - val_loss: 208.0333 - val_mae: 11.7268\n",
      "Epoch 21/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 158.1290 - mae: 10.0819 - val_loss: 188.5968 - val_mae: 10.9252\n",
      "Epoch 22/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 141.5097 - mae: 9.3989 - val_loss: 171.1100 - val_mae: 10.1826\n",
      "Epoch 23/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 126.8590 - mae: 8.7824 - val_loss: 155.1069 - val_mae: 9.5023\n",
      "Epoch 24/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 113.8495 - mae: 8.1855 - val_loss: 141.1461 - val_mae: 8.9013\n",
      "Epoch 25/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 102.7952 - mae: 7.6559 - val_loss: 128.5370 - val_mae: 8.3759\n",
      "Epoch 26/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 92.9008 - mae: 7.1939 - val_loss: 117.4214 - val_mae: 7.9283\n",
      "Epoch 27/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 84.4002 - mae: 6.7977 - val_loss: 107.1753 - val_mae: 7.4952\n",
      "Epoch 28/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 76.7826 - mae: 6.4440 - val_loss: 97.8019 - val_mae: 7.0883\n",
      "Epoch 29/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 69.8528 - mae: 6.1057 - val_loss: 89.5214 - val_mae: 6.7371\n",
      "Epoch 30/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 64.0365 - mae: 5.8297 - val_loss: 82.2868 - val_mae: 6.4191\n",
      "Epoch 31/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 58.8091 - mae: 5.5656 - val_loss: 75.7637 - val_mae: 6.1204\n",
      "Epoch 32/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 54.4688 - mae: 5.3686 - val_loss: 70.1686 - val_mae: 5.8762\n",
      "Epoch 33/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 50.8239 - mae: 5.1641 - val_loss: 65.5168 - val_mae: 5.6590\n",
      "Epoch 34/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 47.1657 - mae: 4.9613 - val_loss: 60.5958 - val_mae: 5.4413\n",
      "Epoch 35/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 43.8192 - mae: 4.7794 - val_loss: 56.0207 - val_mae: 5.2382\n",
      "Epoch 36/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 40.9074 - mae: 4.6070 - val_loss: 52.2051 - val_mae: 5.0664\n",
      "Epoch 37/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 38.3828 - mae: 4.4631 - val_loss: 48.3883 - val_mae: 4.8720\n",
      "Epoch 38/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 36.0408 - mae: 4.2929 - val_loss: 45.4450 - val_mae: 4.7069\n",
      "Epoch 39/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 33.8198 - mae: 4.1323 - val_loss: 42.1782 - val_mae: 4.5490\n",
      "Epoch 40/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 31.7754 - mae: 3.9878 - val_loss: 39.6067 - val_mae: 4.4087\n",
      "Epoch 41/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 30.0784 - mae: 3.8526 - val_loss: 37.1207 - val_mae: 4.2635\n",
      "Epoch 42/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 28.4465 - mae: 3.7413 - val_loss: 34.7348 - val_mae: 4.1390\n",
      "Epoch 43/200\n",
      "323/323 [==============================] - 0s 60us/sample - loss: 26.9642 - mae: 3.6178 - val_loss: 32.9590 - val_mae: 4.0253\n",
      "Epoch 44/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 25.8545 - mae: 3.5133 - val_loss: 30.9432 - val_mae: 3.9456\n",
      "Epoch 45/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 24.6370 - mae: 3.4396 - val_loss: 29.4287 - val_mae: 3.8491\n",
      "Epoch 46/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 23.5344 - mae: 3.3246 - val_loss: 27.5630 - val_mae: 3.8015\n",
      "Epoch 47/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 22.5644 - mae: 3.2811 - val_loss: 26.4817 - val_mae: 3.7044\n",
      "Epoch 48/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 22.0248 - mae: 3.2057 - val_loss: 25.6644 - val_mae: 3.6333\n",
      "Epoch 49/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 21.1826 - mae: 3.1049 - val_loss: 24.5439 - val_mae: 3.5900\n",
      "Epoch 50/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 20.5529 - mae: 3.0721 - val_loss: 23.5975 - val_mae: 3.5349\n",
      "Epoch 51/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 19.9364 - mae: 3.0259 - val_loss: 22.7637 - val_mae: 3.4628\n",
      "Epoch 52/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 19.3702 - mae: 2.9785 - val_loss: 21.8676 - val_mae: 3.4208\n",
      "Epoch 53/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 18.7707 - mae: 2.9232 - val_loss: 21.0422 - val_mae: 3.3760\n",
      "Epoch 54/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 18.4022 - mae: 2.8854 - val_loss: 20.8886 - val_mae: 3.4471\n",
      "Epoch 55/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 17.7881 - mae: 2.8747 - val_loss: 19.9280 - val_mae: 3.3176\n",
      "Epoch 56/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 17.3906 - mae: 2.8295 - val_loss: 19.5454 - val_mae: 3.3354\n",
      "Epoch 57/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 16.8876 - mae: 2.7715 - val_loss: 18.7613 - val_mae: 3.2448\n",
      "Epoch 58/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 16.4672 - mae: 2.7663 - val_loss: 18.4344 - val_mae: 3.1565\n",
      "Epoch 59/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 16.1948 - mae: 2.7211 - val_loss: 18.0134 - val_mae: 3.1480\n",
      "Epoch 60/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 15.7108 - mae: 2.6764 - val_loss: 17.6208 - val_mae: 3.1427\n",
      "Epoch 61/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 15.4613 - mae: 2.6681 - val_loss: 17.4190 - val_mae: 3.1294\n",
      "Epoch 62/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 15.3084 - mae: 2.6599 - val_loss: 16.9133 - val_mae: 3.0816\n",
      "Epoch 63/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 14.7766 - mae: 2.5914 - val_loss: 16.5438 - val_mae: 3.0296\n",
      "Epoch 64/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 14.4646 - mae: 2.5304 - val_loss: 16.5248 - val_mae: 3.0499\n",
      "Epoch 65/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 14.0155 - mae: 2.5452 - val_loss: 16.2986 - val_mae: 3.0430\n",
      "Epoch 66/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 13.9626 - mae: 2.5535 - val_loss: 16.1561 - val_mae: 3.0472\n",
      "Epoch 67/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 13.7268 - mae: 2.5132 - val_loss: 15.6718 - val_mae: 2.9696\n",
      "Epoch 68/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 13.3766 - mae: 2.4379 - val_loss: 15.6501 - val_mae: 2.9584\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 65us/sample - loss: 13.0459 - mae: 2.4749 - val_loss: 15.4240 - val_mae: 2.9434\n",
      "Epoch 70/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 12.7815 - mae: 2.4611 - val_loss: 15.4898 - val_mae: 2.9838\n",
      "Epoch 71/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 12.7249 - mae: 2.4321 - val_loss: 15.2114 - val_mae: 2.9384\n",
      "Epoch 72/200\n",
      "323/323 [==============================] - 0s 55us/sample - loss: 12.3237 - mae: 2.4207 - val_loss: 15.2857 - val_mae: 2.9425\n",
      "Epoch 73/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 12.3114 - mae: 2.4322 - val_loss: 14.8223 - val_mae: 2.8936\n",
      "Epoch 74/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 11.9305 - mae: 2.3584 - val_loss: 14.7421 - val_mae: 2.8531\n",
      "Epoch 75/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 11.9591 - mae: 2.3805 - val_loss: 14.5929 - val_mae: 2.8508\n",
      "Epoch 76/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 11.6769 - mae: 2.3339 - val_loss: 14.6059 - val_mae: 2.8351\n",
      "Epoch 77/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 11.4151 - mae: 2.3107 - val_loss: 14.8036 - val_mae: 2.8560\n",
      "Epoch 78/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 11.3281 - mae: 2.3394 - val_loss: 14.4501 - val_mae: 2.7977\n",
      "Epoch 79/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 11.3205 - mae: 2.3212 - val_loss: 14.5589 - val_mae: 2.8624\n",
      "Epoch 80/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 10.9413 - mae: 2.2471 - val_loss: 14.7485 - val_mae: 2.8476\n",
      "Epoch 81/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 10.8898 - mae: 2.3206 - val_loss: 14.4452 - val_mae: 2.8213\n",
      "Epoch 82/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 10.6794 - mae: 2.2669 - val_loss: 14.1969 - val_mae: 2.7812\n",
      "Epoch 83/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 10.5869 - mae: 2.2658 - val_loss: 14.1174 - val_mae: 2.8367\n",
      "Epoch 84/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 10.5547 - mae: 2.2049 - val_loss: 14.5572 - val_mae: 2.8154\n",
      "Epoch 85/200\n",
      "323/323 [==============================] - 0s 55us/sample - loss: 10.2995 - mae: 2.2137 - val_loss: 14.4563 - val_mae: 2.7727\n",
      "Epoch 86/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 10.3510 - mae: 2.2522 - val_loss: 14.4638 - val_mae: 2.7417\n",
      "Epoch 87/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 10.1964 - mae: 2.2499 - val_loss: 14.3586 - val_mae: 2.7606\n",
      "Epoch 88/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 10.0027 - mae: 2.2198 - val_loss: 14.0154 - val_mae: 2.7648\n",
      "Epoch 89/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 9.8387 - mae: 2.1532 - val_loss: 14.3230 - val_mae: 2.7770\n",
      "Epoch 90/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 9.7858 - mae: 2.1857 - val_loss: 13.9865 - val_mae: 2.7996\n",
      "Epoch 91/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 9.7018 - mae: 2.1242 - val_loss: 13.9825 - val_mae: 2.7263\n",
      "Epoch 92/200\n",
      "323/323 [==============================] - 0s 63us/sample - loss: 9.7737 - mae: 2.1422 - val_loss: 14.4067 - val_mae: 2.7255\n",
      "Epoch 93/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 9.5001 - mae: 2.1365 - val_loss: 14.8434 - val_mae: 2.8200\n",
      "Epoch 94/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 9.4478 - mae: 2.1549 - val_loss: 14.2319 - val_mae: 2.7785\n",
      "Epoch 95/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 9.3255 - mae: 2.1025 - val_loss: 14.1868 - val_mae: 2.6962\n",
      "Epoch 96/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 9.2305 - mae: 2.0963 - val_loss: 14.3844 - val_mae: 2.7175\n",
      "Epoch 97/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 9.0730 - mae: 2.0949 - val_loss: 14.0854 - val_mae: 2.7094\n",
      "Epoch 98/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 9.1512 - mae: 2.0726 - val_loss: 14.7851 - val_mae: 2.6915\n",
      "Epoch 99/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 9.0321 - mae: 2.1181 - val_loss: 14.0979 - val_mae: 2.7081\n",
      "Epoch 100/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 9.0322 - mae: 2.0819 - val_loss: 14.8754 - val_mae: 2.7636\n",
      "Epoch 101/200\n",
      "323/323 [==============================] - 0s 61us/sample - loss: 8.9868 - mae: 2.0648 - val_loss: 15.3725 - val_mae: 2.7442\n",
      "Epoch 102/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.9469 - mae: 2.0989 - val_loss: 14.9242 - val_mae: 2.6698\n",
      "Epoch 103/200\n",
      "323/323 [==============================] - 0s 55us/sample - loss: 8.8132 - mae: 2.0975 - val_loss: 14.5649 - val_mae: 2.7549\n",
      "Epoch 104/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 8.8441 - mae: 2.0537 - val_loss: 15.0585 - val_mae: 2.7124\n",
      "Epoch 105/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.6560 - mae: 2.0877 - val_loss: 14.3956 - val_mae: 2.6548\n",
      "Epoch 106/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.7347 - mae: 2.0327 - val_loss: 15.0808 - val_mae: 2.6271\n",
      "Epoch 107/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.7725 - mae: 2.0954 - val_loss: 14.4157 - val_mae: 2.6996\n",
      "Epoch 108/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.4526 - mae: 2.0123 - val_loss: 14.8056 - val_mae: 2.6685\n",
      "Epoch 109/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 8.6661 - mae: 2.0648 - val_loss: 14.9621 - val_mae: 2.7324\n",
      "Epoch 110/200\n",
      "323/323 [==============================] - 0s 55us/sample - loss: 8.3976 - mae: 2.0223 - val_loss: 15.2559 - val_mae: 2.7403\n",
      "Epoch 111/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 8.3959 - mae: 2.0441 - val_loss: 14.8257 - val_mae: 2.6470\n",
      "Epoch 112/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 8.5301 - mae: 2.0492 - val_loss: 15.0804 - val_mae: 2.6866\n",
      "Epoch 113/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.4015 - mae: 2.0064 - val_loss: 14.9877 - val_mae: 2.6498\n",
      "Epoch 114/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 8.4039 - mae: 2.0512 - val_loss: 14.6643 - val_mae: 2.6364\n",
      "Epoch 115/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.2658 - mae: 2.0356 - val_loss: 14.2980 - val_mae: 2.6838\n",
      "Epoch 116/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 8.3170 - mae: 1.9911 - val_loss: 14.3328 - val_mae: 2.6412\n",
      "Epoch 117/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 8.3408 - mae: 2.0075 - val_loss: 14.6839 - val_mae: 2.6135\n",
      "Epoch 118/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 8.1410 - mae: 1.9988 - val_loss: 15.1192 - val_mae: 2.6962\n",
      "Epoch 119/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.9977 - mae: 1.9760 - val_loss: 14.7848 - val_mae: 2.6515\n",
      "Epoch 120/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 8.1598 - mae: 1.9869 - val_loss: 15.8164 - val_mae: 2.6545\n",
      "Epoch 121/200\n",
      "323/323 [==============================] - 0s 60us/sample - loss: 8.0163 - mae: 2.0176 - val_loss: 14.6750 - val_mae: 2.6394\n",
      "Epoch 122/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.9611 - mae: 1.9575 - val_loss: 14.8267 - val_mae: 2.6240\n",
      "Epoch 123/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 8.3227 - mae: 2.0116 - val_loss: 14.5685 - val_mae: 2.6336\n",
      "Epoch 124/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.8253 - mae: 1.9361 - val_loss: 15.1746 - val_mae: 2.6591\n",
      "Epoch 125/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.7703 - mae: 1.9502 - val_loss: 14.6894 - val_mae: 2.6516\n",
      "Epoch 126/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 8.0109 - mae: 1.9587 - val_loss: 14.6281 - val_mae: 2.7272\n",
      "Epoch 127/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 7.8885 - mae: 1.9256 - val_loss: 14.6523 - val_mae: 2.6576\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 65us/sample - loss: 7.7619 - mae: 1.9072 - val_loss: 14.7671 - val_mae: 2.6150\n",
      "Epoch 129/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.6756 - mae: 1.9159 - val_loss: 14.9229 - val_mae: 2.6210\n",
      "Epoch 130/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.6975 - mae: 1.9310 - val_loss: 15.7853 - val_mae: 2.6227\n",
      "Epoch 131/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.8032 - mae: 1.9938 - val_loss: 14.6977 - val_mae: 2.5827\n",
      "Epoch 132/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 7.6023 - mae: 1.9217 - val_loss: 14.9820 - val_mae: 2.6038\n",
      "Epoch 133/200\n",
      "323/323 [==============================] - ETA: 0s - loss: 5.3613 - mae: 1.784 - 0s 59us/sample - loss: 7.6256 - mae: 1.9200 - val_loss: 15.9097 - val_mae: 2.7222\n",
      "Epoch 134/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.7702 - mae: 1.9372 - val_loss: 15.8394 - val_mae: 2.6688\n",
      "Epoch 135/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 7.8456 - mae: 1.9529 - val_loss: 15.1072 - val_mae: 2.5889\n",
      "Epoch 136/200\n",
      "323/323 [==============================] - ETA: 0s - loss: 5.3317 - mae: 1.703 - 0s 56us/sample - loss: 7.6566 - mae: 1.9358 - val_loss: 15.1331 - val_mae: 2.5836\n",
      "Epoch 137/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.4392 - mae: 1.9111 - val_loss: 14.7787 - val_mae: 2.6242\n",
      "Epoch 138/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.6426 - mae: 1.9240 - val_loss: 15.0005 - val_mae: 2.6990\n",
      "Epoch 139/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.5310 - mae: 1.8777 - val_loss: 15.4411 - val_mae: 2.5844\n",
      "Epoch 140/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 7.3969 - mae: 1.9052 - val_loss: 15.0986 - val_mae: 2.7009\n",
      "Epoch 141/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 7.4087 - mae: 1.8806 - val_loss: 14.8307 - val_mae: 2.5671\n",
      "Epoch 142/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 7.3446 - mae: 1.8709 - val_loss: 14.8017 - val_mae: 2.5937\n",
      "Epoch 143/200\n",
      "323/323 [==============================] - 0s 68us/sample - loss: 7.3241 - mae: 1.8726 - val_loss: 15.1017 - val_mae: 2.5817\n",
      "Epoch 144/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 7.4094 - mae: 1.8913 - val_loss: 14.8042 - val_mae: 2.6078\n",
      "Epoch 145/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.2834 - mae: 1.8557 - val_loss: 15.5017 - val_mae: 2.6905\n",
      "Epoch 146/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.3369 - mae: 1.8665 - val_loss: 14.8943 - val_mae: 2.5755\n",
      "Epoch 147/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.1550 - mae: 1.8380 - val_loss: 15.8875 - val_mae: 2.6572\n",
      "Epoch 148/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.2642 - mae: 1.8768 - val_loss: 14.8135 - val_mae: 2.5575\n",
      "Epoch 149/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.1983 - mae: 1.8618 - val_loss: 14.9705 - val_mae: 2.6649\n",
      "Epoch 150/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.1389 - mae: 1.8426 - val_loss: 15.4763 - val_mae: 2.5745\n",
      "Epoch 151/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.2417 - mae: 1.8814 - val_loss: 15.5666 - val_mae: 2.5745\n",
      "Epoch 152/200\n",
      "323/323 [==============================] - 0s 55us/sample - loss: 7.0179 - mae: 1.8570 - val_loss: 15.3173 - val_mae: 2.5748\n",
      "Epoch 153/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 7.0088 - mae: 1.8292 - val_loss: 15.2291 - val_mae: 2.5683\n",
      "Epoch 154/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.2723 - mae: 1.8694 - val_loss: 15.6230 - val_mae: 2.5866\n",
      "Epoch 155/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.9342 - mae: 1.8302 - val_loss: 15.1112 - val_mae: 2.5748\n",
      "Epoch 156/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.0412 - mae: 1.8291 - val_loss: 15.2028 - val_mae: 2.6857\n",
      "Epoch 157/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.1314 - mae: 1.8518 - val_loss: 15.1112 - val_mae: 2.6210\n",
      "Epoch 158/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.9486 - mae: 1.7936 - val_loss: 16.3468 - val_mae: 2.6269\n",
      "Epoch 159/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 7.0300 - mae: 1.8723 - val_loss: 15.7611 - val_mae: 2.5917\n",
      "Epoch 160/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.9712 - mae: 1.8251 - val_loss: 16.4946 - val_mae: 2.6558\n",
      "Epoch 161/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 7.0488 - mae: 1.8827 - val_loss: 15.4433 - val_mae: 2.6308\n",
      "Epoch 162/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.7657 - mae: 1.7873 - val_loss: 15.8444 - val_mae: 2.6431\n",
      "Epoch 163/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.8413 - mae: 1.8231 - val_loss: 15.5474 - val_mae: 2.6572\n",
      "Epoch 164/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.7615 - mae: 1.7860 - val_loss: 15.3463 - val_mae: 2.5701\n",
      "Epoch 165/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.7628 - mae: 1.7809 - val_loss: 15.8588 - val_mae: 2.5651\n",
      "Epoch 166/200\n",
      "323/323 [==============================] - 0s 71us/sample - loss: 6.9187 - mae: 1.8462 - val_loss: 15.1415 - val_mae: 2.5977\n",
      "Epoch 167/200\n",
      "323/323 [==============================] - 0s 77us/sample - loss: 6.6938 - mae: 1.7844 - val_loss: 15.4234 - val_mae: 2.5582\n",
      "Epoch 168/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.6291 - mae: 1.7825 - val_loss: 16.0466 - val_mae: 2.6604\n",
      "Epoch 169/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.6175 - mae: 1.7756 - val_loss: 16.3055 - val_mae: 2.6153\n",
      "Epoch 170/200\n",
      "323/323 [==============================] - 0s 61us/sample - loss: 6.7490 - mae: 1.8098 - val_loss: 15.1817 - val_mae: 2.5728\n",
      "Epoch 171/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 6.5674 - mae: 1.7591 - val_loss: 16.5554 - val_mae: 2.5958\n",
      "Epoch 172/200\n",
      "323/323 [==============================] - 0s 52us/sample - loss: 6.7005 - mae: 1.7986 - val_loss: 15.4979 - val_mae: 2.5721\n",
      "Epoch 173/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.4621 - mae: 1.7519 - val_loss: 15.6245 - val_mae: 2.6010\n",
      "Epoch 174/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.5130 - mae: 1.7873 - val_loss: 15.3067 - val_mae: 2.6743\n",
      "Epoch 175/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 6.5759 - mae: 1.7565 - val_loss: 15.8433 - val_mae: 2.6576\n",
      "Epoch 176/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.4416 - mae: 1.7523 - val_loss: 16.6293 - val_mae: 2.6205\n",
      "Epoch 177/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.4322 - mae: 1.7971 - val_loss: 15.2874 - val_mae: 2.5618\n",
      "Epoch 178/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.4029 - mae: 1.7574 - val_loss: 16.1648 - val_mae: 2.5837\n",
      "Epoch 179/200\n",
      "323/323 [==============================] - 0s 55us/sample - loss: 6.3457 - mae: 1.7544 - val_loss: 15.6159 - val_mae: 2.6043\n",
      "Epoch 180/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.6785 - mae: 1.7899 - val_loss: 15.6639 - val_mae: 2.6184\n",
      "Epoch 181/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.2857 - mae: 1.7208 - val_loss: 16.3481 - val_mae: 2.5924\n",
      "Epoch 182/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.3204 - mae: 1.7463 - val_loss: 17.3017 - val_mae: 2.6929\n",
      "Epoch 183/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.3870 - mae: 1.7965 - val_loss: 15.8181 - val_mae: 2.6102\n",
      "Epoch 184/200\n",
      "323/323 [==============================] - ETA: 0s - loss: 5.0354 - mae: 1.707 - 0s 61us/sample - loss: 6.3921 - mae: 1.7459 - val_loss: 17.3025 - val_mae: 2.7054\n",
      "Epoch 185/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.2936 - mae: 1.7674 - val_loss: 15.2138 - val_mae: 2.5672\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 62us/sample - loss: 6.2512 - mae: 1.7189 - val_loss: 15.5982 - val_mae: 2.5611\n",
      "Epoch 187/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.1588 - mae: 1.7164 - val_loss: 15.8354 - val_mae: 2.5951\n",
      "Epoch 188/200\n",
      "323/323 [==============================] - 0s 55us/sample - loss: 6.2542 - mae: 1.7063 - val_loss: 18.0795 - val_mae: 2.8024\n",
      "Epoch 189/200\n",
      "323/323 [==============================] - 0s 55us/sample - loss: 6.5244 - mae: 1.8168 - val_loss: 15.5715 - val_mae: 2.6130\n",
      "Epoch 190/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.3961 - mae: 1.7501 - val_loss: 16.3615 - val_mae: 2.5721\n",
      "Epoch 191/200\n",
      "323/323 [==============================] - 0s 65us/sample - loss: 6.2530 - mae: 1.7345 - val_loss: 15.3339 - val_mae: 2.5509\n",
      "Epoch 192/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 6.2050 - mae: 1.7078 - val_loss: 15.3542 - val_mae: 2.5657\n",
      "Epoch 193/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.1683 - mae: 1.7043 - val_loss: 15.2403 - val_mae: 2.5750\n",
      "Epoch 194/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.1234 - mae: 1.6962 - val_loss: 15.7188 - val_mae: 2.5701\n",
      "Epoch 195/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.0598 - mae: 1.6997 - val_loss: 15.9965 - val_mae: 2.5793\n",
      "Epoch 196/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 6.1055 - mae: 1.7139 - val_loss: 15.5759 - val_mae: 2.6076\n",
      "Epoch 197/200\n",
      "323/323 [==============================] - 0s 59us/sample - loss: 6.1019 - mae: 1.7155 - val_loss: 15.5933 - val_mae: 2.5586\n",
      "Epoch 198/200\n",
      "323/323 [==============================] - 0s 56us/sample - loss: 5.9149 - mae: 1.6654 - val_loss: 15.7438 - val_mae: 2.6181\n",
      "Epoch 199/200\n",
      "323/323 [==============================] - 0s 55us/sample - loss: 6.1762 - mae: 1.7111 - val_loss: 16.0888 - val_mae: 2.6357\n",
      "Epoch 200/200\n",
      "323/323 [==============================] - 0s 62us/sample - loss: 5.9693 - mae: 1.6895 - val_loss: 15.7619 - val_mae: 2.5828\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Compile and Train the model for 200 epochs. Change the batch size from 1 to 128\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu',\n",
    "                        input_shape=(train_data.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_data, train_targets, validation_split =0.2, epochs = 200, batch_size = 128)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "k = 5\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 120\n",
    "all_scores = []\n",
    "\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=128, verbose=1)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    \n",
    "# Get a fresh, compiled model.\n",
    "model = build_model()\n",
    "# Train it on the entirety of the data.\n",
    "history = model.fit(train_data, train_targets, validation_split =0.2, epochs=200, batch_size=128, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Task 3: Plot the MAE (train & test) curves\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "plt.plot(epochs[10:], mae[10:], 'r', label='mean_absolute_error')\n",
    "plt.plot(epochs[10:], val_mae[10:], 'b', label='val_mean_absolute_error')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets, verbose=2)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Task 4: Comment on your model\n",
    "With higher batch size, the model is 'smoother' but there is a drop of quality. Compare to the model on top, this model have a higher max and min loss rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Scenerio B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1: Build the model\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()\n",
    "\n",
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "    \n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/200\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 508.1220 - mae: 20.5266 - val_loss: 496.8917 - val_mae: 20.2473\n",
      "Epoch 2/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 323.7639 - mae: 15.4232 - val_loss: 253.9840 - val_mae: 13.1565\n",
      "Epoch 3/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 127.9989 - mae: 8.4711 - val_loss: 115.7191 - val_mae: 7.7827\n",
      "Epoch 4/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 71.1978 - mae: 6.1180 - val_loss: 79.9329 - val_mae: 6.4752\n",
      "Epoch 5/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 51.6140 - mae: 5.1070 - val_loss: 57.9377 - val_mae: 5.4477\n",
      "Epoch 6/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 40.2697 - mae: 4.3685 - val_loss: 44.4995 - val_mae: 4.6373\n",
      "Epoch 7/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 32.2405 - mae: 3.8503 - val_loss: 35.9800 - val_mae: 4.0429\n",
      "Epoch 8/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 27.0030 - mae: 3.4445 - val_loss: 30.0379 - val_mae: 3.6652\n",
      "Epoch 9/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 24.0009 - mae: 3.1875 - val_loss: 25.1691 - val_mae: 3.3863\n",
      "Epoch 10/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 22.0678 - mae: 3.0381 - val_loss: 23.5253 - val_mae: 3.2802\n",
      "Epoch 11/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 20.8028 - mae: 2.8899 - val_loss: 22.0140 - val_mae: 3.1977\n",
      "Epoch 12/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 19.7756 - mae: 2.8159 - val_loss: 20.6619 - val_mae: 3.0980\n",
      "Epoch 13/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 18.7203 - mae: 2.7036 - val_loss: 19.3558 - val_mae: 2.9992\n",
      "Epoch 14/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 17.9613 - mae: 2.6644 - val_loss: 18.6425 - val_mae: 2.9455\n",
      "Epoch 15/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 17.3071 - mae: 2.5957 - val_loss: 18.4071 - val_mae: 2.8990\n",
      "Epoch 16/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 16.9008 - mae: 2.5410 - val_loss: 17.7407 - val_mae: 2.8788\n",
      "Epoch 17/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 16.2203 - mae: 2.5127 - val_loss: 17.3631 - val_mae: 2.8379\n",
      "Epoch 18/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 15.7444 - mae: 2.4669 - val_loss: 16.5558 - val_mae: 2.8310\n",
      "Epoch 19/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 15.4383 - mae: 2.4294 - val_loss: 15.9444 - val_mae: 2.8173\n",
      "Epoch 20/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 15.0882 - mae: 2.4138 - val_loss: 15.7886 - val_mae: 2.7912\n",
      "Epoch 21/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 14.7972 - mae: 2.3746 - val_loss: 15.7525 - val_mae: 2.8239\n",
      "Epoch 22/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 14.3124 - mae: 2.3350 - val_loss: 15.5002 - val_mae: 2.7641\n",
      "Epoch 23/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 14.0408 - mae: 2.3434 - val_loss: 15.0590 - val_mae: 2.7849\n",
      "Epoch 24/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 13.7123 - mae: 2.3025 - val_loss: 15.0221 - val_mae: 2.8149\n",
      "Epoch 25/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 13.3035 - mae: 2.2791 - val_loss: 14.8254 - val_mae: 2.7556\n",
      "Epoch 26/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 13.3018 - mae: 2.2508 - val_loss: 14.9422 - val_mae: 2.8619\n",
      "Epoch 27/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 12.9738 - mae: 2.2309 - val_loss: 14.3842 - val_mae: 2.7529\n",
      "Epoch 28/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 12.8428 - mae: 2.2139 - val_loss: 14.1191 - val_mae: 2.7846\n",
      "Epoch 29/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 12.5883 - mae: 2.1913 - val_loss: 13.7742 - val_mae: 2.7299\n",
      "Epoch 30/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 12.1912 - mae: 2.1891 - val_loss: 13.8636 - val_mae: 2.7415\n",
      "Epoch 31/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 12.1870 - mae: 2.1639 - val_loss: 13.3468 - val_mae: 2.7180\n",
      "Epoch 32/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.9728 - mae: 2.1559 - val_loss: 13.4661 - val_mae: 2.6831\n",
      "Epoch 33/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.9902 - mae: 2.1375 - val_loss: 13.2120 - val_mae: 2.6503\n",
      "Epoch 34/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.7821 - mae: 2.1171 - val_loss: 13.2623 - val_mae: 2.7363\n",
      "Epoch 35/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.4837 - mae: 2.1325 - val_loss: 13.0974 - val_mae: 2.6799\n",
      "Epoch 36/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.4848 - mae: 2.0950 - val_loss: 12.8350 - val_mae: 2.6518\n",
      "Epoch 37/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.5008 - mae: 2.0851 - val_loss: 12.5308 - val_mae: 2.6360\n",
      "Epoch 38/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.0457 - mae: 2.0796 - val_loss: 12.8225 - val_mae: 2.6803\n",
      "Epoch 39/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 11.1143 - mae: 2.0649 - val_loss: 12.5315 - val_mae: 2.6095\n",
      "Epoch 40/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.9809 - mae: 2.0597 - val_loss: 12.1396 - val_mae: 2.5906\n",
      "Epoch 41/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.8576 - mae: 2.0533 - val_loss: 12.1712 - val_mae: 2.6145\n",
      "Epoch 42/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.5050 - mae: 2.0320 - val_loss: 12.2935 - val_mae: 2.6935\n",
      "Epoch 43/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.6154 - mae: 2.0195 - val_loss: 11.9782 - val_mae: 2.5826\n",
      "Epoch 44/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.1352 - mae: 1.9996 - val_loss: 12.3321 - val_mae: 2.6522\n",
      "Epoch 45/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.5258 - mae: 2.0140 - val_loss: 12.1630 - val_mae: 2.6356\n",
      "Epoch 46/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.1637 - mae: 1.9987 - val_loss: 11.9517 - val_mae: 2.6181\n",
      "Epoch 47/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.0682 - mae: 1.9911 - val_loss: 12.0569 - val_mae: 2.6000\n",
      "Epoch 48/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.9120 - mae: 1.9942 - val_loss: 11.6154 - val_mae: 2.5920\n",
      "Epoch 49/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.7832 - mae: 1.9665 - val_loss: 11.9118 - val_mae: 2.6627\n",
      "Epoch 50/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.6718 - mae: 1.9790 - val_loss: 11.9213 - val_mae: 2.6509\n",
      "Epoch 51/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.6572 - mae: 1.9464 - val_loss: 12.3928 - val_mae: 2.6975\n",
      "Epoch 52/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.8982 - mae: 1.9395 - val_loss: 11.6888 - val_mae: 2.6022\n",
      "Epoch 53/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.5284 - mae: 1.9341 - val_loss: 11.8085 - val_mae: 2.6112\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.6353 - mae: 1.9173 - val_loss: 11.8070 - val_mae: 2.6465\n",
      "Epoch 55/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.4734 - mae: 1.9138 - val_loss: 11.4773 - val_mae: 2.6145\n",
      "Epoch 56/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.4709 - mae: 1.9102 - val_loss: 11.3010 - val_mae: 2.5550\n",
      "Epoch 57/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.3335 - mae: 1.9016 - val_loss: 11.3100 - val_mae: 2.5481\n",
      "Epoch 58/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.2085 - mae: 1.9083 - val_loss: 11.3315 - val_mae: 2.5232\n",
      "Epoch 59/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.6997 - mae: 1.9417 - val_loss: 11.5152 - val_mae: 2.6006\n",
      "Epoch 60/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.0990 - mae: 1.8729 - val_loss: 11.3613 - val_mae: 2.5555\n",
      "Epoch 61/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.0432 - mae: 1.8682 - val_loss: 11.4750 - val_mae: 2.5673\n",
      "Epoch 62/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.8549 - mae: 1.8572 - val_loss: 11.5613 - val_mae: 2.5438\n",
      "Epoch 63/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.7893 - mae: 1.8477 - val_loss: 11.3389 - val_mae: 2.5550\n",
      "Epoch 64/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.8486 - mae: 1.8489 - val_loss: 11.5756 - val_mae: 2.5786\n",
      "Epoch 65/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.5542 - mae: 1.8488 - val_loss: 11.4794 - val_mae: 2.5313\n",
      "Epoch 66/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.7844 - mae: 1.8271 - val_loss: 11.3859 - val_mae: 2.5071\n",
      "Epoch 67/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.6883 - mae: 1.8205 - val_loss: 11.4337 - val_mae: 2.5482\n",
      "Epoch 68/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.5259 - mae: 1.8238 - val_loss: 11.7209 - val_mae: 2.5536\n",
      "Epoch 69/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.5805 - mae: 1.7997 - val_loss: 11.4070 - val_mae: 2.5221\n",
      "Epoch 70/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.4062 - mae: 1.8153 - val_loss: 11.6411 - val_mae: 2.5812\n",
      "Epoch 71/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.3967 - mae: 1.7938 - val_loss: 11.6201 - val_mae: 2.5571\n",
      "Epoch 72/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.2391 - mae: 1.8107 - val_loss: 11.4163 - val_mae: 2.5350\n",
      "Epoch 73/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.2816 - mae: 1.7725 - val_loss: 11.7396 - val_mae: 2.5715\n",
      "Epoch 74/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.9961 - mae: 1.7838 - val_loss: 11.9287 - val_mae: 2.5780\n",
      "Epoch 75/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.0173 - mae: 1.7653 - val_loss: 11.5839 - val_mae: 2.5277\n",
      "Epoch 76/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.1202 - mae: 1.7957 - val_loss: 11.5576 - val_mae: 2.5367\n",
      "Epoch 77/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.1395 - mae: 1.7481 - val_loss: 11.6519 - val_mae: 2.5682\n",
      "Epoch 78/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.9663 - mae: 1.7529 - val_loss: 11.6585 - val_mae: 2.5736\n",
      "Epoch 79/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.9156 - mae: 1.7507 - val_loss: 12.0272 - val_mae: 2.6297\n",
      "Epoch 80/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.9757 - mae: 1.7456 - val_loss: 11.5174 - val_mae: 2.5119\n",
      "Epoch 81/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.8165 - mae: 1.7185 - val_loss: 12.0621 - val_mae: 2.5856\n",
      "Epoch 82/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.8137 - mae: 1.7567 - val_loss: 11.6420 - val_mae: 2.4995\n",
      "Epoch 83/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.5344 - mae: 1.7247 - val_loss: 11.7735 - val_mae: 2.5762\n",
      "Epoch 84/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.8059 - mae: 1.7318 - val_loss: 11.8128 - val_mae: 2.5762\n",
      "Epoch 85/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.7385 - mae: 1.7062 - val_loss: 11.7373 - val_mae: 2.5427\n",
      "Epoch 86/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.6725 - mae: 1.7152 - val_loss: 11.6505 - val_mae: 2.5093\n",
      "Epoch 87/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.4518 - mae: 1.7049 - val_loss: 11.6879 - val_mae: 2.5091\n",
      "Epoch 88/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.6046 - mae: 1.6787 - val_loss: 11.6945 - val_mae: 2.5115\n",
      "Epoch 89/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.6334 - mae: 1.6908 - val_loss: 11.6983 - val_mae: 2.5174\n",
      "Epoch 90/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.4120 - mae: 1.7012 - val_loss: 11.4566 - val_mae: 2.4912\n",
      "Epoch 91/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.4675 - mae: 1.6721 - val_loss: 11.7539 - val_mae: 2.5155\n",
      "Epoch 92/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.4220 - mae: 1.6919 - val_loss: 11.8855 - val_mae: 2.5411\n",
      "Epoch 93/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.3869 - mae: 1.6586 - val_loss: 11.8318 - val_mae: 2.5278\n",
      "Epoch 94/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.3098 - mae: 1.6630 - val_loss: 11.8639 - val_mae: 2.5205\n",
      "Epoch 95/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.0235 - mae: 1.6599 - val_loss: 11.6603 - val_mae: 2.5283\n",
      "Epoch 96/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.3030 - mae: 1.6492 - val_loss: 11.7034 - val_mae: 2.5147\n",
      "Epoch 97/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.2285 - mae: 1.6658 - val_loss: 12.0888 - val_mae: 2.5443\n",
      "Epoch 98/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.2405 - mae: 1.6462 - val_loss: 12.3417 - val_mae: 2.6269\n",
      "Epoch 99/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.1004 - mae: 1.6383 - val_loss: 11.9391 - val_mae: 2.5298\n",
      "Epoch 100/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.0355 - mae: 1.6514 - val_loss: 11.9018 - val_mae: 2.5248\n",
      "Epoch 101/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.1628 - mae: 1.6346 - val_loss: 11.7529 - val_mae: 2.4946\n",
      "Epoch 102/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.0338 - mae: 1.6291 - val_loss: 12.0386 - val_mae: 2.5130\n",
      "Epoch 103/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.9128 - mae: 1.6250 - val_loss: 11.9913 - val_mae: 2.4984\n",
      "Epoch 104/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.8530 - mae: 1.6377 - val_loss: 12.0058 - val_mae: 2.5084\n",
      "Epoch 105/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.9876 - mae: 1.6209 - val_loss: 12.0384 - val_mae: 2.5287\n",
      "Epoch 106/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.8563 - mae: 1.6049 - val_loss: 11.9335 - val_mae: 2.5125\n",
      "Epoch 107/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.8602 - mae: 1.6172 - val_loss: 12.0544 - val_mae: 2.5306\n",
      "Epoch 108/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.7958 - mae: 1.6091 - val_loss: 12.3814 - val_mae: 2.5803\n",
      "Epoch 109/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.9299 - mae: 1.5903 - val_loss: 12.3999 - val_mae: 2.5344\n",
      "Epoch 110/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.6683 - mae: 1.5952 - val_loss: 12.1686 - val_mae: 2.5506\n",
      "Epoch 111/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.8303 - mae: 1.5926 - val_loss: 11.9754 - val_mae: 2.4894\n",
      "Epoch 112/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.7868 - mae: 1.5824 - val_loss: 12.1236 - val_mae: 2.4957\n",
      "Epoch 113/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.5660 - mae: 1.5723 - val_loss: 12.2177 - val_mae: 2.5507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.6726 - mae: 1.5696 - val_loss: 12.3737 - val_mae: 2.5267\n",
      "Epoch 115/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.5289 - mae: 1.5758 - val_loss: 12.1917 - val_mae: 2.5106\n",
      "Epoch 116/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.6114 - mae: 1.5728 - val_loss: 12.3885 - val_mae: 2.4995\n",
      "Epoch 117/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.5807 - mae: 1.5571 - val_loss: 12.1428 - val_mae: 2.4921\n",
      "Epoch 118/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.6470 - mae: 1.5513 - val_loss: 12.4164 - val_mae: 2.5197\n",
      "Epoch 119/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3104 - mae: 1.5643 - val_loss: 12.2523 - val_mae: 2.4958\n",
      "Epoch 120/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3506 - mae: 1.5649 - val_loss: 12.2969 - val_mae: 2.5272\n",
      "Epoch 121/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.5986 - mae: 1.5580 - val_loss: 12.4207 - val_mae: 2.5176\n",
      "Epoch 122/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3854 - mae: 1.5359 - val_loss: 12.2466 - val_mae: 2.4995\n",
      "Epoch 123/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.2827 - mae: 1.5347 - val_loss: 12.4824 - val_mae: 2.5022\n",
      "Epoch 124/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3241 - mae: 1.5578 - val_loss: 12.7563 - val_mae: 2.5434\n",
      "Epoch 125/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.2406 - mae: 1.5171 - val_loss: 13.0477 - val_mae: 2.5483\n",
      "Epoch 126/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.4039 - mae: 1.5534 - val_loss: 12.5117 - val_mae: 2.5068\n",
      "Epoch 127/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.1613 - mae: 1.5348 - val_loss: 12.8328 - val_mae: 2.5555\n",
      "Epoch 128/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.2306 - mae: 1.5297 - val_loss: 12.6381 - val_mae: 2.5296\n",
      "Epoch 129/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.2102 - mae: 1.5382 - val_loss: 12.5271 - val_mae: 2.5678\n",
      "Epoch 130/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.0219 - mae: 1.5322 - val_loss: 12.7482 - val_mae: 2.5805\n",
      "Epoch 131/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.1924 - mae: 1.5078 - val_loss: 12.7400 - val_mae: 2.5491\n",
      "Epoch 132/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.1093 - mae: 1.5244 - val_loss: 12.6536 - val_mae: 2.5191\n",
      "Epoch 133/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.0823 - mae: 1.5065 - val_loss: 12.6774 - val_mae: 2.5013\n",
      "Epoch 134/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.9417 - mae: 1.5114 - val_loss: 13.0755 - val_mae: 2.5606\n",
      "Epoch 135/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.1196 - mae: 1.5093 - val_loss: 12.6074 - val_mae: 2.5163\n",
      "Epoch 136/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.6788 - mae: 1.4909 - val_loss: 12.6343 - val_mae: 2.5591\n",
      "Epoch 137/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.0016 - mae: 1.4993 - val_loss: 12.8482 - val_mae: 2.5520\n",
      "Epoch 138/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.8656 - mae: 1.5000 - val_loss: 12.6117 - val_mae: 2.5126\n",
      "Epoch 139/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.9692 - mae: 1.4890 - val_loss: 12.5177 - val_mae: 2.5429\n",
      "Epoch 140/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.9964 - mae: 1.4959 - val_loss: 13.0191 - val_mae: 2.5391\n",
      "Epoch 141/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.7618 - mae: 1.5012 - val_loss: 12.6912 - val_mae: 2.5838\n",
      "Epoch 142/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.8042 - mae: 1.4746 - val_loss: 13.1528 - val_mae: 2.5917\n",
      "Epoch 143/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.9362 - mae: 1.4930 - val_loss: 12.3198 - val_mae: 2.5088\n",
      "Epoch 144/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.8041 - mae: 1.4548 - val_loss: 12.5378 - val_mae: 2.4890\n",
      "Epoch 145/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.8015 - mae: 1.4594 - val_loss: 13.2666 - val_mae: 2.5650\n",
      "Epoch 146/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.7737 - mae: 1.4796 - val_loss: 12.3738 - val_mae: 2.5476\n",
      "Epoch 147/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.7917 - mae: 1.4694 - val_loss: 12.5880 - val_mae: 2.5138\n",
      "Epoch 148/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.7022 - mae: 1.4493 - val_loss: 12.6152 - val_mae: 2.5341\n",
      "Epoch 149/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.7554 - mae: 1.4580 - val_loss: 12.9176 - val_mae: 2.5166\n",
      "Epoch 150/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.7309 - mae: 1.4594 - val_loss: 12.8483 - val_mae: 2.5241\n",
      "Epoch 151/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.5797 - mae: 1.4592 - val_loss: 12.6457 - val_mae: 2.5327\n",
      "Epoch 152/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.6474 - mae: 1.4499 - val_loss: 12.6424 - val_mae: 2.5726\n",
      "Epoch 153/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.6642 - mae: 1.4689 - val_loss: 12.7230 - val_mae: 2.5399\n",
      "Epoch 154/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.6341 - mae: 1.4506 - val_loss: 12.5476 - val_mae: 2.5541\n",
      "Epoch 155/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.5262 - mae: 1.4406 - val_loss: 13.5363 - val_mae: 2.5942\n",
      "Epoch 156/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.6018 - mae: 1.4525 - val_loss: 12.7806 - val_mae: 2.5384\n",
      "Epoch 157/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.4606 - mae: 1.4357 - val_loss: 13.4816 - val_mae: 2.5650\n",
      "Epoch 158/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.4932 - mae: 1.4381 - val_loss: 13.2480 - val_mae: 2.5644\n",
      "Epoch 159/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.3872 - mae: 1.4544 - val_loss: 12.9234 - val_mae: 2.5342\n",
      "Epoch 160/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.3980 - mae: 1.4534 - val_loss: 12.9138 - val_mae: 2.5329\n",
      "Epoch 161/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.4680 - mae: 1.4325 - val_loss: 12.9471 - val_mae: 2.5252\n",
      "Epoch 162/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.2763 - mae: 1.4115 - val_loss: 13.2550 - val_mae: 2.5413\n",
      "Epoch 163/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.4789 - mae: 1.4375 - val_loss: 12.9326 - val_mae: 2.5167\n",
      "Epoch 164/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.4887 - mae: 1.4214 - val_loss: 13.0759 - val_mae: 2.5303\n",
      "Epoch 165/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.3690 - mae: 1.4262 - val_loss: 13.1984 - val_mae: 2.5862\n",
      "Epoch 166/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.2782 - mae: 1.4326 - val_loss: 13.2530 - val_mae: 2.5922\n",
      "Epoch 167/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.3204 - mae: 1.4065 - val_loss: 12.9722 - val_mae: 2.5619\n",
      "Epoch 168/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.2973 - mae: 1.4044 - val_loss: 13.0430 - val_mae: 2.5449\n",
      "Epoch 169/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.3571 - mae: 1.4110 - val_loss: 12.6830 - val_mae: 2.5315\n",
      "Epoch 170/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.3077 - mae: 1.4067 - val_loss: 13.4420 - val_mae: 2.6043\n",
      "Epoch 171/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.2391 - mae: 1.4129 - val_loss: 13.1022 - val_mae: 2.5625\n",
      "Epoch 172/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.0774 - mae: 1.3963 - val_loss: 12.8795 - val_mae: 2.6536\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.4255 - mae: 1.4185 - val_loss: 12.9723 - val_mae: 2.5445\n",
      "Epoch 174/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.2939 - mae: 1.3923 - val_loss: 12.9460 - val_mae: 2.5640\n",
      "Epoch 175/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.1099 - mae: 1.4018 - val_loss: 12.9256 - val_mae: 2.5925\n",
      "Epoch 176/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.1111 - mae: 1.4105 - val_loss: 13.4171 - val_mae: 2.5720\n",
      "Epoch 177/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.1097 - mae: 1.4021 - val_loss: 12.8851 - val_mae: 2.5188\n",
      "Epoch 178/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.1533 - mae: 1.3911 - val_loss: 12.9842 - val_mae: 2.5570\n",
      "Epoch 179/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.2353 - mae: 1.3746 - val_loss: 13.0525 - val_mae: 2.5347\n",
      "Epoch 180/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.9950 - mae: 1.3744 - val_loss: 13.1462 - val_mae: 2.5305\n",
      "Epoch 181/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.0891 - mae: 1.3799 - val_loss: 13.5364 - val_mae: 2.5828\n",
      "Epoch 182/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.1041 - mae: 1.3948 - val_loss: 13.6771 - val_mae: 2.5686\n",
      "Epoch 183/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.0518 - mae: 1.3866 - val_loss: 13.4782 - val_mae: 2.5729\n",
      "Epoch 184/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.0739 - mae: 1.3788 - val_loss: 13.0051 - val_mae: 2.5501\n",
      "Epoch 185/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.9507 - mae: 1.3662 - val_loss: 13.4987 - val_mae: 2.5621\n",
      "Epoch 186/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.9075 - mae: 1.3884 - val_loss: 13.5007 - val_mae: 2.5849\n",
      "Epoch 187/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.0148 - mae: 1.3591 - val_loss: 13.5107 - val_mae: 2.5899\n",
      "Epoch 188/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.8572 - mae: 1.3519 - val_loss: 13.1137 - val_mae: 2.5581\n",
      "Epoch 189/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.9867 - mae: 1.3639 - val_loss: 13.3869 - val_mae: 2.5714\n",
      "Epoch 190/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.9245 - mae: 1.3650 - val_loss: 13.3136 - val_mae: 2.5552\n",
      "Epoch 191/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.8108 - mae: 1.3488 - val_loss: 13.5442 - val_mae: 2.5699\n",
      "Epoch 192/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.8005 - mae: 1.3466 - val_loss: 13.9596 - val_mae: 2.5553\n",
      "Epoch 193/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.8842 - mae: 1.3376 - val_loss: 13.7181 - val_mae: 2.6257\n",
      "Epoch 194/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.9094 - mae: 1.3344 - val_loss: 13.5192 - val_mae: 2.5677\n",
      "Epoch 195/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.8346 - mae: 1.3163 - val_loss: 13.7332 - val_mae: 2.5636\n",
      "Epoch 196/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.8752 - mae: 1.3467 - val_loss: 13.2845 - val_mae: 2.5578\n",
      "Epoch 197/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.7577 - mae: 1.3595 - val_loss: 12.9217 - val_mae: 2.5363\n",
      "Epoch 198/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.7438 - mae: 1.3293 - val_loss: 13.6997 - val_mae: 2.6000\n",
      "Epoch 199/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.7672 - mae: 1.3390 - val_loss: 13.4787 - val_mae: 2.5834\n",
      "Epoch 200/200\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 4.8031 - mae: 1.3209 - val_loss: 13.7205 - val_mae: 2.5863\n",
      "processing fold # 0\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 229.1028 - mae: 11.5125 - val_loss: 39.9847 - val_mae: 3.6831\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 31.9156 - mae: 3.8171 - val_loss: 28.6702 - val_mae: 2.9047\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 23.3982 - mae: 3.1746 - val_loss: 23.5659 - val_mae: 2.5848\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 19.6057 - mae: 2.9054 - val_loss: 20.4379 - val_mae: 2.5454\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 17.5779 - mae: 2.6816 - val_loss: 19.3354 - val_mae: 2.5441\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 16.0421 - mae: 2.6720 - val_loss: 17.2774 - val_mae: 2.1694\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 15.5692 - mae: 2.6082 - val_loss: 14.7552 - val_mae: 2.1088\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 14.7878 - mae: 2.5409 - val_loss: 14.6695 - val_mae: 2.2703\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 13.3003 - mae: 2.4281 - val_loss: 14.1278 - val_mae: 1.9054\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 13.7079 - mae: 2.4479 - val_loss: 13.8655 - val_mae: 2.3654\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 12.8214 - mae: 2.3501 - val_loss: 13.0873 - val_mae: 1.9348\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 12.1772 - mae: 2.2970 - val_loss: 11.5251 - val_mae: 1.9731\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 11.4350 - mae: 2.3276 - val_loss: 12.5181 - val_mae: 1.8672\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 11.9716 - mae: 2.2653 - val_loss: 11.7735 - val_mae: 1.8622\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 11.7123 - mae: 2.2073 - val_loss: 10.1075 - val_mae: 2.1301\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 10.8351 - mae: 2.1300 - val_loss: 11.0785 - val_mae: 2.2670\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 11.0781 - mae: 2.2083 - val_loss: 10.5238 - val_mae: 2.1858\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 10.4470 - mae: 2.1525 - val_loss: 11.5137 - val_mae: 2.0735\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 10.2729 - mae: 2.1124 - val_loss: 10.2531 - val_mae: 1.8574\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 10.3898 - mae: 2.1425 - val_loss: 10.2177 - val_mae: 1.8058\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.9649 - mae: 2.0727 - val_loss: 9.0334 - val_mae: 1.7903\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.9635 - mae: 2.0258 - val_loss: 9.6296 - val_mae: 1.7681\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.9792 - mae: 2.1052 - val_loss: 8.9267 - val_mae: 1.9581\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.7963 - mae: 2.0270 - val_loss: 8.7987 - val_mae: 2.1074\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.4240 - mae: 2.0099 - val_loss: 9.4823 - val_mae: 2.3056\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.3212 - mae: 2.0487 - val_loss: 9.4238 - val_mae: 1.9359\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.8333 - mae: 2.0024 - val_loss: 9.4872 - val_mae: 1.8553\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.0344 - mae: 2.0207 - val_loss: 8.4174 - val_mae: 1.7127\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.2038 - mae: 2.0124 - val_loss: 8.0729 - val_mae: 1.7605\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.6810 - mae: 1.9275 - val_loss: 8.1745 - val_mae: 1.7326\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.7019 - mae: 1.9298 - val_loss: 7.9946 - val_mae: 2.0599\n",
      "Epoch 32/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.4634 - mae: 1.9682 - val_loss: 10.5373 - val_mae: 2.0187\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.6126 - mae: 1.8916 - val_loss: 8.0468 - val_mae: 1.7800\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.1171 - mae: 1.8687 - val_loss: 7.8544 - val_mae: 1.9845\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.3142 - mae: 1.9245 - val_loss: 7.1185 - val_mae: 1.6664\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.9374 - mae: 1.9360 - val_loss: 7.2268 - val_mae: 1.8009\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.6880 - mae: 1.8273 - val_loss: 6.9912 - val_mae: 1.7076\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.5457 - mae: 1.8324 - val_loss: 6.6912 - val_mae: 1.6816\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.9505 - mae: 1.8663 - val_loss: 7.8198 - val_mae: 2.1286\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.6804 - mae: 1.8854 - val_loss: 6.7201 - val_mae: 1.6159\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.7610 - mae: 1.7901 - val_loss: 6.9796 - val_mae: 1.7652\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.4945 - mae: 1.7824 - val_loss: 7.6188 - val_mae: 1.9107\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.1777 - mae: 1.7300 - val_loss: 8.6113 - val_mae: 1.8516\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.4996 - mae: 1.7835 - val_loss: 7.0698 - val_mae: 1.6464\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.3801 - mae: 1.7589 - val_loss: 8.5940 - val_mae: 1.8562\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.5316 - mae: 1.7545 - val_loss: 6.8910 - val_mae: 1.8738\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.4753 - mae: 1.7553 - val_loss: 7.5764 - val_mae: 1.9459\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.2630 - mae: 1.7132 - val_loss: 7.1767 - val_mae: 1.6924\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.2485 - mae: 1.6981 - val_loss: 8.0147 - val_mae: 1.8477\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.0101 - mae: 1.6818 - val_loss: 7.5540 - val_mae: 1.8334\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.3314 - mae: 1.7018 - val_loss: 9.4465 - val_mae: 2.4705\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.9497 - mae: 1.7121 - val_loss: 6.9170 - val_mae: 1.7228\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.8366 - mae: 1.7005 - val_loss: 6.7935 - val_mae: 1.8867\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.8197 - mae: 1.6785 - val_loss: 6.8027 - val_mae: 1.8085\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9864 - mae: 1.7131 - val_loss: 7.0470 - val_mae: 1.8662\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.9308 - mae: 1.6531 - val_loss: 7.9504 - val_mae: 1.7556\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4056 - mae: 1.6493 - val_loss: 6.3065 - val_mae: 1.6508\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5774 - mae: 1.6420 - val_loss: 9.3263 - val_mae: 2.4311\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.4019 - mae: 1.6563 - val_loss: 7.8341 - val_mae: 2.1352\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.5131 - mae: 1.6450 - val_loss: 7.2080 - val_mae: 1.7564\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.2889 - mae: 1.6123 - val_loss: 7.1735 - val_mae: 1.9274\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.8398 - mae: 1.7217 - val_loss: 7.2740 - val_mae: 1.8941\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.9457 - mae: 1.5800 - val_loss: 6.4055 - val_mae: 1.7346\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.3931 - mae: 1.6469 - val_loss: 6.3848 - val_mae: 1.7982\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2324 - mae: 1.5843 - val_loss: 6.2282 - val_mae: 1.7701\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4479 - mae: 1.6276 - val_loss: 9.6779 - val_mae: 2.1251\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - ETA: 0s - loss: 6.4262 - mae: 1.616 - 1s 2ms/sample - loss: 6.3407 - mae: 1.6030 - val_loss: 6.4261 - val_mae: 1.8249\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8163 - mae: 1.5613 - val_loss: 7.3783 - val_mae: 1.7811\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.2411 - mae: 1.5971 - val_loss: 6.4881 - val_mae: 1.8887\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.0635 - mae: 1.5747 - val_loss: 6.9214 - val_mae: 1.8759\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.0763 - mae: 1.5802 - val_loss: 7.3064 - val_mae: 1.9720\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0352 - mae: 1.5784 - val_loss: 9.6685 - val_mae: 2.2248\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0705 - mae: 1.5833 - val_loss: 6.8733 - val_mae: 1.7665\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8587 - mae: 1.5283 - val_loss: 8.1880 - val_mae: 2.1162\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8575 - mae: 1.5817 - val_loss: 6.4076 - val_mae: 1.7508\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2007 - mae: 1.5694 - val_loss: 7.0556 - val_mae: 2.0832\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3859 - mae: 1.5297 - val_loss: 9.9645 - val_mae: 2.0296\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9607 - mae: 1.5746 - val_loss: 5.9706 - val_mae: 1.7035\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0090 - mae: 1.6093 - val_loss: 6.8384 - val_mae: 1.8544\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.4643 - mae: 1.4863 - val_loss: 7.6205 - val_mae: 1.8329\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4501 - mae: 1.5153 - val_loss: 6.6905 - val_mae: 1.9001\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2917 - mae: 1.5048 - val_loss: 6.9079 - val_mae: 2.0225\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5379 - mae: 1.5084 - val_loss: 7.6510 - val_mae: 2.0256\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3324 - mae: 1.5117 - val_loss: 7.6476 - val_mae: 1.8446\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2827 - mae: 1.4576 - val_loss: 7.1845 - val_mae: 1.9198\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5257 - mae: 1.4613 - val_loss: 7.3188 - val_mae: 1.8944\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3782 - mae: 1.4766 - val_loss: 7.3627 - val_mae: 1.9104\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2628 - mae: 1.4849 - val_loss: 7.3619 - val_mae: 1.8461\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2511 - mae: 1.4926 - val_loss: 7.2222 - val_mae: 1.8987\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3256 - mae: 1.4697 - val_loss: 7.5039 - val_mae: 1.9522\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3345 - mae: 1.5095 - val_loss: 9.9083 - val_mae: 2.0811\n",
      "Epoch 92/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2133 - mae: 1.4361 - val_loss: 6.8287 - val_mae: 1.8220\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.2298 - mae: 1.4236 - val_loss: 6.5076 - val_mae: 1.9228\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.3417 - mae: 1.4026 - val_loss: 8.3687 - val_mae: 2.2563\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.8052 - mae: 1.4408 - val_loss: 10.8870 - val_mae: 2.2581\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5862 - mae: 1.3713 - val_loss: 8.0455 - val_mae: 2.1258\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.8927 - mae: 1.4384 - val_loss: 6.6805 - val_mae: 1.9146\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.8851 - mae: 1.4600 - val_loss: 6.3717 - val_mae: 1.7806\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.8866 - mae: 1.4453 - val_loss: 6.0920 - val_mae: 1.8089\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5101 - mae: 1.4026 - val_loss: 9.6139 - val_mae: 2.2176\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.8413 - mae: 1.4441 - val_loss: 7.9337 - val_mae: 2.0118\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5746 - mae: 1.4455 - val_loss: 7.9470 - val_mae: 2.1935\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.7098 - mae: 1.3744 - val_loss: 7.3062 - val_mae: 1.8703\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.6611 - mae: 1.4129 - val_loss: 8.4415 - val_mae: 2.0775\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.4675 - mae: 1.4036 - val_loss: 10.3330 - val_mae: 2.2541\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5899 - mae: 1.3677 - val_loss: 7.6720 - val_mae: 2.0116\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.6730 - mae: 1.4339 - val_loss: 9.5486 - val_mae: 2.1310\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7060 - mae: 1.4820 - val_loss: 8.2769 - val_mae: 2.1361\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5982 - mae: 1.3744 - val_loss: 7.8356 - val_mae: 2.0931\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.4309 - mae: 1.3729 - val_loss: 7.9589 - val_mae: 2.2110\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4730 - mae: 1.3435 - val_loss: 8.8724 - val_mae: 2.1071\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2556 - mae: 1.3219 - val_loss: 7.5684 - val_mae: 1.9002\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3119 - mae: 1.3661 - val_loss: 9.6209 - val_mae: 2.4121\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4636 - mae: 1.3745 - val_loss: 8.9589 - val_mae: 2.0762\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5009 - mae: 1.4110 - val_loss: 8.1664 - val_mae: 2.1408\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8601 - mae: 1.3217 - val_loss: 9.1768 - val_mae: 2.1478\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.3728 - mae: 1.4116 - val_loss: 7.2016 - val_mae: 1.9728\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0917 - mae: 1.3278 - val_loss: 7.5722 - val_mae: 1.8377\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0638 - mae: 1.3111 - val_loss: 8.1964 - val_mae: 2.1826\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.3276 - mae: 1.3585 - val_loss: 7.6550 - val_mae: 1.9950\n",
      "processing fold # 1\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 157.7282 - mae: 9.1680 - val_loss: 28.5690 - val_mae: 4.1259\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 25.8059 - mae: 3.2798 - val_loss: 18.1545 - val_mae: 3.2497\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 18.6075 - mae: 2.8331 - val_loss: 16.3866 - val_mae: 3.0148\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 15.5131 - mae: 2.6246 - val_loss: 13.2521 - val_mae: 2.8150\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 14.0511 - mae: 2.5406 - val_loss: 13.0543 - val_mae: 2.8012\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.0964 - mae: 2.3276 - val_loss: 17.7574 - val_mae: 3.2613\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 11.8996 - mae: 2.3018 - val_loss: 13.1266 - val_mae: 2.7950\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.6999 - mae: 2.2603 - val_loss: 12.4855 - val_mae: 2.7707\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.0631 - mae: 2.2323 - val_loss: 12.0854 - val_mae: 2.7488\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.1620 - mae: 2.2032 - val_loss: 12.4061 - val_mae: 2.7200\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.9251 - mae: 2.1030 - val_loss: 12.4666 - val_mae: 2.7670\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4183 - mae: 2.1314 - val_loss: 10.9040 - val_mae: 2.6259\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.3805 - mae: 2.1105 - val_loss: 10.6242 - val_mae: 2.5967\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.9254 - mae: 2.0089 - val_loss: 14.5745 - val_mae: 2.9020\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.1004 - mae: 2.0816 - val_loss: 13.7243 - val_mae: 2.8525\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.5098 - mae: 2.0175 - val_loss: 11.2998 - val_mae: 2.6448\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.6312 - mae: 2.0137 - val_loss: 12.0301 - val_mae: 2.7215\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.6499 - mae: 1.9993 - val_loss: 12.6393 - val_mae: 2.7293\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.3473 - mae: 2.0309 - val_loss: 10.7746 - val_mae: 2.5750\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.1389 - mae: 1.9673 - val_loss: 9.8512 - val_mae: 2.4618\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.4921 - mae: 1.9301 - val_loss: 10.7352 - val_mae: 2.5357\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.8609 - mae: 1.8653 - val_loss: 13.1125 - val_mae: 2.8516\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.7907 - mae: 1.8481 - val_loss: 15.0880 - val_mae: 2.9925\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.9002 - mae: 1.9433 - val_loss: 10.3610 - val_mae: 2.4550\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.6052 - mae: 1.8689 - val_loss: 11.6150 - val_mae: 2.6093\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.3452 - mae: 1.8544 - val_loss: 8.9453 - val_mae: 2.3377\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.3513 - mae: 1.8251 - val_loss: 9.7039 - val_mae: 2.4221\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0910 - mae: 1.8398 - val_loss: 12.1021 - val_mae: 2.6868\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5170 - mae: 1.8084 - val_loss: 10.1036 - val_mae: 2.4733\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.9141 - mae: 1.8072 - val_loss: 10.0759 - val_mae: 2.4668\n",
      "Epoch 31/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0371 - mae: 1.7518 - val_loss: 11.0586 - val_mae: 2.5463\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4317 - mae: 1.7310 - val_loss: 11.6445 - val_mae: 2.5668\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0681 - mae: 1.7736 - val_loss: 9.9470 - val_mae: 2.4424\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8134 - mae: 1.7361 - val_loss: 13.1076 - val_mae: 2.7089\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6835 - mae: 1.7705 - val_loss: 9.9182 - val_mae: 2.4174\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8444 - mae: 1.7798 - val_loss: 12.5089 - val_mae: 2.6654\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6494 - mae: 1.7641 - val_loss: 9.0669 - val_mae: 2.3253\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5764 - mae: 1.7582 - val_loss: 12.3272 - val_mae: 2.5929\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1442 - mae: 1.6925 - val_loss: 14.0861 - val_mae: 2.7525\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8897 - mae: 1.6476 - val_loss: 9.9546 - val_mae: 2.4259\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9639 - mae: 1.6170 - val_loss: 11.8481 - val_mae: 2.5397\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9360 - mae: 1.6858 - val_loss: 17.0856 - val_mae: 3.0209\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4405 - mae: 1.6550 - val_loss: 10.9381 - val_mae: 2.4823\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6748 - mae: 1.5705 - val_loss: 14.9827 - val_mae: 2.8193\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1504 - mae: 1.6758 - val_loss: 11.0214 - val_mae: 2.5136\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7941 - mae: 1.6333 - val_loss: 11.2441 - val_mae: 2.4944\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6166 - mae: 1.5945 - val_loss: 10.8272 - val_mae: 2.5226\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.7942 - mae: 1.6779 - val_loss: 12.2372 - val_mae: 2.6401\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2293 - mae: 1.5620 - val_loss: 11.5517 - val_mae: 2.5682\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2301 - mae: 1.5841 - val_loss: 12.1725 - val_mae: 2.5396\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3023 - mae: 1.6118 - val_loss: 9.9808 - val_mae: 2.4700\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5122 - mae: 1.6327 - val_loss: 12.1100 - val_mae: 2.6233\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3360 - mae: 1.5619 - val_loss: 17.9508 - val_mae: 3.1568\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7907 - mae: 1.5376 - val_loss: 15.8569 - val_mae: 2.9354\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0643 - mae: 1.5260 - val_loss: 10.9440 - val_mae: 2.5458\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4952 - mae: 1.5331 - val_loss: 11.5115 - val_mae: 2.5125\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9516 - mae: 1.4730 - val_loss: 14.7460 - val_mae: 2.8114\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2867 - mae: 1.5758 - val_loss: 13.0684 - val_mae: 2.6232\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0962 - mae: 1.4857 - val_loss: 12.4399 - val_mae: 2.5978\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8723 - mae: 1.5331 - val_loss: 15.3417 - val_mae: 2.9806\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6406 - mae: 1.5336 - val_loss: 15.7337 - val_mae: 2.8996\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7107 - mae: 1.4650 - val_loss: 15.1885 - val_mae: 2.8432\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5817 - mae: 1.4620 - val_loss: 13.1744 - val_mae: 2.7261\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0856 - mae: 1.4646 - val_loss: 15.8049 - val_mae: 2.7931\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3418 - mae: 1.4609 - val_loss: 12.4342 - val_mae: 2.6135\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2772 - mae: 1.4610 - val_loss: 13.6209 - val_mae: 2.6899\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3444 - mae: 1.4668 - val_loss: 12.8349 - val_mae: 2.6405\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5493 - mae: 1.4441 - val_loss: 13.1106 - val_mae: 2.6207\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3923 - mae: 1.4659 - val_loss: 19.1607 - val_mae: 3.1908\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.6497 - mae: 1.4229 - val_loss: 11.4683 - val_mae: 2.5292\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.3503 - mae: 1.4391 - val_loss: 15.4043 - val_mae: 2.8953\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0730 - mae: 1.3753 - val_loss: 17.2167 - val_mae: 3.1531\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3027 - mae: 1.4093 - val_loss: 12.4595 - val_mae: 2.6570\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.1783 - mae: 1.4316 - val_loss: 21.5369 - val_mae: 3.2598\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2150 - mae: 1.3979 - val_loss: 16.9728 - val_mae: 3.0108\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2024 - mae: 1.4117 - val_loss: 17.3306 - val_mae: 2.9903\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2989 - mae: 1.4695 - val_loss: 17.5021 - val_mae: 3.0096\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0004 - mae: 1.3721 - val_loss: 15.4099 - val_mae: 2.6933\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.7213 - mae: 1.4097 - val_loss: 14.3086 - val_mae: 2.7685\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8850 - mae: 1.3951 - val_loss: 14.6755 - val_mae: 2.7107\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8900 - mae: 1.3631 - val_loss: 18.7498 - val_mae: 2.9537\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7602 - mae: 1.3998 - val_loss: 17.3643 - val_mae: 2.8792\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9764 - mae: 1.3657 - val_loss: 17.1213 - val_mae: 2.8859\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9091 - mae: 1.3460 - val_loss: 17.8988 - val_mae: 2.8847\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6905 - mae: 1.3389 - val_loss: 14.2732 - val_mae: 2.6841\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4367 - mae: 1.2740 - val_loss: 16.7184 - val_mae: 3.0012\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9210 - mae: 1.3483 - val_loss: 20.9071 - val_mae: 3.0991\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6331 - mae: 1.3252 - val_loss: 16.5102 - val_mae: 2.8350\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4370 - mae: 1.2658 - val_loss: 16.7238 - val_mae: 2.9022\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.5975 - mae: 1.2507 - val_loss: 13.6519 - val_mae: 2.7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3734 - mae: 1.2640 - val_loss: 18.8866 - val_mae: 2.9837\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7187 - mae: 1.2871 - val_loss: 15.0482 - val_mae: 2.7118\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5810 - mae: 1.2457 - val_loss: 20.0674 - val_mae: 3.0567\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4331 - mae: 1.2875 - val_loss: 20.8286 - val_mae: 3.0394\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.3475 - mae: 1.2858 - val_loss: 15.8266 - val_mae: 2.7416\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1364 - mae: 1.2112 - val_loss: 17.8013 - val_mae: 2.8725\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2208 - mae: 1.2389 - val_loss: 19.1842 - val_mae: 3.0260\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5309 - mae: 1.2673 - val_loss: 18.8555 - val_mae: 3.0051\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3434 - mae: 1.2808 - val_loss: 16.9422 - val_mae: 2.9171\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0642 - mae: 1.2412 - val_loss: 20.0955 - val_mae: 2.9366\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3777 - mae: 1.2326 - val_loss: 16.9615 - val_mae: 2.8424\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.1942 - mae: 1.2226 - val_loss: 18.8675 - val_mae: 2.9791\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2361 - mae: 1.2643 - val_loss: 18.7656 - val_mae: 3.0367\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2317 - mae: 1.2247 - val_loss: 14.4638 - val_mae: 2.7276\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0571 - mae: 1.2096 - val_loss: 18.2430 - val_mae: 2.9576\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1727 - mae: 1.2260 - val_loss: 17.5070 - val_mae: 2.8755\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1562 - mae: 1.1859 - val_loss: 16.4945 - val_mae: 2.8744\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8306 - mae: 1.1497 - val_loss: 16.4478 - val_mae: 2.9767\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.9624 - mae: 1.2257 - val_loss: 16.6523 - val_mae: 2.8237\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0755 - mae: 1.2017 - val_loss: 18.7639 - val_mae: 2.9488\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0107 - mae: 1.2089 - val_loss: 19.7001 - val_mae: 3.0481\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7769 - mae: 1.1404 - val_loss: 20.0539 - val_mae: 3.0504\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8483 - mae: 1.1562 - val_loss: 20.9028 - val_mae: 2.9988\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7940 - mae: 1.1509 - val_loss: 17.9669 - val_mae: 2.8751\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0276 - mae: 1.2254 - val_loss: 18.0765 - val_mae: 3.0822\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8030 - mae: 1.1687 - val_loss: 21.8435 - val_mae: 3.0420\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.9889 - mae: 1.1836 - val_loss: 19.4765 - val_mae: 3.0746\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0789 - mae: 1.1746 - val_loss: 19.2613 - val_mae: 2.8944\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.6918 - mae: 1.1454 - val_loss: 18.1311 - val_mae: 2.9617\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.7705 - mae: 1.1299 - val_loss: 17.2533 - val_mae: 2.9031\n",
      "processing fold # 2\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 202.6212 - mae: 9.9942 - val_loss: 22.6008 - val_mae: 3.3717\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 32.2492 - mae: 3.6139 - val_loss: 14.7895 - val_mae: 2.9919\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 23.2024 - mae: 3.1018 - val_loss: 11.3681 - val_mae: 2.5087\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 19.7659 - mae: 2.8433 - val_loss: 11.4394 - val_mae: 2.4665\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 18.3209 - mae: 2.7067 - val_loss: 9.6831 - val_mae: 2.3459\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 16.1108 - mae: 2.5382 - val_loss: 9.9242 - val_mae: 2.4505\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.4049 - mae: 2.4575 - val_loss: 10.2817 - val_mae: 2.4294\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.1182 - mae: 2.4260 - val_loss: 9.3178 - val_mae: 2.3762\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 13.1180 - mae: 2.3425 - val_loss: 10.2056 - val_mae: 2.5309\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 12.0052 - mae: 2.2845 - val_loss: 8.7320 - val_mae: 2.2429\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.1902 - mae: 2.3003 - val_loss: 10.7927 - val_mae: 2.5770\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 11.5738 - mae: 2.2389 - val_loss: 10.1939 - val_mae: 2.6344\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.7587 - mae: 2.2279 - val_loss: 9.4377 - val_mae: 2.4984\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.5089 - mae: 2.1731 - val_loss: 8.0206 - val_mae: 2.2448\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.3647 - mae: 2.0503 - val_loss: 13.3383 - val_mae: 2.9734\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 10.1624 - mae: 2.1564 - val_loss: 7.9576 - val_mae: 2.1980\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.9718 - mae: 2.0475 - val_loss: 8.8243 - val_mae: 2.3475\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.7188 - mae: 2.0410 - val_loss: 7.8058 - val_mae: 2.1427\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.5174 - mae: 2.0537 - val_loss: 7.1005 - val_mae: 2.1166\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4476 - mae: 2.0075 - val_loss: 8.2411 - val_mae: 2.2342\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.0813 - mae: 1.9472 - val_loss: 9.4889 - val_mae: 2.4396\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.5086 - mae: 1.9327 - val_loss: 7.6966 - val_mae: 2.1768\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.7124 - mae: 1.9990 - val_loss: 7.4701 - val_mae: 2.1615\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.5054 - mae: 1.9602 - val_loss: 8.6925 - val_mae: 2.3670\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2092 - mae: 1.9497 - val_loss: 8.5789 - val_mae: 2.4037\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2990 - mae: 1.9107 - val_loss: 7.4287 - val_mae: 2.1340\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6189 - mae: 1.9194 - val_loss: 7.2949 - val_mae: 2.1451\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1824 - mae: 1.8662 - val_loss: 7.1164 - val_mae: 2.1185\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6598 - mae: 1.8737 - val_loss: 9.1542 - val_mae: 2.4485\n",
      "Epoch 30/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.1963 - mae: 1.8390 - val_loss: 7.8236 - val_mae: 2.2071\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.0261 - mae: 1.8820 - val_loss: 8.0062 - val_mae: 2.3085\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8373 - mae: 1.8492 - val_loss: 7.7575 - val_mae: 2.2399\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.8721 - mae: 1.7533 - val_loss: 10.8560 - val_mae: 2.6511\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.6381 - mae: 1.7723 - val_loss: 8.6836 - val_mae: 2.3755\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2635 - mae: 1.7605 - val_loss: 8.2010 - val_mae: 2.2532\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.4714 - mae: 1.7428 - val_loss: 8.5366 - val_mae: 2.3144\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.0341 - mae: 1.7658 - val_loss: 8.8487 - val_mae: 2.3840\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.0939 - mae: 1.7575 - val_loss: 7.5573 - val_mae: 2.1476\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.2865 - mae: 1.7365 - val_loss: 8.0711 - val_mae: 2.2537\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.0837 - mae: 1.7247 - val_loss: 9.4256 - val_mae: 2.4098\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.9315 - mae: 1.7742 - val_loss: 7.3473 - val_mae: 2.0903\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.0058 - mae: 1.6849 - val_loss: 7.8365 - val_mae: 2.1550\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.7211 - mae: 1.7389 - val_loss: 7.4809 - val_mae: 2.1033\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0947 - mae: 1.7125 - val_loss: 11.0507 - val_mae: 2.5936\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.6861 - mae: 1.6975 - val_loss: 7.1663 - val_mae: 2.1204\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4980 - mae: 1.6122 - val_loss: 8.7972 - val_mae: 2.3737\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.7540 - mae: 1.7092 - val_loss: 7.4036 - val_mae: 2.1337\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3081 - mae: 1.6643 - val_loss: 7.4344 - val_mae: 2.1261\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4436 - mae: 1.5973 - val_loss: 8.1706 - val_mae: 2.2151\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3826 - mae: 1.6650 - val_loss: 8.1511 - val_mae: 2.2085\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.3197 - mae: 1.5867 - val_loss: 7.7816 - val_mae: 2.1003\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2798 - mae: 1.6365 - val_loss: 8.3956 - val_mae: 2.2470\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0569 - mae: 1.6235 - val_loss: 8.5275 - val_mae: 2.3312\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4500 - mae: 1.6134 - val_loss: 10.5100 - val_mae: 2.4769\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9787 - mae: 1.5666 - val_loss: 7.4255 - val_mae: 2.1248\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1579 - mae: 1.5976 - val_loss: 10.4729 - val_mae: 2.4718\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0270 - mae: 1.5725 - val_loss: 8.2926 - val_mae: 2.2037\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.9526 - mae: 1.5852 - val_loss: 8.9613 - val_mae: 2.3112\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5586 - mae: 1.5344 - val_loss: 9.6176 - val_mae: 2.2806\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6355 - mae: 1.6061 - val_loss: 7.2727 - val_mae: 2.1542\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8340 - mae: 1.5979 - val_loss: 7.8666 - val_mae: 2.1521\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6571 - mae: 1.5971 - val_loss: 6.9287 - val_mae: 2.0291\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5980 - mae: 1.5502 - val_loss: 10.5322 - val_mae: 2.5748\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5059 - mae: 1.5620 - val_loss: 9.3741 - val_mae: 2.4276\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4266 - mae: 1.4606 - val_loss: 8.2922 - val_mae: 2.2058\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8299 - mae: 1.5121 - val_loss: 10.6662 - val_mae: 2.4584\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5086 - mae: 1.4906 - val_loss: 7.7702 - val_mae: 2.1436\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0410 - mae: 1.4859 - val_loss: 8.3396 - val_mae: 2.1960\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4137 - mae: 1.5326 - val_loss: 8.0098 - val_mae: 2.1259\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.0296 - mae: 1.4595 - val_loss: 8.8180 - val_mae: 2.2784\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8959 - mae: 1.5046 - val_loss: 7.3260 - val_mae: 2.1009\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3312 - mae: 1.4529 - val_loss: 7.9170 - val_mae: 2.0681\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1163 - mae: 1.4911 - val_loss: 14.7927 - val_mae: 2.8190\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2786 - mae: 1.4686 - val_loss: 8.5950 - val_mae: 2.1734\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9363 - mae: 1.4452 - val_loss: 9.9726 - val_mae: 2.3071\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8755 - mae: 1.4501 - val_loss: 7.6390 - val_mae: 2.0648\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3128 - mae: 1.4623 - val_loss: 10.5482 - val_mae: 2.3336\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8467 - mae: 1.4361 - val_loss: 8.5563 - val_mae: 2.1551\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1366 - mae: 1.4009 - val_loss: 8.1976 - val_mae: 2.1660\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6708 - mae: 1.4445 - val_loss: 7.9709 - val_mae: 2.1419\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6895 - mae: 1.4000 - val_loss: 9.0031 - val_mae: 2.2079\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5925 - mae: 1.4790 - val_loss: 8.3813 - val_mae: 2.1076\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8515 - mae: 1.4035 - val_loss: 9.1824 - val_mae: 2.1831\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4022 - mae: 1.3997 - val_loss: 10.7866 - val_mae: 2.4574\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7406 - mae: 1.4026 - val_loss: 9.4427 - val_mae: 2.2624\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.8575 - mae: 1.3614 - val_loss: 9.3722 - val_mae: 2.2393\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.3587 - mae: 1.4091 - val_loss: 8.1213 - val_mae: 2.1664\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4611 - mae: 1.3438 - val_loss: 10.0552 - val_mae: 2.2834\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5732 - mae: 1.3649 - val_loss: 10.6262 - val_mae: 2.2572\n",
      "Epoch 90/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2811 - mae: 1.3705 - val_loss: 10.0328 - val_mae: 2.2837\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0084 - mae: 1.3201 - val_loss: 8.5707 - val_mae: 2.2592\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0843 - mae: 1.3669 - val_loss: 8.4955 - val_mae: 2.2075\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0425 - mae: 1.2869 - val_loss: 12.2159 - val_mae: 2.4444\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2025 - mae: 1.3643 - val_loss: 8.8951 - val_mae: 2.2098\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0801 - mae: 1.3840 - val_loss: 9.2584 - val_mae: 2.1760\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8502 - mae: 1.3582 - val_loss: 8.9106 - val_mae: 2.2215\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0305 - mae: 1.3616 - val_loss: 7.3463 - val_mae: 2.0714\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7615 - mae: 1.3291 - val_loss: 7.9042 - val_mae: 2.0909\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6414 - mae: 1.3086 - val_loss: 9.4569 - val_mae: 2.3192\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1647 - mae: 1.3574 - val_loss: 8.4389 - val_mae: 2.1748\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7469 - mae: 1.2892 - val_loss: 9.6049 - val_mae: 2.3601\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8065 - mae: 1.3480 - val_loss: 9.3502 - val_mae: 2.3500\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.7567 - mae: 1.3464 - val_loss: 8.9180 - val_mae: 2.2269\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7139 - mae: 1.3119 - val_loss: 8.6818 - val_mae: 2.2344\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6286 - mae: 1.2644 - val_loss: 10.7177 - val_mae: 2.4529\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.5505 - mae: 1.2886 - val_loss: 9.0292 - val_mae: 2.2743\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7140 - mae: 1.3021 - val_loss: 11.2298 - val_mae: 2.5296\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5259 - mae: 1.2639 - val_loss: 12.4417 - val_mae: 2.5822\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4538 - mae: 1.2522 - val_loss: 9.1353 - val_mae: 2.2560\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4328 - mae: 1.2669 - val_loss: 8.6507 - val_mae: 2.1508\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5601 - mae: 1.2576 - val_loss: 8.6037 - val_mae: 2.2449\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4917 - mae: 1.2969 - val_loss: 8.1763 - val_mae: 2.1143\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.1899 - mae: 1.2385 - val_loss: 9.6096 - val_mae: 2.2743\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5058 - mae: 1.2561 - val_loss: 7.9166 - val_mae: 2.2347\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4057 - mae: 1.2416 - val_loss: 8.2719 - val_mae: 2.1788\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2757 - mae: 1.2344 - val_loss: 9.7170 - val_mae: 2.3798\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2773 - mae: 1.2065 - val_loss: 9.4088 - val_mae: 2.3354\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.2316 - mae: 1.2092 - val_loss: 8.6715 - val_mae: 2.2167\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.3015 - mae: 1.2108 - val_loss: 9.5940 - val_mae: 2.2310\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.1399 - mae: 1.2121 - val_loss: 11.2101 - val_mae: 2.4313\n",
      "processing fold # 3\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 200.6801 - mae: 10.2883 - val_loss: 34.4031 - val_mae: 3.8178\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 23.4809 - mae: 3.2661 - val_loss: 25.2140 - val_mae: 3.4044\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 17.4507 - mae: 2.8110 - val_loss: 20.3481 - val_mae: 2.8408\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 14.1447 - mae: 2.6301 - val_loss: 21.2950 - val_mae: 2.8990\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 12.2192 - mae: 2.4771 - val_loss: 21.6198 - val_mae: 2.8567\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 11.8816 - mae: 2.3441 - val_loss: 19.5577 - val_mae: 2.6629\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 10.7798 - mae: 2.2172 - val_loss: 18.4580 - val_mae: 2.6547\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.9060 - mae: 2.2610 - val_loss: 17.0873 - val_mae: 2.4529\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.5065 - mae: 2.2198 - val_loss: 19.1768 - val_mae: 2.5651\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 9.4937 - mae: 2.1267 - val_loss: 20.6538 - val_mae: 2.9277\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.9181 - mae: 2.0883 - val_loss: 18.4771 - val_mae: 2.6014\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.4464 - mae: 2.0823 - val_loss: 20.0921 - val_mae: 2.9010\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.3388 - mae: 2.0338 - val_loss: 20.5983 - val_mae: 2.7414\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.6100 - mae: 2.0366 - val_loss: 16.7696 - val_mae: 2.5224\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 8.2757 - mae: 1.9439 - val_loss: 17.2306 - val_mae: 2.4913\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.9432 - mae: 1.9578 - val_loss: 17.6825 - val_mae: 2.5381\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.8713 - mae: 1.9033 - val_loss: 19.0408 - val_mae: 2.7837\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.1255 - mae: 1.8987 - val_loss: 17.9631 - val_mae: 2.6525\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.4443 - mae: 1.8988 - val_loss: 17.1393 - val_mae: 2.5041\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.2541 - mae: 1.8543 - val_loss: 19.4304 - val_mae: 2.6529\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.0602 - mae: 1.8787 - val_loss: 16.6208 - val_mae: 2.4570\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1132 - mae: 1.8654 - val_loss: 17.5795 - val_mae: 2.7774\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.4071 - mae: 1.8427 - val_loss: 19.0856 - val_mae: 2.6697\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.8050 - mae: 1.8317 - val_loss: 19.7378 - val_mae: 2.5573\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 7.1684 - mae: 1.8565 - val_loss: 18.0527 - val_mae: 2.6311\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2427 - mae: 1.7980 - val_loss: 17.1259 - val_mae: 2.4243\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.5251 - mae: 1.7778 - val_loss: 20.6566 - val_mae: 2.8102\n",
      "Epoch 28/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1263 - mae: 1.7176 - val_loss: 18.1650 - val_mae: 2.6285\n",
      "Epoch 29/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4336 - mae: 1.7495 - val_loss: 19.8889 - val_mae: 2.7779\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.2547 - mae: 1.6868 - val_loss: 18.5789 - val_mae: 2.4790\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1026 - mae: 1.7342 - val_loss: 18.2556 - val_mae: 2.5704\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.1299 - mae: 1.6858 - val_loss: 17.4635 - val_mae: 2.6101\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.4014 - mae: 1.7342 - val_loss: 17.4262 - val_mae: 2.5519\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 6.0728 - mae: 1.7034 - val_loss: 16.6865 - val_mae: 2.5135\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.2533 - mae: 1.6791 - val_loss: 16.9197 - val_mae: 2.4296\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.9406 - mae: 1.6750 - val_loss: 16.5705 - val_mae: 2.4516\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.8015 - mae: 1.6783 - val_loss: 16.0279 - val_mae: 2.4974\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5359 - mae: 1.6585 - val_loss: 17.3316 - val_mae: 2.5550\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.6990 - mae: 1.6068 - val_loss: 17.9995 - val_mae: 2.4801\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4217 - mae: 1.6077 - val_loss: 17.1515 - val_mae: 2.4059\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.4116 - mae: 1.6109 - val_loss: 16.6927 - val_mae: 2.5758\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2646 - mae: 1.5988 - val_loss: 17.0733 - val_mae: 2.5282\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.3135 - mae: 1.6545 - val_loss: 18.4999 - val_mae: 2.7023\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2783 - mae: 1.6144 - val_loss: 16.7036 - val_mae: 2.4707\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.2703 - mae: 1.6007 - val_loss: 15.8149 - val_mae: 2.3728\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5112 - mae: 1.5917 - val_loss: 16.3158 - val_mae: 2.4152\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.3766 - mae: 1.5608 - val_loss: 17.1736 - val_mae: 2.5161\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.9734 - mae: 1.5231 - val_loss: 16.8628 - val_mae: 2.4602\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.1844 - mae: 1.5352 - val_loss: 18.6055 - val_mae: 2.6496\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 5.5205 - mae: 1.5414 - val_loss: 16.5427 - val_mae: 2.4377\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9511 - mae: 1.4836 - val_loss: 17.4857 - val_mae: 2.5048\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9421 - mae: 1.5203 - val_loss: 16.4736 - val_mae: 2.5314\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.8442 - mae: 1.4943 - val_loss: 18.3702 - val_mae: 2.6911\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.6634 - mae: 1.5395 - val_loss: 16.0436 - val_mae: 2.4172\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.9586 - mae: 1.4892 - val_loss: 18.3747 - val_mae: 2.6109\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.4900 - mae: 1.4471 - val_loss: 22.1920 - val_mae: 3.0721\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7031 - mae: 1.4589 - val_loss: 16.4100 - val_mae: 2.6851\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2215 - mae: 1.3789 - val_loss: 19.6221 - val_mae: 2.6378\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5482 - mae: 1.4693 - val_loss: 16.0222 - val_mae: 2.4083\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.4338 - mae: 1.4351 - val_loss: 18.2374 - val_mae: 2.5889\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.5808 - mae: 1.4639 - val_loss: 16.8275 - val_mae: 2.5855\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1685 - mae: 1.4667 - val_loss: 17.2448 - val_mae: 2.5216\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.2779 - mae: 1.4051 - val_loss: 16.2870 - val_mae: 2.5959\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1692 - mae: 1.4428 - val_loss: 16.9343 - val_mae: 2.5657\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.7938 - mae: 1.4387 - val_loss: 15.8139 - val_mae: 2.5452\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8966 - mae: 1.3774 - val_loss: 18.3393 - val_mae: 2.6482\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0911 - mae: 1.4370 - val_loss: 15.3651 - val_mae: 2.4658\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9827 - mae: 1.3885 - val_loss: 17.7427 - val_mae: 2.6546\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0303 - mae: 1.3918 - val_loss: 23.3971 - val_mae: 2.9752\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0259 - mae: 1.3690 - val_loss: 17.0362 - val_mae: 2.5721\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.1088 - mae: 1.3531 - val_loss: 19.9252 - val_mae: 2.7442\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0667 - mae: 1.3814 - val_loss: 17.0971 - val_mae: 2.5197\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.5369 - mae: 1.3398 - val_loss: 19.0324 - val_mae: 2.6796\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6824 - mae: 1.3288 - val_loss: 15.6784 - val_mae: 2.5740\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.1072 - mae: 1.3958 - val_loss: 16.0854 - val_mae: 2.4160\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.9607 - mae: 1.2835 - val_loss: 18.2488 - val_mae: 2.6480\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.8316 - mae: 1.3369 - val_loss: 16.2876 - val_mae: 2.5006\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.3444 - mae: 1.3010 - val_loss: 17.8093 - val_mae: 2.5298\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.3403 - mae: 1.3183 - val_loss: 17.5103 - val_mae: 2.5877\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.8182 - mae: 1.3469 - val_loss: 19.2298 - val_mae: 2.8618\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.4882 - mae: 1.2797 - val_loss: 16.5497 - val_mae: 2.5356\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.4026 - mae: 1.2787 - val_loss: 16.1027 - val_mae: 2.4256\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.4462 - mae: 1.2657 - val_loss: 18.1491 - val_mae: 2.6442\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.4653 - mae: 1.3347 - val_loss: 18.6633 - val_mae: 2.6490\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.3102 - mae: 1.2806 - val_loss: 17.0002 - val_mae: 2.8469\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.1121 - mae: 1.2707 - val_loss: 16.6006 - val_mae: 2.6436\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.2091 - mae: 1.2575 - val_loss: 17.1341 - val_mae: 2.6137\n",
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.1614 - mae: 1.2724 - val_loss: 19.3600 - val_mae: 2.8476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.1267 - mae: 1.2569 - val_loss: 17.8487 - val_mae: 2.8282\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.0263 - mae: 1.2617 - val_loss: 18.3555 - val_mae: 2.8526\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.0549 - mae: 1.2297 - val_loss: 18.8652 - val_mae: 2.7050\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.9226 - mae: 1.2611 - val_loss: 21.2711 - val_mae: 2.8850\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.0098 - mae: 1.2137 - val_loss: 18.6517 - val_mae: 2.8166\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 2.8819 - mae: 1.2363 - val_loss: 16.7742 - val_mae: 2.7155\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.9274 - mae: 1.1889 - val_loss: 17.8341 - val_mae: 2.6743\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.4205 - mae: 1.1491 - val_loss: 18.7847 - val_mae: 2.6206\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.9394 - mae: 1.2313 - val_loss: 19.5202 - val_mae: 2.7698\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.7036 - mae: 1.1615 - val_loss: 18.8642 - val_mae: 2.7029\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.8372 - mae: 1.1767 - val_loss: 19.4106 - val_mae: 2.9183\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.7619 - mae: 1.1768 - val_loss: 20.0144 - val_mae: 2.8239\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.6195 - mae: 1.1813 - val_loss: 18.9258 - val_mae: 2.7758\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.7877 - mae: 1.2287 - val_loss: 18.4752 - val_mae: 2.6753\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.6758 - mae: 1.1574 - val_loss: 18.3990 - val_mae: 2.7447\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.5415 - mae: 1.1592 - val_loss: 19.5519 - val_mae: 2.7928\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.6534 - mae: 1.1818 - val_loss: 19.0010 - val_mae: 2.8377\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.6014 - mae: 1.1618 - val_loss: 18.2826 - val_mae: 2.6576\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.5047 - mae: 1.1448 - val_loss: 17.7902 - val_mae: 2.6388\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.4011 - mae: 1.1322 - val_loss: 22.1568 - val_mae: 2.9976\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.5986 - mae: 1.1653 - val_loss: 18.7938 - val_mae: 2.6987\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.5630 - mae: 1.1530 - val_loss: 17.2370 - val_mae: 2.6566\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.4646 - mae: 1.1321 - val_loss: 18.5262 - val_mae: 2.6924\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.3714 - mae: 1.1392 - val_loss: 18.0175 - val_mae: 2.6921\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.3877 - mae: 1.1300 - val_loss: 19.1972 - val_mae: 2.6700\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.6171 - mae: 1.1891 - val_loss: 17.9587 - val_mae: 2.5920\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.1683 - mae: 1.0819 - val_loss: 19.6476 - val_mae: 2.9077\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.3794 - mae: 1.1113 - val_loss: 22.8797 - val_mae: 3.1407\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.3726 - mae: 1.1232 - val_loss: 20.0159 - val_mae: 2.7817\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.3513 - mae: 1.1136 - val_loss: 17.5580 - val_mae: 2.6439\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.1658 - mae: 1.0881 - val_loss: 19.1827 - val_mae: 2.8146\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 2.0288 - mae: 1.0544 - val_loss: 18.1770 - val_mae: 2.7896\n",
      "processing fold # 4\n",
      "Train on 324 samples, validate on 80 samples\n",
      "Epoch 1/120\n",
      "324/324 [==============================] - 1s 4ms/sample - loss: 184.9895 - mae: 9.9799 - val_loss: 77.3689 - val_mae: 5.6743\n",
      "Epoch 2/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 30.5333 - mae: 3.7274 - val_loss: 47.9316 - val_mae: 4.1719\n",
      "Epoch 3/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 21.4208 - mae: 3.0925 - val_loss: 45.4622 - val_mae: 3.9810\n",
      "Epoch 4/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 17.8494 - mae: 2.7979 - val_loss: 34.7720 - val_mae: 3.6217\n",
      "Epoch 5/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 15.2450 - mae: 2.4964 - val_loss: 32.6986 - val_mae: 3.2222\n",
      "Epoch 6/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 13.8251 - mae: 2.4189 - val_loss: 29.2801 - val_mae: 3.2329\n",
      "Epoch 7/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 12.8553 - mae: 2.2792 - val_loss: 24.5283 - val_mae: 2.9746\n",
      "Epoch 8/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 11.7815 - mae: 2.1889 - val_loss: 23.0407 - val_mae: 2.9566\n",
      "Epoch 9/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 11.1685 - mae: 2.1953 - val_loss: 18.4800 - val_mae: 2.7872\n",
      "Epoch 10/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 10.6999 - mae: 2.1449 - val_loss: 21.5743 - val_mae: 2.9278\n",
      "Epoch 11/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 10.3472 - mae: 2.0788 - val_loss: 21.0114 - val_mae: 2.8593\n",
      "Epoch 12/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 10.0648 - mae: 2.0403 - val_loss: 20.1908 - val_mae: 2.9401\n",
      "Epoch 13/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.6137 - mae: 2.0166 - val_loss: 18.2060 - val_mae: 2.7499\n",
      "Epoch 14/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.2044 - mae: 2.0269 - val_loss: 18.4359 - val_mae: 2.7232\n",
      "Epoch 15/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.0144 - mae: 1.9995 - val_loss: 16.4452 - val_mae: 2.7398\n",
      "Epoch 16/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 9.7394 - mae: 1.9674 - val_loss: 15.4940 - val_mae: 2.6017\n",
      "Epoch 17/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.9551 - mae: 1.9605 - val_loss: 16.8554 - val_mae: 2.7480\n",
      "Epoch 18/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.7881 - mae: 1.9491 - val_loss: 14.0283 - val_mae: 2.5922\n",
      "Epoch 19/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.4425 - mae: 1.8842 - val_loss: 15.7167 - val_mae: 2.6317\n",
      "Epoch 20/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.7444 - mae: 1.8452 - val_loss: 17.2492 - val_mae: 2.7115\n",
      "Epoch 21/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.8508 - mae: 1.8677 - val_loss: 14.5695 - val_mae: 2.7654\n",
      "Epoch 22/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.4819 - mae: 1.8658 - val_loss: 16.5325 - val_mae: 2.9800\n",
      "Epoch 23/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.9961 - mae: 1.8493 - val_loss: 12.4659 - val_mae: 2.3917\n",
      "Epoch 24/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.1418 - mae: 1.8129 - val_loss: 14.0358 - val_mae: 2.6681\n",
      "Epoch 25/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.5500 - mae: 1.8366 - val_loss: 13.4481 - val_mae: 2.5482\n",
      "Epoch 26/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.9044 - mae: 1.8315 - val_loss: 13.3678 - val_mae: 2.7348\n",
      "Epoch 27/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 8.1143 - mae: 1.8385 - val_loss: 12.6432 - val_mae: 2.4818\n",
      "Epoch 28/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.6073 - mae: 1.7968 - val_loss: 13.1163 - val_mae: 2.6350\n",
      "Epoch 29/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.9134 - mae: 1.8048 - val_loss: 11.7795 - val_mae: 2.3450\n",
      "Epoch 30/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.5884 - mae: 1.7560 - val_loss: 13.1020 - val_mae: 2.6556\n",
      "Epoch 31/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.6450 - mae: 1.7307 - val_loss: 12.5238 - val_mae: 2.4506\n",
      "Epoch 32/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.4821 - mae: 1.7939 - val_loss: 11.9092 - val_mae: 2.3875\n",
      "Epoch 33/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.6100 - mae: 1.7509 - val_loss: 12.0654 - val_mae: 2.4885\n",
      "Epoch 34/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.3036 - mae: 1.7396 - val_loss: 11.7786 - val_mae: 2.3994\n",
      "Epoch 35/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.2484 - mae: 1.7589 - val_loss: 12.3693 - val_mae: 2.4757\n",
      "Epoch 36/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 7.1578 - mae: 1.7440 - val_loss: 11.7213 - val_mae: 2.4007\n",
      "Epoch 37/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.9847 - mae: 1.7144 - val_loss: 11.2226 - val_mae: 2.3376\n",
      "Epoch 38/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.6870 - mae: 1.7214 - val_loss: 12.8359 - val_mae: 2.5334\n",
      "Epoch 39/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.9137 - mae: 1.7012 - val_loss: 11.9533 - val_mae: 2.4461\n",
      "Epoch 40/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.5818 - mae: 1.6950 - val_loss: 11.4909 - val_mae: 2.3806\n",
      "Epoch 41/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.6038 - mae: 1.6571 - val_loss: 12.7494 - val_mae: 2.6383\n",
      "Epoch 42/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.3002 - mae: 1.6571 - val_loss: 11.6741 - val_mae: 2.4312\n",
      "Epoch 43/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.7151 - mae: 1.6764 - val_loss: 12.3623 - val_mae: 2.5021\n",
      "Epoch 44/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.3701 - mae: 1.6348 - val_loss: 13.5570 - val_mae: 2.6478\n",
      "Epoch 45/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.3431 - mae: 1.6701 - val_loss: 12.9673 - val_mae: 2.5482\n",
      "Epoch 46/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.6298 - mae: 1.6488 - val_loss: 12.1442 - val_mae: 2.4262\n",
      "Epoch 47/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.1954 - mae: 1.6743 - val_loss: 12.6549 - val_mae: 2.4613\n",
      "Epoch 48/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.0865 - mae: 1.6441 - val_loss: 12.0194 - val_mae: 2.4500\n",
      "Epoch 49/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 6.0950 - mae: 1.5967 - val_loss: 12.8582 - val_mae: 2.5292\n",
      "Epoch 50/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.9085 - mae: 1.6178 - val_loss: 12.5926 - val_mae: 2.4753\n",
      "Epoch 51/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.8181 - mae: 1.5581 - val_loss: 13.2274 - val_mae: 2.5764\n",
      "Epoch 52/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.4975 - mae: 1.5728 - val_loss: 13.0503 - val_mae: 2.4583\n",
      "Epoch 53/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.7199 - mae: 1.5549 - val_loss: 12.6478 - val_mae: 2.4580\n",
      "Epoch 54/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.8195 - mae: 1.5179 - val_loss: 12.9678 - val_mae: 2.5554\n",
      "Epoch 55/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.8122 - mae: 1.5379 - val_loss: 12.5388 - val_mae: 2.4983\n",
      "Epoch 56/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.4278 - mae: 1.5631 - val_loss: 12.5272 - val_mae: 2.4935\n",
      "Epoch 57/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.5632 - mae: 1.4888 - val_loss: 13.6437 - val_mae: 2.6889\n",
      "Epoch 58/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.5628 - mae: 1.5543 - val_loss: 14.1028 - val_mae: 2.6559\n",
      "Epoch 59/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.3505 - mae: 1.5143 - val_loss: 13.8231 - val_mae: 2.6536\n",
      "Epoch 60/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.6005 - mae: 1.5276 - val_loss: 12.8622 - val_mae: 2.5462\n",
      "Epoch 61/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.4964 - mae: 1.4810 - val_loss: 14.9306 - val_mae: 2.7989\n",
      "Epoch 62/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.2353 - mae: 1.5776 - val_loss: 13.7472 - val_mae: 2.5924\n",
      "Epoch 63/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.3912 - mae: 1.5102 - val_loss: 13.3988 - val_mae: 2.5645\n",
      "Epoch 64/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.4474 - mae: 1.4701 - val_loss: 12.8162 - val_mae: 2.5249\n",
      "Epoch 65/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 5.0082 - mae: 1.4446 - val_loss: 12.8728 - val_mae: 2.5629\n",
      "Epoch 66/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.8322 - mae: 1.4259 - val_loss: 13.6723 - val_mae: 2.6251\n",
      "Epoch 67/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.9874 - mae: 1.4500 - val_loss: 15.2301 - val_mae: 2.7345\n",
      "Epoch 68/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.7373 - mae: 1.4449 - val_loss: 13.5200 - val_mae: 2.5373\n",
      "Epoch 69/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.8094 - mae: 1.4369 - val_loss: 13.8073 - val_mae: 2.6180\n",
      "Epoch 70/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.9556 - mae: 1.4486 - val_loss: 13.5011 - val_mae: 2.4671\n",
      "Epoch 71/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.9176 - mae: 1.4580 - val_loss: 14.1045 - val_mae: 2.6175\n",
      "Epoch 72/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.9714 - mae: 1.4520 - val_loss: 13.5806 - val_mae: 2.5232\n",
      "Epoch 73/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5311 - mae: 1.4090 - val_loss: 13.3078 - val_mae: 2.5518\n",
      "Epoch 74/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5931 - mae: 1.3649 - val_loss: 14.8300 - val_mae: 2.5945\n",
      "Epoch 75/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.7916 - mae: 1.4267 - val_loss: 14.4322 - val_mae: 2.6222\n",
      "Epoch 76/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.6821 - mae: 1.3978 - val_loss: 13.1709 - val_mae: 2.4851\n",
      "Epoch 77/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.7546 - mae: 1.4111 - val_loss: 14.3162 - val_mae: 2.5540\n",
      "Epoch 78/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5211 - mae: 1.3983 - val_loss: 15.5681 - val_mae: 2.8484\n",
      "Epoch 79/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.8015 - mae: 1.4251 - val_loss: 14.6493 - val_mae: 2.6256\n",
      "Epoch 80/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5725 - mae: 1.4351 - val_loss: 14.2464 - val_mae: 2.5508\n",
      "Epoch 81/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.3698 - mae: 1.3661 - val_loss: 14.4776 - val_mae: 2.6464\n",
      "Epoch 82/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5205 - mae: 1.3877 - val_loss: 13.5318 - val_mae: 2.5406\n",
      "Epoch 83/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.4862 - mae: 1.3792 - val_loss: 13.6800 - val_mae: 2.5089\n",
      "Epoch 84/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.5344 - mae: 1.3572 - val_loss: 13.9094 - val_mae: 2.5250\n",
      "Epoch 85/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.4329 - mae: 1.4114 - val_loss: 12.8444 - val_mae: 2.4434\n",
      "Epoch 86/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.4851 - mae: 1.3859 - val_loss: 15.2232 - val_mae: 2.8017\n",
      "Epoch 87/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.4601 - mae: 1.4202 - val_loss: 15.0221 - val_mae: 2.7111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.1595 - mae: 1.3218 - val_loss: 12.8670 - val_mae: 2.5493\n",
      "Epoch 89/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.4667 - mae: 1.3726 - val_loss: 14.1321 - val_mae: 2.6852\n",
      "Epoch 90/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.2115 - mae: 1.3234 - val_loss: 13.5953 - val_mae: 2.5070\n",
      "Epoch 91/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.2382 - mae: 1.3719 - val_loss: 14.0638 - val_mae: 2.6373\n",
      "Epoch 92/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.9681 - mae: 1.3350 - val_loss: 13.7864 - val_mae: 2.6443\n",
      "Epoch 93/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.3051 - mae: 1.3493 - val_loss: 14.3288 - val_mae: 2.5777\n",
      "Epoch 94/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.1817 - mae: 1.3278 - val_loss: 13.7509 - val_mae: 2.5916\n",
      "Epoch 95/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0160 - mae: 1.3187 - val_loss: 14.7174 - val_mae: 2.5941\n",
      "Epoch 96/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.1416 - mae: 1.3377 - val_loss: 14.2981 - val_mae: 2.6667\n",
      "Epoch 97/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0421 - mae: 1.2890 - val_loss: 13.5152 - val_mae: 2.5366\n",
      "Epoch 98/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0971 - mae: 1.3756 - val_loss: 13.7927 - val_mae: 2.5725\n",
      "Epoch 99/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.9780 - mae: 1.2772 - val_loss: 13.8137 - val_mae: 2.6524\n",
      "Epoch 100/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.0397 - mae: 1.3191 - val_loss: 13.1008 - val_mae: 2.5991\n",
      "Epoch 101/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.1151 - mae: 1.3018 - val_loss: 13.4606 - val_mae: 2.4998\n",
      "Epoch 102/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.1581 - mae: 1.2726 - val_loss: 14.1037 - val_mae: 2.6470\n",
      "Epoch 103/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 4.1918 - mae: 1.3125 - val_loss: 14.8328 - val_mae: 2.6544\n",
      "Epoch 104/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9850 - mae: 1.2630 - val_loss: 14.4621 - val_mae: 2.6413\n",
      "Epoch 105/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9915 - mae: 1.2298 - val_loss: 13.9494 - val_mae: 2.5882\n",
      "Epoch 106/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.9670 - mae: 1.2615 - val_loss: 14.0049 - val_mae: 2.6808\n",
      "Epoch 107/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8802 - mae: 1.2505 - val_loss: 13.5306 - val_mae: 2.6168\n",
      "Epoch 108/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7370 - mae: 1.2638 - val_loss: 15.5131 - val_mae: 2.7691\n",
      "Epoch 109/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 4.0121 - mae: 1.2919 - val_loss: 14.9357 - val_mae: 2.7311\n",
      "Epoch 110/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6129 - mae: 1.2819 - val_loss: 15.3720 - val_mae: 2.7503\n",
      "Epoch 111/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.5878 - mae: 1.2853 - val_loss: 12.8546 - val_mae: 2.5336\n",
      "Epoch 112/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.5094 - mae: 1.2271 - val_loss: 13.8788 - val_mae: 2.6047\n",
      "Epoch 113/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.6019 - mae: 1.2641 - val_loss: 13.7607 - val_mae: 2.7095\n",
      "Epoch 114/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.9516 - mae: 1.2741 - val_loss: 13.1027 - val_mae: 2.5691\n",
      "Epoch 115/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4331 - mae: 1.2012 - val_loss: 14.8829 - val_mae: 2.6555\n",
      "Epoch 116/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.6573 - mae: 1.2612 - val_loss: 13.0303 - val_mae: 2.5274\n",
      "Epoch 117/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.8460 - mae: 1.3082 - val_loss: 13.0545 - val_mae: 2.5414\n",
      "Epoch 118/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.4335 - mae: 1.2576 - val_loss: 13.1679 - val_mae: 2.5925\n",
      "Epoch 119/120\n",
      "324/324 [==============================] - 1s 3ms/sample - loss: 3.6724 - mae: 1.2642 - val_loss: 13.5502 - val_mae: 2.5813\n",
      "Epoch 120/120\n",
      "324/324 [==============================] - 1s 2ms/sample - loss: 3.7235 - mae: 1.3143 - val_loss: 13.1144 - val_mae: 2.5141\n",
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/50\n",
      "323/323 [==============================] - 1s 4ms/sample - loss: 200.6991 - mae: 10.3166 - val_loss: 46.9218 - val_mae: 4.5903\n",
      "Epoch 2/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 29.3109 - mae: 3.5763 - val_loss: 26.7374 - val_mae: 3.5057\n",
      "Epoch 3/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 22.4842 - mae: 3.0199 - val_loss: 20.4858 - val_mae: 3.1269\n",
      "Epoch 4/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 18.8990 - mae: 2.8177 - val_loss: 17.6336 - val_mae: 2.9586\n",
      "Epoch 5/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 16.4410 - mae: 2.6166 - val_loss: 15.6185 - val_mae: 2.7552\n",
      "Epoch 6/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 14.0772 - mae: 2.4629 - val_loss: 15.7169 - val_mae: 3.1502\n",
      "Epoch 7/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 13.3943 - mae: 2.4532 - val_loss: 12.4701 - val_mae: 2.6180\n",
      "Epoch 8/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 12.8004 - mae: 2.3061 - val_loss: 15.0396 - val_mae: 2.8554\n",
      "Epoch 9/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 12.2329 - mae: 2.2136 - val_loss: 12.9286 - val_mae: 2.6760\n",
      "Epoch 10/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 12.0684 - mae: 2.2221 - val_loss: 11.5073 - val_mae: 2.6451\n",
      "Epoch 11/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 11.7016 - mae: 2.2362 - val_loss: 12.0755 - val_mae: 2.7207\n",
      "Epoch 12/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.8227 - mae: 2.1805 - val_loss: 11.6374 - val_mae: 2.4812\n",
      "Epoch 13/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.6643 - mae: 2.1128 - val_loss: 11.9422 - val_mae: 2.6448\n",
      "Epoch 14/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 10.1359 - mae: 2.0851 - val_loss: 12.4277 - val_mae: 2.5733\n",
      "Epoch 15/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 10.0965 - mae: 2.0573 - val_loss: 11.0129 - val_mae: 2.4803\n",
      "Epoch 16/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 9.5218 - mae: 2.0070 - val_loss: 12.5816 - val_mae: 2.7562\n",
      "Epoch 17/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.6099 - mae: 2.0224 - val_loss: 14.5840 - val_mae: 2.9047\n",
      "Epoch 18/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 9.2589 - mae: 1.9910 - val_loss: 11.2011 - val_mae: 2.4700\n",
      "Epoch 19/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 9.0270 - mae: 1.9446 - val_loss: 11.6695 - val_mae: 2.4902\n",
      "Epoch 20/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.3573 - mae: 1.9176 - val_loss: 13.4929 - val_mae: 2.6804\n",
      "Epoch 21/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.0612 - mae: 1.9472 - val_loss: 11.8386 - val_mae: 2.5432\n",
      "Epoch 22/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 8.6849 - mae: 1.9645 - val_loss: 12.9836 - val_mae: 2.5617\n",
      "Epoch 23/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.9854 - mae: 1.8984 - val_loss: 13.0935 - val_mae: 2.6108\n",
      "Epoch 24/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.0393 - mae: 1.9014 - val_loss: 13.3284 - val_mae: 2.5942\n",
      "Epoch 25/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.5210 - mae: 1.9103 - val_loss: 13.2751 - val_mae: 2.7501\n",
      "Epoch 26/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 8.1834 - mae: 1.8729 - val_loss: 11.9135 - val_mae: 2.5186\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.5861 - mae: 1.8732 - val_loss: 12.6963 - val_mae: 2.6717\n",
      "Epoch 28/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.8427 - mae: 1.8200 - val_loss: 14.5478 - val_mae: 2.6817\n",
      "Epoch 29/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.4997 - mae: 1.8615 - val_loss: 14.6323 - val_mae: 2.7369\n",
      "Epoch 30/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.2762 - mae: 1.8071 - val_loss: 14.0780 - val_mae: 2.6415\n",
      "Epoch 31/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.5330 - mae: 1.7945 - val_loss: 13.5363 - val_mae: 2.4864\n",
      "Epoch 32/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 7.4724 - mae: 1.7784 - val_loss: 13.0817 - val_mae: 2.6475\n",
      "Epoch 33/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 7.3972 - mae: 1.7635 - val_loss: 13.6379 - val_mae: 2.5577\n",
      "Epoch 34/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.9591 - mae: 1.7849 - val_loss: 15.3452 - val_mae: 2.6758\n",
      "Epoch 35/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.7779 - mae: 1.7479 - val_loss: 15.0123 - val_mae: 2.7377\n",
      "Epoch 36/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.9714 - mae: 1.7194 - val_loss: 16.2567 - val_mae: 2.6559\n",
      "Epoch 37/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3447 - mae: 1.6730 - val_loss: 15.4057 - val_mae: 2.6136\n",
      "Epoch 38/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.7294 - mae: 1.7546 - val_loss: 16.2147 - val_mae: 2.5747\n",
      "Epoch 39/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.5890 - mae: 1.7034 - val_loss: 14.1964 - val_mae: 2.4718\n",
      "Epoch 40/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.2683 - mae: 1.6296 - val_loss: 16.3103 - val_mae: 2.6316\n",
      "Epoch 41/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3685 - mae: 1.6935 - val_loss: 13.5050 - val_mae: 2.4600\n",
      "Epoch 42/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.6845 - mae: 1.6607 - val_loss: 15.9624 - val_mae: 2.8044\n",
      "Epoch 43/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3783 - mae: 1.6992 - val_loss: 17.8079 - val_mae: 2.8072\n",
      "Epoch 44/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.3214 - mae: 1.6156 - val_loss: 15.2025 - val_mae: 2.5400\n",
      "Epoch 45/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.4696 - mae: 1.6309 - val_loss: 13.6495 - val_mae: 2.4678\n",
      "Epoch 46/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.5364 - mae: 1.6444 - val_loss: 15.1283 - val_mae: 2.5553\n",
      "Epoch 47/50\n",
      "323/323 [==============================] - 1s 2ms/sample - loss: 6.2747 - mae: 1.5926 - val_loss: 15.8740 - val_mae: 2.5249\n",
      "Epoch 48/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.8739 - mae: 1.5502 - val_loss: 15.1684 - val_mae: 2.4900\n",
      "Epoch 49/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 6.0306 - mae: 1.6307 - val_loss: 18.6980 - val_mae: 2.7270\n",
      "Epoch 50/50\n",
      "323/323 [==============================] - 1s 3ms/sample - loss: 5.8390 - mae: 1.6165 - val_loss: 16.7751 - val_mae: 2.8902\n"
     ]
    }
   ],
   "source": [
    "#Task 2: Compile and Fit the model. Change the learning rate from 0.001 to 0.0002\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu',\n",
    "                        input_shape=(train_data.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.0002), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "model.fit(train_data, train_targets, validation_split =0.2, epochs = 200, batch_size = 1)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "k = 5\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 120\n",
    "all_scores = []\n",
    "\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    \n",
    "# Get a fresh, compiled model.\n",
    "model = build_model()\n",
    "# Train it on the entirety of the data.\n",
    "history = model.fit(train_data, train_targets, validation_split =0.2, epochs=50, batch_size=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Task 3: Plot the MAE (train & test) curves\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "epochs = range(1, len(mae) + 1)\n",
    "\n",
    "plt.plot(epochs[10:], mae[10:], 'r', label='mean_absolute_error')\n",
    "plt.plot(epochs[10:], val_mae[10:], 'b', label='val_mean_absolute_error')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets, verbose=2)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Task 4: Comment on your model\n",
    "After reducing the learn rate, the network is slower in training and validation but the model look almost the same. We can see this from epochs 40 of the current model and epichs 43 of the model on top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
